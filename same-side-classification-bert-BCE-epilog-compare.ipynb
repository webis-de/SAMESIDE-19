{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:32.748273Z",
     "start_time": "2019-11-27T12:06:32.744972Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import gluonnlp as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from bert import *\n",
    "from mxboard import SummaryWriter\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:35.173247Z",
     "start_time": "2019-11-27T12:06:35.169744Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:37.394755Z",
     "start_time": "2019-11-27T12:06:37.392028Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:39.732276Z",
     "start_time": "2019-11-27T12:06:39.727946Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# set repeatable random state\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:42.104566Z",
     "start_time": "2019-11-27T12:06:42.102244Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:44.149101Z",
     "start_time": "2019-11-27T12:06:44.135382Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make tqdm jupyter friendly\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# for .progress_apply() we have to hack it like this?\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:46.244608Z",
     "start_time": "2019-11-27T12:06:46.241092Z"
    },
    "code_folding": [
     0,
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:48.339142Z",
     "start_time": "2019-11-27T12:06:48.336997Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'\n",
    "new_within_test = 'data/same-side-classification/within-topic/within_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:06:52.247825Z",
     "start_time": "2019-11-27T12:06:50.233253Z"
    },
    "code_folding": [
     0,
     10,
     11
    ],
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:00.843436\n",
      "Time for [read within]: 0:00:00.813130\n",
      "Time for [read new within]: 0:00:00.353044\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"read cross\"):\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "    #                              quotechar='\"',\n",
    "    #                              quoting=csv.QUOTE_ALL,\n",
    "    #                              encoding='utf-8',\n",
    "    #                              escapechar='\\\\',\n",
    "    #                              doublequote=True,  # <-- change, \"\" as quote escape in text?\n",
    "    #                              index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id')\n",
    "\n",
    "with Timer(\"read new within\"):\n",
    "    new_within_test_df = pd.read_csv(new_within_test, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T09:43:10.087253Z",
     "start_time": "2019-11-04T09:43:09.940258Z"
    }
   },
   "outputs": [],
   "source": [
    "! head -n 5 data/same-side-classification/within-topic/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T09:43:22.202044Z",
     "start_time": "2019-11-04T09:43:22.058400Z"
    }
   },
   "outputs": [],
   "source": [
    "! head -n 5 data/same-side-classification/within-topic/within_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:24.198808Z",
     "start_time": "2019-11-27T12:06:54.342449Z"
    },
    "code_folding": [
     1
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross traindev]: 0:00:32.932377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross test]: 0:00:03.402511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within traindev]: 0:00:34.850193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within test]: 0:00:01.872121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag new within test]: 0:00:16.794515\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.progress_apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag new within test\"):\n",
    "    new_within_test_df = new_within_test_df.progress_apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:26.355520Z",
     "start_time": "2019-11-27T12:08:26.347426Z"
    },
    "code_folding": [
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# requires nltk  wordtokenize\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# model uses BERT Tokenizer ...\n",
    "\n",
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "    \n",
    "    return\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T09:44:55.670829Z",
     "start_time": "2019-11-04T09:44:55.488227Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  same-side\n",
      "======================================== \n",
      "\n",
      "Total instances:  61048\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  61048  instances\n",
      "\t\t False :  29853  instances\n",
      "\t\t True :  31195  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  29853  instances\n",
      "True :  31195  instances\n",
      "\n",
      "\n",
      "Unique argument1: 7828\n",
      "Unique argument2: 7806\n",
      "Unique total arguments: 9361 \n",
      "\n",
      "Time for [overview cross]: 0:00:00.180387\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"overview cross\"):\n",
    "    get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T09:44:55.964631Z",
     "start_time": "2019-11-04T09:44:55.737699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  same-side\n",
      "======================================== \n",
      "\n",
      "Total instances:  63903\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  40840  instances\n",
      "\t\t False :  20006  instances\n",
      "\t\t True :  20834  instances\n",
      "gay marriage :  23063  instances\n",
      "\t\t False :  9786  instances\n",
      "\t\t True :  13277  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  29792  instances\n",
      "True :  34111  instances\n",
      "\n",
      "\n",
      "Unique argument1: 10508\n",
      "Unique argument2: 10453\n",
      "Unique total arguments: 13574 \n",
      "\n",
      "Time for [overview within]: 0:00:00.224594\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"overview within\"):\n",
    "    get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count raw length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_arg_len(row):\n",
    "    row['argument1_len'] = len(row['argument1'])\n",
    "    row['argument2_len'] = len(row['argument2'])\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff']\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "cross_test_df = cross_test_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(compute_arg_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize and count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T09:44:58.893321Z",
     "start_time": "2019-11-04T09:44:56.028744Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "_, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                    dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                    pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                    use_decoder=False, use_classifier=False)\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "tokenizer = bert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T10:02:33.339719Z",
     "start_time": "2019-11-04T09:44:58.975123Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3605254bc66844d7a471b22d71cb9088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9756ab70e54a599ab58f5010a41ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d764e93a1ecf4696899b936f5df5bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752c8f50d9f24cc6b0474bebe7a9dd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download('punct')\n",
    "\n",
    "\n",
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff'])\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "cross_test_df = cross_test_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(tokenize_arguments, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T10:02:33.843446Z",
     "start_time": "2019-11-04T10:02:33.729401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>264.863337</td>\n",
       "      <td>228.493382</td>\n",
       "      <td>36.369955</td>\n",
       "      <td>199.451563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>438.187823</td>\n",
       "      <td>405.800206</td>\n",
       "      <td>388.217671</td>\n",
       "      <td>335.043546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>258.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2964.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>2926.000000</td>\n",
       "      <td>2926.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_diff  \\\n",
       "count   61048.000000   61048.000000         61048.000000   \n",
       "mean      264.863337     228.493382            36.369955   \n",
       "std       438.187823     405.800206           388.217671   \n",
       "min         3.000000       4.000000         -2837.000000   \n",
       "25%        18.000000      17.000000           -55.000000   \n",
       "50%        83.000000      72.000000             3.000000   \n",
       "75%       258.000000     197.000000            88.000000   \n",
       "max      2964.000000    2964.000000          2926.000000   \n",
       "\n",
       "       argument12_len_diff_abs  \n",
       "count             61048.000000  \n",
       "mean                199.451563  \n",
       "std                 335.043546  \n",
       "min                   0.000000  \n",
       "25%                  23.000000  \n",
       "50%                  71.000000  \n",
       "75%                 199.000000  \n",
       "max                2926.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T10:02:34.145772Z",
     "start_time": "2019-11-04T10:02:34.123937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>252.189647</td>\n",
       "      <td>219.179303</td>\n",
       "      <td>33.010344</td>\n",
       "      <td>190.980486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>425.471105</td>\n",
       "      <td>393.925258</td>\n",
       "      <td>373.091463</td>\n",
       "      <td>322.199974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-58.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2825.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_diff  \\\n",
       "count   63903.000000   63903.000000         63903.000000   \n",
       "mean      252.189647     219.179303            33.010344   \n",
       "std       425.471105     393.925258           373.091463   \n",
       "min         3.000000       4.000000         -2837.000000   \n",
       "25%        15.000000      14.000000           -58.000000   \n",
       "50%        85.000000      73.000000             2.000000   \n",
       "75%       222.000000     179.000000            91.000000   \n",
       "max      2825.000000    2964.000000          2724.000000   \n",
       "\n",
       "       argument12_len_diff_abs  \n",
       "count             63903.000000  \n",
       "mean                190.980486  \n",
       "std                 322.199974  \n",
       "min                   0.000000  \n",
       "25%                  23.000000  \n",
       "50%                  75.000000  \n",
       "75%                 178.000000  \n",
       "max                2837.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T10:02:34.456033Z",
     "start_time": "2019-11-04T10:02:34.428623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3552.000000</td>\n",
       "      <td>3552.000000</td>\n",
       "      <td>3552.000000</td>\n",
       "      <td>3552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>504.283502</td>\n",
       "      <td>462.664414</td>\n",
       "      <td>41.619088</td>\n",
       "      <td>369.798705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>548.058512</td>\n",
       "      <td>526.286693</td>\n",
       "      <td>562.168586</td>\n",
       "      <td>425.413402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2733.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>-153.250000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>238.500000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>767.000000</td>\n",
       "      <td>665.250000</td>\n",
       "      <td>247.250000</td>\n",
       "      <td>517.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2825.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>2116.000000</td>\n",
       "      <td>2733.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_diff  \\\n",
       "count    3552.000000    3552.000000          3552.000000   \n",
       "mean      504.283502     462.664414            41.619088   \n",
       "std       548.058512     526.286693           562.168586   \n",
       "min         4.000000       4.000000         -2733.000000   \n",
       "25%        85.000000      78.750000          -153.250000   \n",
       "50%       273.000000     238.500000            11.500000   \n",
       "75%       767.000000     665.250000           247.250000   \n",
       "max      2825.000000    2964.000000          2116.000000   \n",
       "\n",
       "       argument12_len_diff_abs  \n",
       "count              3552.000000  \n",
       "mean                369.798705  \n",
       "std                 425.413402  \n",
       "min                   0.000000  \n",
       "25%                  62.000000  \n",
       "50%                 206.000000  \n",
       "75%                 517.250000  \n",
       "max                2733.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T10:02:35.387033Z",
     "start_time": "2019-11-04T10:02:34.716234Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEgCAYAAABFO1+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydeZhcVZn/P2/tS+/ZN7KThCyEsAQHRBAYEUWRqCOiIwKCiqLIb1xmBkVHFNRxFFQUFFFUBAURBRRBFoGwhCQSQlaSzr50d3qtfTm/P865Vbeqq7urk67uSnK/z3Ofqrufu533fN9VlFI4cODAgQMH/cE10g1w4MCBAwfVD0dYOHDgwIGDAeEICwcOHDhwMCAcYeHAgQMHDgaEIywcOHDgwMGAcISFAwcOHDgYEI6wcODAgQMHA8IRFg4cOHDgYED0KSxEZKGIvCAiO0TkdhFptK17aXia58CBAwcOqgH9MYvbgBuAhcBG4FkRmWnWeSvcLgcOHDhwUEXw9LOuRin1F/P/OyLyCvAXEfkw4OQIceDAgYOjCP0JCxGReqVUJ4BS6kkRWQbcDzQNS+scOHDgwEFVoD811M3APPsCpdSrwNnAA5VslAMHDhw4qC6Ik3XWgQMHDhwMBMd11oEDBw4cDAhHWDhw4MCBgwHhCIvDHCLSLCLnDNGx3mPianpE5IShOKaDww8islZEzhyiY90lIl8fimM5GFn06Q0lIrfSj4usUuqairToMIGINANXKKUeH8Zz3gXsVEr9d4VO8R3gU0qpP1bo+FUJEbkBmKWU+tBIt+VQICLTgK2AVymVPtjjKKXmD/K8E4GXlFKTD/acRyJszyNiW3yzUup/zHoBbgKuMOt+BnxBGUOy2f/nwFJgO/rbHLb+phj9MYsVwCtAAFgCbDLTYiBT+aY5GAFMBdYOxYFEpD+37KMO1XI/KtSO84G/DLjVYY5DuHcNSqkaM/2PbfmVwIXA8cAi4J3AVbb19wCrgFHAfwG/F5ExB9mGQ4dSqt8JeBI9UrHmvcCTA+13pE9AM3BOH+veCawGOoDngUVF+/0/4FWgE7gXCNjWfx7YA+xGjzgUMAv9YqWAJNAD/Kmc4xW1ywX8N7AN2A/8EqgH/OaYCj0KeqOP/b8P7AC60AOJN9vW3QD8HviVWX8FEAR+AbQD68y17bTto9Ajemv+LuDr5v+ZwE6zz35zTy5Ed0wbgQPAfxZd2xeBN4A24D6gyaybZs71EfQIrRX4L7PuPHNPU+Ye/NMsvxTYAnSjR4eX9HFP3MB/mvN2m/syxXZ9V6MHWVvNsn8BXjbP6mXgX2zHKnlO8/yfNvu0Avf20Zbt5pw9ZnqTOeZzwP+Ze/Z1YCbwd3OfWoFfozu0Xu+2ea73od+VbvRg4qSi8z4AXGT+nwCsNNveC/zWeqb9fRvm2f2+xPt2S5nf46nmeB3AP4EzzfIPACuKtr0WeMj896MZ9XZgH/BjIFj0Dn4B2AvcDbwGXGA7ltfcw8Ul2jTNPA9PH21+HrjSNn858IL5fyyQAGpt6/8BfHzE+rwyHsIGzEdn5huBDSPV4GqZ6ENYoFnYfjR1dKM7qGbAb9vvJWAiOrhxnfUCoDuuvcB8IGRezlyHiq0zLWpHyeOVaNtlwGZgBlBjPvK7besLOu8S+38IPcrxANeZtgbMuhvQHe6F6I47iKbYT5t3ZjJaoA1GWKSBL5sP8mNAC/AboNbcozgww2z/WeAFcx4/8BPgHrPO+mjvMO063nyI82xt/5WtHWG0wJtj5icA8/u4J/8BrAHmAGKOPcp2fX8zzyVoftuBD5t7eLGZH9XfOdEjzP8y9zUAnN5HW6zr9NiWXWru46fNOYNo4XOuuU9jgGeA75V6t829iaOFtBv4JqZDM+utzrIW8KEHItea5e8174T1TPv8NtCsNgrUmW3d6AHCqWV8i5PQgu98c4/ONfNj0N9RNzDbtv3LwAfM/+8BD5lnUwv8Cfhm0Tt4s2ljED14udd2rHcDawZ4HrvQQufnwGjb+k5gqW3+JKDb/H8PsK7oeD8Abh2xPq+MB/FR8wLcZaatwEdGqsHVMtG3sLgN+J+iZRuAt9j2+5Bt3beAH5v/d1ovqpmfRXnCouTxSrTtCeCTtvk55mP2mPl+hUWJ47UDx5v/NwDPFK3fArzNNn8FgxMWMcBt5mvN9vaP6xXgQvN/HXC2bd0E69psH+1k2/qXyHcYN9BbWHQAyzCjzH7uwQbg3X2sU8BbbfMfRuv27dssR3fofZ4TPaq/3d7+Ps5nXWexsNg+wH4XAqtKvdvm3jxuW3ccELPNnw08Yf6fgWbEYlv/vO2ZDvRtPAv8u/l/Ln0w3BLt/wK2QY9Z9ldMP4Vmu182/2ejhUcILdwjwEzbfm8izwLPRLNOO/OfaPa3hNrvgc/30a4atADwAOPMtn+1rc8Ac23zs83zE/OuvFB0vBuBu8r9Pod6GtAbSin1c/RI4A9mepNS6hcD7XcUYypwnYh0WBMwBf2SWdhr+x9Fv1SYbXbY1tn/94e+jleMiWjBb2Eb+Rd5QIjIdSKyTkQ6zXXVA6P7ae/BXo+FNqWUZR+Lmd99tvUx8tc6FfiD7Z6vQ3+M9msr6z4ppSLAvwEfB/aIyMMiMrePNk5Bq6D6gv2ai+8/Zn7SAOf8PLoDecl4Kl3Wz/kGagMiMlZEfisiu0SkC92Zji69K9D7vgVs+vvzgUds17dLmZ7Ndn0WBvo2foNmWwAfNPPlYCrwvqLjno4eMJQ67oNKqSh55vGKbb+/mOUWWpRScWtGKbUbrdZbJiINwNvRarxeUEr1KKVWKKXSSql9wKeAfxWROrNJD1Bn26UO6DH3r3idtb67zHsy5CjXddaNVgG0A8eKyBmVa9Jhjx3AjUqpBtsUUkrdU8a+e9BqFAtTitYrDg270R+WhWPQNHtf6c3zEJE3o0dw7wcalVINaBot/bRvoOuJoj9WC+MHakc/2AG8vei+B5RSu8rYt9d9VUr9VSl1LrrDWY9WYfV13pl9rCs+dvH9B/0MdvV3TqXUXqXUx5RSE9EG0B+JyKxyrqOP5d80yxYpperQ6kXptVd5OB942PzfA0wyXj4WjrH9H+jb+B1wpohMRqthyhUWO9DMwn7csFLqJrP+MWC0iCxGCw3ruK3oAcd82371Sin7IKLUPf0F+p69D1he5jtmP5Z1f9ai1ZYWjifvYLIWmCEitX2sH3YMKCxE5Ga0JP0vtH72P9AGVQfgFZGAbfKgP/CPi8hS0QiLyDuKHnpfuA/4qIjME5EQWl9vxz60veFgcQ9wrYhMF5Ea4Bto/Ws5bpa1aMHSAnhE5Mv0HvkU4z7gSyLSKCKT0CMrO1YDHxQRt4icB7xlMBdThB8DN4rIVAARGSMi7y5z333ANBFxmX3Hici7RCSMtm300LcH4E+B/xGR2eZ5LxKRUX1s+wh6sPVBEfGIyL+h1Tp/7u+cIvI+04GCHrCpPtrTAmQZ+B2pNcfvMM/lPwbYviREZDraFrfeLFqOfkeuMdd3EXCKbZd+vw2lVAvwFFq3v1Uptc52rhtE5Kk+mvIr4AIReZt5lwIiYgkdzPv9e+DbaNvE38zyrGnT/4nIWHOeSSLytgEu/UG0/eUzaBVhX/dnqYjMERGXeSduAZ5SJjmr2fdz5pwT0XbAu0zbNqK/j6+Y63kP2mPq/gHaVjGUwywuRBvd3qGUusBM76p0ww4TPIIemVjTDUqpFWhj7A/QH/ZmtN54QCilHkW/UE+a/ZabVQnz+zPgOEOZHzyI9t6JNpo/g7Y9xdGGz3LwV+BRtCfSNrPvQGqlr6ENe1uBx9EfbMK2/jPABWhd/SXoj/Bg8X20ofIxEelGG7uXlrnv78xvm4isRH8X16GZwAG0EPtkH/t+Fy0UH0MbqH+GNoT2glKqDe0NdB3aAPt54J1KqdYBznky8KKI9Jhr/IxSamuJ40fReu3nzDtyah9t/iq6s+tEs4KDTQz6DvIqKJRSSeAi9PvejlarPWBbX8638RvgHHqziinoQWsvKKV2oA3N/4kWmDvQAtDev1nH/V3R4OgLph0vGJXc42hbXp9QSsXQnfZ0+r93M9BqrW60F1WCvDoMtBPGn9AOEq+hn8VPbOs/gLZ5tKOdRd5rBOqIYMBEgiLyKPA+pVTP8DTJgQURmYd+ifxljv6rGiLyCbRR+VAYhIMqgYg8AvxAKfXIgBsf+rlWox0Y2ip9rnJgmPWx6jAP5BwMygkyiQKrReQJbKNCdZRHcFcKhm4+jPaOuRkdT3FYCgoRmYAeXS1He3pchx5VOjgy8BSaBVccSqnFw3GeciAiTeiYiA+PdFuGE+Uwi4+UWu54RFUGIvIXtPteBh2j8Eml1J6RbdXBwdgPHkbT9Q50gNaXjLrCgYPDDiLyMXRsxt1KqY+PdHuGE049CwcOHDhwMCAGVEOJyGy0q91x6OhRAJRSh+KV48CBAwcODiOUY7P4OfAVdG6Zs9AR3Qfrkz1sGD16tJo2bdpIN8OBAwcODiu88sorrUqpXgkLyxEWQaXUEyIiSqltwA0i8g+0AKlaTJs2jRUrVox0Mxw4cODgsIKIFGcZAMoTFnETrLRJRD6FjjYdO5SNc+DAgQMH1Y1ygvI+i07JcA1wIjrMvaSHlAMHDhw4ODIxILNQSr1s/vag7RUODgc8cBXMOQ/mv2ekW+LAgYMjAFVRvctBBfD6H8EXPqKFRSqVYufOncTj8YE3dnBICAQCTJ48Ga/XO9JNcTBCcITFkQilIJOA9JHdie7cuZPa2lqmTZtGYaJTB0MJpRRtbW3s3LmT6dOnj3RzHIwQyk1R7uBwQjYNKgup2MDbHsaIx+OMGjXKERQVhogwatQoh8Ed5TgoYWGSaDmoVqRNCq/BMIvdq+HP10I2W5k2VQiOoBgeOPfZwcEyiyuGtBUOhhZGWMSjg0gUvPlvsOJO6CjpYu3AgYOjHH0KCxHp6mPqprBEqINqg2EU+9s7B9jQvo/J7deyvt/Nntqwn3+/8yWyWSen2OGKb3zjGwXzl112GWPHjmXBggUj1CIHhwP6YxYdwGylVF3RVIsun+igSpFMaGHhygxCDWWprAYQFiu3tfPMxhaiqb4KxzkoRiZTXfeqWFhceuml/OUvfxmh1jg4XNCfsPglvesFWyi3Nq6DEUBPRKufPNnEAFvakDHMYn//wiKR1jaNnvhhWWKjIrjwwgs58cQTmT9/PrfffjsANTU1fPnLX2bp0qUsX76cRx55hLlz53L66adzzTXX8M53vhOAG264ge985zu5Yy1YsIDm5maam5uZO3cuV1xxBQsWLOCSSy7h8ccf57TTTmP27Nm89NJLAEQiES677DJOPvlkTjjhBP74xz8CcNddd3HRRRdx3nnnMXv2bD7/+c8D8MUvfpFYLMbixYu55JJLADjjjDNoamoatvvl4PBEn66zSqn/7mfdFwY6sIhMQQuc8ei6wLcrpb5vCofcC0wDmoH3K6XazT5fQhcVyQDXKKX+apafiK5NG0SXcfyMcnKr94lINEITgxQWZTKLnLBIVJew+Oqf1vL67q4hPeZxE+v4ygXzB9zuzjvvpKmpiVgsxsknn8yyZcuIRCIsWLCAr33ta8TjcWbPns0zzzzD9OnTufjiiwc8JsDmzZv53e9+x+23387JJ5/Mb37zG5599lkeeughvvGNb/Dggw9y44038ta3vpU777yTjo4OTjnlFM455xwAVq9ezapVq/D7/cyZM4dPf/rT3HTTTfzgBz9g9erVh3RvHBx9qKTrbBq4Tik1DzgVuFpEjgO+CDyhlJoNPGHmMes+AMwHzgN+JCJuc6zbgCvR1dZmm/UO+kAkEgEGKywMs2jd2K9HVLUKi5HELbfcwvHHH8+pp57Kjh072LRpE263m2XLlgGwfv16ZsyYkYtRKFdYTJ8+nYULF+JyuZg/fz5nn302IsLChQtpbm4G4LHHHuOmm25i8eLFnHnmmcTjcbZv3w7A2WefTX19PYFAgOOOO45t2xznharG374Cmx8f6Vb0iYoF5ZnqbnvM/24RWQdMQhdWP9Ns9gt0acYvmOW/VUolgK0ishk4RUSagTql1HIAEfklcCHwaKXafrgjGosC4B2UGspsm4pC53ZonFZys0Ra69+rTQ1VDgOoBJ566ikef/xxli9fTigUynXYgUAAt1uPdfojwR6Ph6xNONtjGfx+f+6/y+XKzbtcLtLpdO7Y999/P3PmzCk47osvvliwv9vtzu3joErx8k8h0Q2zzhnplpTEsATlicg04ATgRWCcVSbU/FoZbCcBO2y77TTLJpn/xctLnedKEVkhIitaWlqG8hIOK8SNsPANpnpp2iZY+rFbOMyiEJ2dnTQ2NhIKhVi/fj0vvPBCr23mzp3Lli1bcmzg3nvvza2bNm0aK1euBGDlypVs3bp1UOd/29vexq233poTSKtWrRpwH6/XSyqVGtR5HAwD0vGqzrowoLAQkZki4jf/zxSRa0SkodwTiEgNcD/wWaVUf0rlUlE/qp/lvRcqdbtS6iSl1EljxvSq3XHUwBIWXlKQLdMTJ52Appn6fz92i6QjLApw3nnnkU6nWbRoEddffz2nnnpqr22CwSA/+tGPOO+88zj99NMZN24c9fX1ACxbtowDBw6wePFibrvtNo499thBnf/6668nlUqxaNEiFixYwPXXXz/gPldeeSWLFi3KGbgvvvhi3vSmN7FhwwYmT57Mz372s0G1wcEQIJPWmRdS0ZFuSZ8oRw11P3CSiMwCfgY8hPaGOn+gHUXEa/b/tVLqAbN4n4hMUErtEZEJwH6zfCcwxbb7ZGC3WT65xHIHfSARt6X5SMd1QsGBkI5DzVj9svYjLCxmEXGEBaBVRY8+2lsj2tNTGBB51llnsX79epRSXH311Zx00kmAFiSPPfZYyWO/9tpruf933XVX7v+0adNy64LBID/5yU967XvppZdy6aWX5ub//Oc/5/7ffPPN3Hzzzbn5e+65p58rdDAsyKmBD2NmAWSVUmngPcD3lFLXAhMG2kl0foCfAeuUUt+1rXqIfD2MjwB/tC3/gIj4RWQ62pD9klFVdYvIqeaY/27bx0EJJO3CotyXL5MEjx/GzO1fWJj4CodZDA533HEHixcvZv78+XR2dnLVVVeNdJMcVBNyKXoOMp/b7WfBK78YuvaUQDnMIiUiF6M79gvMsnLyFJ8GfBhYIyKWn95/AjcB94nI5cB24H0ASqm1InIf8Drak+pqpZSlQ/kEedfZR3GM2/0imbQzizJfvnQcAg3QNAO18hek02m8nt6vRzLjqKEOBtdeey3XXnvtSDfDQbXCSvp5MMk/s1nYvRImnTi0bSpCOcLio8DHgRuVUlvNqP9XA+2klHqW0vYGgLP72OdG4MYSy1cATi6CMpFOHASzSBtmMXYukopy/xPL+cDb3txrs0TKCcpz4GDIYRm2D0ZYWAPCxNDGGRWjHGFxrlLqGmvGCIwjO/f1YY5M0ubZNBhm4fGTGTUHN5DZvw4oISzSjhrKgYMhx8FkiraQNEbxRPfQtacEyrFZlKq3fekQt8PBECKTOnibRaJxNgBNkTdKbuaooRw4qAByzOIghEVKB+FWWlj0ySyMneKDwHQReci2qhZoq2irHBwSlP2FGwyzcPuJuWtRyk8geaDkZo4ayoGDCiBtC4odLCxmER9ElumDQH/M4nngf4H15tearsNJt1HVULYAu0yizJcvnQRPgHg6Sww/rj7o8JtSL/KA78tEE4MI+HNQVbBnnd2xYwdnnXUW8+bNY/78+Xz/+98fwZYdxbC+t4NSQw0Ps+hTWCiltimlnlJKvUkp9bRtWmlcaR1UIRLpDO5sviNPJ8sUFpkEeHzEkhni+HBnSjOSedmNLHFtJh0fRGGloxzVnKLc4/Hwv//7v6xbt44XXniBH/7wh7z++usj2LqjFDlmcRDm4GFSQ5UTwX2RiGwSkU6r+JGIVNbsfjghFYPXHxp4u2FCZyyFj3wqh7Q95uK3l8Ca3/feKZs1NosA8VSGmPLjKVELQymFP6uPl01EhrzthysO5xTlEyZMYMmSJQDU1tYyb948du3aNWz3zoGBxShUBjKDTMWSM3CPvDfUt4ALlFLrKtqSwxXrH4b7L4drVkPT9JFuDV2xFH5JkcKLlxQZ60VSCrXhUVTNOFwL31u4k1XLwu0jkc6g8OLJ9hYW6awihB4BqWSVCYtHvwh71wztMccvhLffNOBmR0qK8ubmZlatWsXSpUsHd58cHDrsudlSUXDXl7+vZefIJPVxPP7+tz9IlOMNtc8RFP0g3qF/KyzVy4XFLGLuGgDSyXywj6gMG3fs772TNarx+Ikltc3CXSJjbSKdJSx6W0lFyTilVYEjI0V5T08Py5Yt43vf+x51dXWHcDccHBTstorBekTZB24VVEWVwyxWiMi9wINArgex5Xo6umGN3A9G11gBdMZS+EmR9NZCpp2saZ9KdCNAMlbiZbKYhcdPPJUhq3yESwiLZDpLCP0ih4gTSaapC5QTzD8MKIMBVAJHQoryVCrFsmXLuOSSS7jooovKvXQHQ4n0QcRGWbB7UMU7ITx6aNpUhHKYRR0QBf4Vne7jAuCdFWnN4QjrQVVJtkhLWGR8enSYNcwiZYSEO12indaoxu0nltIGbp/qPbpJpDM5ZhGShOM+y+GfolwpxeWXX868efP43Oc+N6hzOxhCHAnMQin10Yqd/UiAJSTK9TqqMDqiKSZKGpevloTykjWMJxntwEdfwsJiFgHiyQxZ/CVrYSRSRczCCczjvPPO48c//jGLFi1izpw5A6YoHz16NKecckpu3bJly/jlL3/J4sWLOfnkkw8qRflnP/tZFi1ahFKKadOmFWSYLQUrRfmSJUv4xCc+wd13383ChQtZvHgxoL2lzj9/wKTSDoYSxTaLwcC+/UgKCxE5Fl3WdJxSaoGILALepZT6esVadTihKtVQSdzeIHG8qKTu3FMRbVPxlHKJzdksfMSjWTLKh1+VtllYBu4wcbqNsNi8v4enNuznijfPqMAVVTeOhBTlTjn7KoBd9TTYWIsCZlE522k5aqg7gC+B9sdUSr2KrpXtAGxqqOrwDuqMpQhKBpfXTxwfKm2pofRL5MuWEBZWLn3DLOL4CJDo1YkkbQbukCRyzOJ3K3bw9YfXOSlA+oGTotxBvyhgFoMceFaLGgoIKaVe0qUkcnB6BQup6mMWQVdKd/zKhzdVKCz8JWwROTWU20c8lSGDnwBJkpksfo87t1kinSlQQ1k2i71dellrd4Iaf8XKuh/WcFKUO+gXBTaLgzBw++sh0VlRYVEOs2gVkZmYUqYi8l5gT8VadLjBUkNVSdyBjrNI4/JoZiHmJcwYYREooV7Kq6ECxFIZYspHQFLEk4VjgkQqQxibgdswib2dRlj0lDh2heGoUIYHzn2uMOzCYtBqqCjUjtP/R1gNdTXwE2CuiOwCPosuRuQAqpJZ+Ekh3kCBsMjG9YgjSJx4qij9RM511kc8lSWGD4BErFDvnk7EcIvuNELkhcU+wyxauodXWAQCAdra2pyOrMJQStHW1kYgEBjpphy5SCfArb+7wTOLCASbwOWFeOWERTneUFuAc0QkDLiUUpVNQHK4wWIUVSQsfCRR3kJmoRK64/dJhv2RCIEGW+CVzXU2ns7gyQmLCDAqv5mN4oaJcyCeRimVU0O1DDOzmDx5Mjt37qSlpWVYz3s0IhAIMHny5JFuxpELq1JlZP/BMYtAPQTqRtwbqgFd93oa4LFsF/aCSEc1cuUQq0MN1RlL4VUpMt4gCeVFrBxPtpco0t0FBcLC7jrbgxsdzJWMFbrwZW3JA2tcCbYn03TF0sRN2vLhZhZerzcXFe3AwWGNdAKCRlgcjOts3QTw1464gfsR4AVgDZAdYNsjE+3bwBcuHRmZqjZmkcTrTqJ8Wg3lThtamsx39JGeIqpqd51NZ3ArzSxSRZllM7bkgbWuJD3xNPu686Og4RYWDhwcMbCYBRxcUJ43bITFCKqhgIBS6ugO7bz3Qzqp3IU/6r2uigzc8VSGTCoFbnAbNZTLpO0Qm7CIFQsLm+tsLJlXQ6XihdekbMeodWnXWcu4LeIICwcODhrpBPhC2m5xMOk+fCHjETWy3lB3i8jHRGSCiDRZU8VaVI3o2Q+RPvTiqVjh7wiiywTkAbh9QRL4cBs1lDuV7+jj0aIXyvLxdmsDd0K0GiqXhNDAsnsoT5Cw8Yay7BXTR4WH3WbhwMERg3QcPAHwBA+SWYQqzizKERZJ4NvAcuAVM62oWIuqEckIJEoU+1GqqryhtHHbuLu6/aTEj8cwC3eqh4zS9qZEcTLBtC0oL53B4w8DhWonIMeeVM3YnOvsPsMs5k+qr15m8fpD8PB1I90KBw76hpVa3BsYnM0imzXMwqihKugNVY6w+BwwSyk1TSk13UxHT14HpbS+P1lCWKRimPCTqjBwW26zAHj8pFx5YeFJR2hD58hPRouuxVbPIpbM4A2E9OIiYSFGWEh4rA7KM8yiMeRlcmOQ1p4E2WpMW77hUVh9z0i3woGDvpFjFoHBeUNZKitvqOLeUOUIi7XorLNHJ5IRQJW2SdjZRLUwC8kLi7QlLJTCm47SijagpePFzCKudaUuF4l0Fn9Q18LIFqmhxIx4pHYcAaUjuPd1JRhXF2BMjZ9URtEZG2SVr+FArF0L8+zR6Z/h4DBAKm6YRWhwfYllM7WYRaJbD3ArgHIM3BlgtYg8SWE9i6PDddYSEiWFhbVMqiLrbDGzyLj9uLIKMkl8mQjtrnGgmnvXz04nwa3tFLFkBn+DVkOpomtyWdcbHoNfxelJZNjXFdfColbv39KToDHsq9xFHgxiB/RvKqI/KAcOqg0Ws/AGBicsrG/SsllkU/pY3uCQN7EcYfGgmY5OWOqnUmooqzMNNVVFPYtCYREg7TLFb1Ix/Nko7a4myEA2UdTWdBw8uoOPpzMEQ7pDzRYJC3c6QhbBFR6NPxsjkkqwtwuOm1CXFxbdCY4dV2Udcqxd/yZ6HGHhoDph2Sw8wcGpoXLMIgR+EzuV6B4ZYaGU+sWQn/VwghESKhlBsllw2TR3llQPjYaOvktWDhe642l8lsGwsFMAACAASURBVLBw+8i6TXqGRBcelaLLM0rzxGLBl0noUQ3a/TYY0mqo4hGOOx0ljp+Q1eGm4rSmYVx9oEBYVB0sYVFK4DtwMNJQqpBZDMZIbQ1SfTX54NpEN9SMHfJmlhPBvZWcFTePo8bIbbygBKWNSb5wfp3VmYZHQ+sGrRN3lWMGqgy64ynqPCbvkydAxhIWxu034mkgmyihMjN5aZRSxFNZ/CFzjUUjHE86SlwChLzaAB4mQUwFGF9XxcJCKRuzcDLVOKhCZFKAytssevaXv2/SroYyA8UKuc+Wo4Y6yfY/ALwPOHriLOy2imSkUFjk1FAmf1KxMBlmdMXS1Puymj14/HlmEWnVzfPUkJQAUlwtL62ZRSKtDcABn4e48uYM2hY8mShxCepRDBCSOKh6xtf7qfV78Htc1RdrkeiGrHEnroLASQcOesGW9RnPIF1nUzY1lDIOHBVynx1wGKyUarNNu5RS3wPeWpHWVCGUfTRaPDLNGXxNGpARNnJ3J1LUe80L4/GjPIXMIu2tIekK9i6tmk6AR7vNAgS9bhLizyUhtODLxIhLQL+YkKuaN7Y2gIgwptZffczCMm6Do4ZyUJ2wxTlpA/dgbBYWswhr11moGIMuRw21xDbrQjONo8ZKmIx1mbR6OleS177SUkOFjLAYYSN3dzzNTG8W4oC7t7DIesOk3QE8xQZuY7OIp7WwCHjdJPDjKhIW3kyUpCuYY09WIaTx9fo81Sks2vP/SwVWOnAw0ihgFsHBpfuwhIUvBG7TnVdIWJSjYP9f2/RN4ETg/QPtJCJ3ish+EXnNtqxJRP4mIpvMb6Nt3ZdEZLOIbBCRt9mWnygia8y6W6SoZF+lkYzmKV1nZ3vRyrwrKTDiwqIrnqY2Z7Mw0aAAPVpYKF8NGU8IbzZeGDxnbBYWswh4XSRdftxF9br92RhJV8imhkrgdQtNIe1JNaamCoVF1M4sHJuFgypEAbMYZLoPq8/x2r2hRk4NdZZtOlcp9TGl1IYyjn0XcF7Rsi8CTyilZgNPmHlE5Dh0Xe/5Zp8fiYhVz/M24EpgtpmKj1lRFAqLjsKV1oMKjyqcHyEUG7hxG/c5wyyUv5asN0SQBN32etnGZmGlGg963aQkn1fKgl/FSLqD+sVE17QYWxvA5dLye0ytf2htFtkM/PLd8MaTB38MO7NwbBYOqhE5ZuHXwiIdKz+wLscswnm38JEycItIqYyzncArSqnVfe2nlHpGRKYVLX43cKb5/wvgKeALZvlvlVIJYKuIbAZOEZFmoE4ptdy05ZfAhcCjA7V7qJC2VYvr7sUsjHAIGnv/cEZxt2+Df94Db/mCTvmKVkOFayxh4UN8hWoo8deivCHC0kZ3PEV90CjVMknw+HNqKL/XTdIVwJ0t7Pj92Tgpd6hADWWpoEALiwORJKlMFq97CLzCogdgy1MwZSnMPOvgjuGooRxUO+zMwlIdlxtYl4qCuHUGBhEdXDuCaqiTgI8Dk8x0JbrDv0NEPj/I841TSu0BML+WM/AkYIdtu5228+0ssbwkRORKEVkhIiuGqnpaxuZZEC1O7Z2K6odrSfThNHCvewie+iZ07cot6o6nCLsNY/AEEE8hs3AFahBfmBAJumJ2ZqFTDcRtBu60K4A3W8gsAipG2m2zWUiCcXX+3HrLfbatJzk01xjv1L+xQka3pzNGKlNm6g5LWLh9joHbQXWimFlA+QPPpEkiaGnnK5hMsBxhMQpYopS6Til1HVp4jAHOAC4donaUskOofpaXhFLqdqXUSUqpk8aMGTMkDVOJHrqUfoDxSGfhylRUq2SMWmZY1VBWB2p08qlMlngqS9hlmIXbj8un260sYeGvRXw1Wg0Vt+VwMuk+7AbuUsIiSJy0J1zALMbV2ZhFzRDHWljCIp4XFtFkmrd+52l+/8rOPnYqQqwdfLW6sIwTZ+GgGmE3cFvCotwo7lQk3/9ARZMJlhNncQxgHyqmgKlKqZiIDLZX2CciE5RSe0RkAmBFn+wEpti2mwzsNssnl1g+bFCJHlpUA3USI1FcByJpCQtrNDCMwsLqQM3IuTuumULQldaF212unLAg0kpM+Qj4/bgDYUKSoCtezCx8xJImzsLrIur247OroTI6lUjGkxeO586qJXxi/vHk80PFwWS4HZprzAuLtp4ksVSG5tYy7Q/RAxBqBJfHsVk4qE7YmYWnkFmkMlncIjm7YC9YzMJCBUurlsMsfgO8ICJfEZGvAM8B94hIGHh9kOd7CPiI+f8R4I+25R8QEb+ITEcbsl8yqqpuETnVeEH9u22fYYGkInRQQxo36VgJNZQvr8O3hEUineHpjUOjBusTORWNZhYWUwi60jm9p8sIMVEZeggQ8Lrx+GsIES9kFpbrbCqvhsp4gviUTViYjjbrDYHLDZ4gp0zyMX9iXiiMHgZmYWW1LduQHmuHYKN+Ro4aykE1ooBZGKZuhMW//t8z3Pb0G33va/VBFvx1I+oN9T/Ax4AOtGH740qprymlIkqpS/raT0TuQRdMmiMiO0XkcuAm4FwR2QSca+ZRSq0F7kMLn78AVyuljD6FTwA/BTYDbzCMxm3QmVYjKkDCFSRbXAwoVcQsjM3i4Vf38JE7X2LHgQoyjSI1lMUsApLKJQX0+ny5gkcRFSTodeMN1mibRdRGFo3rrF0NlXUH8FNKWBjB6Av3stEMecqPEjaLLiMsWsu1i+SERa1j4HZQncgZuG3MIh0nlcmytTXCc5tb+9432aMD8ixUkFn0q4YSERfwqlJqAbpCXtlQSl3cx6qz+9j+RuDGEstXAAsGc+6hhCcVIeYaS8odKqhjDdjUUJbNQo8G9pvOsqUnwZSmEBVBEbPoMkzBTyrHLHweN3F8hEkQIUDQ58YXqsUlimjUCD6lcq6zuTgLjxvlCRKwMYt0vBsPoHLCItRLrRPwuqnxe8rvyMu9Rhuz6LCERbkCKXYA6ifrj2owOXccOBgulLJZpKI5Fv3ark6UUpQMMUtG85HbMHLMQimVBf4pIsdU5OyHATyZKElXiIwnjDsdKfTCsSigy61d1owaqt2M2juiQ9RploLVgUYLbRY+0trzB+0CG0f/70EzC49fB9QlrPiRXBIzny03lAvlCeIniTIFg6yCScpSuflqSqp1RtX4OBCpnDdUZ45ZDFYNVbq9DhyMOOzMIics4rn+oyueZseBPryjLO2GhRH2hpoArBWRJ0TkIWuqSGuqEL5MlLRH2yXCJAo7KfuD8gZzwqIjoju09kgFq8ZZHajFLEwn6iOZZxZuV15YqCB+ryun30xa8SOZvI93LJlBRO+HN4hbFKlkwlyqyb5rCQtvqKRBvynsoy0yxGqoTCLH2ixh0RZJDlzCNZvVwiLUpNVmjhrKQTWiOJEgQDpGezTff7y2u7PEjvROblrBannleEN9dcjPerhAKfzZKGl/GPHXEJJ29nUlmFBvs1H4bDr8ImbRXlFmYV6eIpuFR+VtFn6vi7jygUCEAE1ed669yZjRa1o58N1+XcvC69Z014xwYrEefIFgvhSrYSbaZtHbu2hU2M/O9iGy1cRtH0isA7zBnLDIZBUdsRRN/VXlS3TpTJzBRt1Wh1k4qEYUp/sASMVptzH013Z1cv7CCb33LWYWgTpQGT248g2tCryc4kdPD+kZDydkknjIoHxhPMFawuxhV5fN/zkVyT9cbzBn8LX06h3RCjGLVCzPCGLFwiLPLPweNwkbswj63DljWDpuOnqb2148nSHg1VlWxLxoqVgEGseQMaVYXT5LWNQU5l0yGBX28c+dHb2WHxTswiLeAXUTCu5pa0+if2FhBeQFG7WwSUZGvOaIAwe9kI5r1bHLVWCz6Ejqd70h5OW13X2olopdZ5d8BOZflGcoQ4gBvxrjtvqyiPSISFJEMiJSGaVYtcGoLZQ3jC9YS5g4++yG1VSsSA2lVSUdlWYWBSNuy2aRIuh14zKpOwB8HhdxkyfXsllYow2r88+rofzEklkCHv1KiHlpk7GI2V4zC1fAEhahPm0W7eWoiMq8TmWlCDNqN0vdBmUYua305MEmw4jUiOfvcuCgF9L5SpX2dB9W/3HazNGsNUbuAijVm1mEmqBxakUGROUc8QfAxcAmIAhcYZYd+bA6Q38tvlAdYYmz32IW2awxcFs6fLsaqsLMwrJXBBsL1FC1AY8ZpWhh4fcYNRQQUQEtLMyLpSwVkkWBjetswKc7Z7ff2DaMwMyaX/cAaqimsI90VuW8sw4F2VgHu5XJu2UM+p2xlL5Oyoi1sDML6zk5qigH1QaTbgcoSPfRHk3hdQtLZzTRFkmyt6soqjsVA9SQq5v6QlniRym1GXArpTJKqZ+TTwZ4ZMN0LC5/DS5/DWFJsL/LdFBWznm7GioVRSk1fMyiaYbuRLNZuhOmE7UKv2MxC8sbKoDf686lF+8lLDwB4skMAY8RFuYFtNRVVoyJO9BbONphBea1DYFHVCbWwfaMSdsSywuLmWP0NQzooms8xbSB28rI6QgLB1WGPphFRzRJQ8jHgkk68HXNziIjdy7jbE1u0dbWCM9sbCGZLjN32iBQjrCIiogPWC0i3xKRa4GRqx06jMjmVC+14AsTIs7+LtNBWom+7EFqqRiRZIZURtPF9koxC8tttnG6NuDGOwyz8BYIC3+BsAgVqKFyHX1OWGhmEcwxC31dqbi+TpXsIaG8+KxMthazKKLGlg1hKNxnJdHFDjWm4Jo7YymOaQrhccnA7rN2ZmExIodZOKg22JmFiA7MS0VpjyZpDHmZN74Ol9DbbmFV6rSpoR5+dTf/fudLZIZCDVyEcoTFh812nwIi6BxOy4a8JVWC9972PP/xu38CEDOxCL5gbU56d3UZ6W6vUAXGwB3JeTC4XVK5OAtLDdU0w8y368JHOWZhGbjzwiImQbxuyb1Y/mxMp/ewuc7GU1kCXpeZNbYNK2o9GSGCX7vf5q5b9cqOOapGn6/tUOtapBN4MnF2qkJm0WE+oFE1vvJtFoGG/OjLERYOqg2peKFB2pRWbY+maAj5CPrczBpbw9pdxczCVn/bYFdHjFFhX27QN5QoJ93HNqVUXCnVpZT6qlLqc0YtdcRih3H9TPToh+MJ1uZ03j3d5oHlKlTZ1VCxnJ3imKbQMKihpuvf6AFd+Cjg1Z2/FZTncRNX2sCdcoe0S6zpNIMkdFqOnM3CT8ymhvIaZmEJC0lGiBLQMRhg63wL7RajwkOkhjKBRe3UECEE8Q6yWUV3Ik190MvoGn95zMJfr8tNWu111FAOqg12ZgG50qod0SQNpubMgon1vWMtcn1QXtGzqyPOpMYy6mAcBBwfwiJMaAiyp1Mbkqwss/5wfmSajHXpKO5k0YMyOnxLQEwfHSaeyuaS8w0p7GoogNgBuuNp6oK9mYXlOpvymHZ6fGTFQ0gS7OuKF0SP2g3cXotZJDVzEJMjK5BjFlbyxEJhYamhDrmmhRGIXSpEJ2GIaVWbUlCXExYDnCPWDsEG/d9RQzmoVthtFmCYhTZwN5qSxfMm1LGvK1EQe9FLuwHsao8ysd4RFsOCCfUB9nTGUUqRiuoOKxDOM4uQMiPyVBEF9AYLhMW0UXr7irCLeKcWTjWmdlSsne54qpfNwm7gTttGH8obIkxce1fYXGftBm5vwDKE6+t0pTSz8Jv1OT1pEbPweVzUBjyHbLPIGrVTt4Rpz4bIxtpzAXkNIV95zCJ6QBu34aDVUBv3dfPkeienlIMKophZeEOolGEWYc0spjRpAbCrw6b2tdffBpRS7OqIDT+zEJG7ze9nKnLmKsX4ugDJdJb2aIq0iUUI1tTnRqZhYqzY1t7rQeELQTZNV0Qvnz7GCItKpPyIdegRs+kI0z1txFNZan1uk27cMnC7c66zGU/eY0J8YYIk2NtZzCyyBH36lfAHdfuzKUtYRIkoPz5P/2oooLyOfAC0H9Ap3puaxtCpwqQj7XTEtACqD3oZXeujrSfZ2/fcDisvFOSZ0CDVULc8sYnP/HZV/+dx4OBQUMwsPAEyyRipjMoxi0kNup8pEBb2+ttoh5p4KsvEhuFnFieKyFTgMhFpFJEm+1SR1lQBJjboh7a7I0Ym1k1auagJhXOd47hghqfW788/qFxQnv7t6daqq+mGWVTEyB3vgEC91seLi2S3TmHc4DPucjZmETPMQtnc68QfpsaVLFRDmXQfFrOwhIVlwHanLWZhN3DTZ6zFQMzisbV7+01l3tKiR/MzpkykkzDZWEeOWdQHvYyp8ZPMZAuLOBUjdiBfH/0gmcXW1ghd8XTlPNscOOjFLIKkE3qQ1hjSzMJiC7va+2YW1rpJIyAsfoyuLTEXnZ7cPq2oSGuqAOONvm9vZ5xsopsIAWqC3pz0PmmCl6c2tpAt9kQwhu5oTxe1fg+ja3UnXZFOJt6pPXxcLgg0kO5pA6DOZ0a/JijP7RL+ppbyrdT7Sfoac7uLN0SjN8XerryBW7l9xFL5dB+BQICUcueEhScdJWJXQ+WC3Erlh/L1a7PojKW48u5X+OXy5j63OWCYxbzpU+hUYSTeWSAsrHiO/hiMsjMLt0cbDgeR618plavI19zmVNlzUCGUYBZW/9JgmEVjyEvQ6y5iFlYfpL9Fa92wCwul1C1KqXnAnUqpGUqp6bZpRkVaUwWYWK8f2p7OGCR76CGobQHmgSwaq/Xxu1t0B51nFnp9LNpNQ9ibo48FNgulINIKu1bmYwAOBpYaCiDURDai21LvNcZ02yhln2cCP8pcSNBnSwPmC1PvTrKvM2+zSIoXpci53HlNxlqxhEUmSlQF8mooywZiD8zLZuHuizg982K/3lDb2/Q+W/spjdrToa9p1pTJdBLGnehDWPTBTvZ2RFGxDv68KZZnd/6aQZVWbe1JEjE1Psou4+rAwWBRglko891Z/YgA0xtchcyiZ68uoezX9SxywmKkvKGUUp8QkeNF5FNmWlSRllQJRtX48biEPZ1xJNlDVAUI2SKf5zQKLoEtu/XI94UdMS784XNEjbonHu2hMeSjwdDHXEe1bTncdAx8eybccRaxb83jgW9fxdU/fZzn+6uEVQrxTq2GAq1mMfEEtd5CNRSQUxsFvTa/a59WQ+21qaHiWW/B9gAJfIiJVPdmYsQkgNuqBVwqfUbXTnjjCZZEn6U92nd+qG0HdMe7ra3vPE3x7gOkcTO6sYFOFcaTjdPVo/drCHlzzK0vj6j7n30VF4pVbW7eccuzvLKtfdClVe1sormftjpwcEhIJ/IV8sA4y2iPTEsNxerfcF/kMtrabck796+HUbM0a0arzgNeV36fIUY5iQSvAX4NjDXTr0Xk0xVpTRXA7RLG1QXY2xlHUlFirqAulm6ERYg4JxzTyK79uoO/9oGNrN7RQXOn7hiTsR4aQj78Hjchnzuvhnrj75DsYd3x/8knkp/hJc8SLor8lq/tvJyrfvokl931ciHF7A/xDq2GAgg14YprllLrtphFntJaaqOCIB1viLAk2NsVR6UTIG7iWem1XVz8SCYOXbvxZWO0yqj8MUqpoVo2ADA+voVMVuWYQDEsIbGtH9VOOtpB3F1D0O8h4dEjp1T3AXweFwGvu181VDyV4ZWVLwFwydvPQgSuunuFttsMwsBtMR+f29VvWx04GDRSMVN4jBJxFgHEZIO21FBsfZqabDfhjvX57fa/DmPn5WZ3tceY1BAsXVFvCFCO6+wVwFKl1JeVUl8GTkXX5D5iMaE+wO7OGJ50hKQYie/xacqXjHDWnDF0dXeRFB97zch2u+mDUvFITrI3hnx5NVTLOjIN0/jI6yfSPO5c/uWLf4b3380oOrhpaYIXtrTx9T+/PnDjshldp8HGLDyWsPD0ZhaW2igXHwHgCxNQMZLpLIlY1GSczZdUtZAUP+50HLa/AMBrnuMKjqE3sgsL/SI3RrbgJtOnKsrqeLvi6ZIOALFkBk+yk7RXCwllrjUVOUB9MH9vXVJaWPzpn7sZl2gGYMZxJ3LlGTNo7UmScg+OWWxri+BxCUumNjjMwsHQ4bX74Vsz4embtWo6UxxnEcKd0QNHS0PBHp1VYnLiDaLJtP7uOrYVCIvdnTEmNVYuqWA5wkIAe2RZxiw7YjGhIcjezjjedISk23bzTT6kM+eMJUSCnqyPq8+cRW3Aw9YOU340EclFXTaEvPnMs/vXsz4zidaeBDcvW4jX7YIZbwHgHaP28q7jJ/Ls5lbSmQESgFnR2zabhTell4XdxjPI3VsNFShSQ/myeuQSNcIins702i4pfv3S7niRpATY6raZqlxuqJsMrZvyy4ywcGeTTJO9fab82NYWxRr8lOqEt7T2UEc0JxDdIW2kzkbbc8LC7RKWhPYzacefC/ZVSvHz55o5Jdyi64XXTebYcTqJYLcKDE4N1RplcmOQWWNrHJuFg0NHJgWPfhF+f5kOZm1+trCkqgVvAE82Qa3fo/uJZARaNwJwnDSzuyOWY/G9mcXQ17GwUI6w+DnwoojcICI3AC8AP6tYi6oAVmCeNxPLRz6DKVnYw/yJdYzypUm5glxz9mxmj61hU7vu5CUZtXkwGGaRTqAObOHvB0Zx+enTWTTZdPSBeq1z3L2KM44dQ3c8zeodAxQOsqK3LTVUsBFvJoaPFCG3EUwlmEWBzcIbwmtGLvF41LjN6vZbcRYAKVcAdzYB25fTHJyHx1dUaGjiYti9Mj/fsgFCWlU1R3b06T67rS3KQpNJs5R6Z0tLhDqJ4AlrIeGt0b8q1pETxACfl7t5/46vQ09LbtnLze28vqeLU+takDHHgsuVExadGd+g1VDTRoeZNipMZyxV2ZrqDo58rLobXrwNln5CFynatzafvbrAGyqIW6UZFTLf4r61oLJkXT6Oc21jV0cc9q/T68ZoYRFPaSZfKU8oKM/A/V3go8ABoB34qFLqexVrURVgfF2ARDqLLxMh4ylmFj2ICGfOqGF0UyM+j4tZY2vYcMCMzCWRU0PlmEXrJkRleIPJfOacYwtPNvEE2L2K02aOxiXwzMYW+oXFLHJqKN2RjvdG8WR7C4u+DNyuTBwXWRLxWJ9qqJQrQG26HfauYZN/foHxG4BJS+DAFu3ZpZQWFnPOR4mbua7ttJYQFvFUhr1dcU6fNRrobeRev7eL37y4nTqiBGv1tQVqdKyExDtzzIKeFk5Mr8JFFjb+Jbf/L5c3Ux/0Mj7RDGPmAjruY0ytn5akt2xmoZRiW1uEaaPCTDUxM44qysEhYdtyqJ0Ab79Jf/eJrjwzL2IWAOODRstgVFCJmecxV3awu60bWtZpDYLJD2fZOysVkAfl17NYaVxpv6+UWlWx1lQJrMC8gIqTsaXJsBf8CZHI1XyYPbaWXRHJLW8MFzELo57Jjp5Ljb+oku3EE6BrF/WZAyye0sDTmwbwjMoVPsqroQAm+WMlKW2OWdgN3IaVjKKLVCJWqIaybZdx+Zmc3g4qy3rvcXm32Vzbl+jf3auhe49++SccD00zmSs7OFDCU2nHAd3hzhlfy/i6QE5YZLOKz/52Fed97x+8urODCYEk7pBuZ6heCxbiHXlhsfYB3GTpJgTrHwZ0ptu/rt3LB49vQLr3wJg5ufPOGVfLvri3bNfZlp4EkWSGaaNCTB+tn3O5qqgDkQEiy8vAHc9s4YaH1h7SMaoJW1p6eMct/9Au6UcpkjtWsME9W9eaGG+cSne+rH/tzGLcfACWugx72LMaQqPwzz+fgKSI7V2vmcWYY7U6GO0JBZWLsQAnN1RJjK8P4iZDUJKF9W3trpe2KnmzxtUQQ3fQQZIFgTSdsRTpfa+TVi7GTl/Q+2RWh7tnNW+ePYZXd3YUJgsrRi9moYXFBG80n+epwGZhIrLtzGLSiQCcFdpCOhHP5YWCQmaRcVsvsLDOMzcfkJdr+2L9u3uljRbPRcYdxzz3TtoivW0WzW1R/CQ5Y/X/4zrf/bS06kjtdXu7eHD1bi5ZegzPffGthLM9uWusbdCqLXeikzpLWLx6H/vDs/l9+gyyb/wdEj08sHIXqYzig9OjubZYOHZcLbuiLlSyp1cNjlJobtXHmDY6zOTGECLlBeat3N7OKTc+zp9f3TPgtn0hkc7ww6c28+sXt2lj5hGAR1/by9rdXTz++r6RbsrIINaBr2MLf2wZzx3/2KJtDeKyCQsbs5j+Fjqp5fTks3p+zz9hwvG4JhwPgHf/a9ptdkyhvQKqgFkcbZhYHyCE6ej8tfkVvtr8yNRW+3b22BoSeMkiRWooH0pBe/MatqlxLJ4+rvfJxi/UL82ulZxx7BiUgufe6IddFNssDLMY540WVL2zUFINNXExeEOc7t1AJqXLsOYN3PlXIm0dZ9x8OjLB3mqoYKOuqbFrZd7gNmYujJvPFPbl07nbsK0twsfdf6Kx+RHe1/Nrvr//Mlj+I5av3wnAp986mwZvVrsTGmExur6GHhWgXiLaO6TtDdi1gpqTPsgznqW4MgnU5se55+XtnDi1kSnZnaYtNmYxvobOjB9R2bLqcFuCYdqoMAGvm4n1wX7jQgAyWcVX/riWdFbx2CF0ik+ub6EjmiKVUaxoPoTgzSrC8+adfm5z2wi3ZGSgdmuFzKtqJrf+fRM7eoCmmbDzFb2BnVm4vTzBSSzseV6n6t+/TjP20bNJ4mV8x0od0zQ2Pxja3RHDJTC+fgQN3CISFhGX+X+siLxLRCoT9VElGFXjp96lvYVcBcLCxiySkVyKj4n1QYJeD3F8Wg1lMQuTMVJa1rFRTebEqfmUGzn4a2D0HNi9iuMn11MX8PRvtyhWQxlmMcYT7V8NZRcWbi9MOYXF2ddRKcMscgbu/HZZtxmlTFlKIp3tLSxAM6Pdq7WqLdgE4dE5Gh3q2NRr8549G/mk9yHUgmXct+Ru1mamwF+/xLJn38n/a3iK8TVurc6CnEAcU+unkzD1EtFqqDW/A4TQkn/j9LPeSbuqYe3f72FLS4SLTzlGt8UTgIapufMeO66WHsz10JDL5AAAIABJREFUlGHkbm7VbrOTTTTs1FGhfiPOAe59eQdrdnUyqSHIs5taDrpa2R9W7WR0jQ+vW3j+jd6dazarWNF8oM+gx5FGOpPlqQ37c+1LpDM5obd8S1tueTyV4Z6XtuuU/0c42jZq9/Olp52NS4Sv/ul1PVDs3K43sAmLdCbLH5OnEMhGYPkPIZvWwsLtZV9gBktj/9Abjs27su/siDG+LqC9pyqEco78DBAQkUnAE2hj910Va1EVwO0SjqnRL7A7kE/Al7NZtG7SrmymU3S5hFlja4gqP0ES1NuYhZ8kjYld7PFNY0JfeeaNkdvjEk6fPZqnN7b0nfMo3gkuD0kJ8Mq2djrQ7Zui9uQ9kzy91VB2LycApp7G5NQWajMH+jRwK+sFPuZUkulsb5sFaCN3105o/odmFSK5l7gpskmPjO65WLsMHtjKW7d8m4x4kLd9g+DUk/hQ6r/Y/PZ72JwZy6fit8Mz3+mlahtd46dLhaknQn3ADa/eB9NOh/pJfPi0WbzoPYUprc/QGIB3LJygWc7o2Tl9LsDscbVElLmeMozczW0RJjcG8ZiPb9rocL+BeR3RJN/+63pOmd7E58+bQ3s0xZriymZloCOa5O/r9/PuxZM4YUojy+0sM9EDXbu587mtvPfHy/nVi9sGffzhwG1PvcGlP3+ZR17TqrjV2ztIpLO8Y+EEOmMpXt+jBwO/XN7Mlx5Yw5/+uXsEWzs86N7yIluz47jotAV89pzZPL5uHxtlWn4D2zfbEUvxXHa+DkZd/gO90KigOurmUId5f8cUMotKqqCgzDgLpVQUuAi4VSn1HuC4AfY57DElJyyKmEWiR0t7tx9Oujy3avbYGnpUkGmu/dQaI3ZjyMcM2YObbAFl7IVJSyCyH7p2ccGiiezrSnDKjY/z/h8v55VtBwq3NdHbtz65mWW3Pc/ibz5LTPk4t/1eWHEnjD42r6LCHpRXZG+Y+i+4UExnNxmXj037u/G6hZDfxiwsT7ApS0mkM71tFpC3uRzYkr/GhqkkXEEmxt8gc//HYONf4eU74JYTWBRfwcOjL4fa8UwdpY9/995jeF/ielonvAVe+bnOnwU5YTGqxkcnYeokwqJtd8GBN+DES3PXN2HpMuolymdm7tPMqGV9wYcEUOP3EKzRQX5lCYvWKNNG5+1VMxtczIqtobOztAD4v79tpCue5qvvms+bZ49BBvJsU0rrog9sgUzeLvHnV/eQyiguWjKJN80cxZpd+ZxY3HsJfHce//r42/iG56c89Pzakob0zmiqV4xLOpPNM51Iq87jVQFsbY1w65O6kOY9L+lR8/ItbYjAZ8+ZreffaEMpxT0v7SjYrlrR0p3gXT94lm//df3AG/eBurY1NPvnMKkhyEdPm85xE+r43hqbK7qNWXREk6TxsHfi2fpd9dfnCp0lx+gBatYTLGDOlaxjYaEsYSEibwIuAR42yzz9bH9EYHJIf0y+kF1Y1Gi/6H/eA8d/AGrG5FbNGlfDfZm3cLprDbLlSUAbuGeL1p83Tju+75NNPEH/rv0Db9/2LV6fcjO3LtzC9rYI19yzurDaXryTTKCeu55r5s2zR/Olt8/l8XGXsWvhJ+FjT8LVL+loc4OSNguASSeScZn8VUkXv39lJ+8/aUqBQNg4/ny+lLoCVT+lbzXUhEXa5gL5Dtrloj08k/dk/4Z701/4gf9ynrvgKbKnXcvvMmfSPONiAKY26c74gZW78LhchE+7Cnr26fsLOWHh97iJumqYJ9uZueb/YP5FsCBfBn7RW95DwtfIh3p+rtV0HdsL7BUWmhpNunKbGiqTVdz9wjZd28NAKUWzcZtl72vwwJV85Llz+J3/a/h/fnbePmPQ3Brh1y9u5wMnT2HehDqawj4WTqpnzbp18Nz34d4PwS1L4IErYeNjsO5P8JMz9HTLCXDjOPj1+yHexQMrdzJnXC3HTajjX2aOIqvgxS1t0PwcbHmKp71vZotrKv/mfZqL2u9g5fZCm8aq7e2c/d2nueDWZ4kc2AN/vJrsuke49M6XeOd3HqXrt1fp/GTfXwSPXY/au4YVzQf47mMbDjqOxBJYSimuf/A1proPcO/k37Nx82aaWyM8/0Yb8yfWMXtcLTPHhHl9wzpWrN3A1tYIx0+u5+Xmdjbt6zsbcHskyT82tRy8h1nxfuv+BD89Bw5sHXDX9kiSD/30RV7d2clPnt5S0iMumkzz/Butfbavu3UHo7KtZM3Ayut2ccdHTmKrd2Zum+e2dfNvP1nOj57anEsR1DXjnXrlhEVYUayeibofidbP0lmn0RkLdhyIMXusTQtSAZQjLD4DfAn4g1JqrYjMAJ6saKuqABMC+sPxh+rzC63SnOk4vOlTBdvPHlvLzzLns1vGa5VLRhdbP9a1k5RyM2tuP8Ji3HxweeCx/4ZVvyKU6eEdG/+bxxq+QbBzE794vjm/bayDllSA7kSaL719Hle9ZSYXfPJmJi37pmYoRXlhSkZwA3iD9IzSbfrnHu1J8cmzZhVsouqP4Z7MW/nr6/t13EkpYeEL54WErYMePfME/JJmzdh38QfP+Xz8wd28MP1q/iN1JceM1iP8+pCXhpCX7kSaJcc0EjzuPB0VXiQsAJLeOuokSqpuKlzw/YLrFF8Y/3tuxbPvVfjDVaYtvZnc2NHaBTdt6nsD3Pr3TVz/4Gv/n73zDpOrKh//552+NdtSNmWzSQgJgfQACV2KgFRFEaR+UZFiQWwgSvkpgiBKV1F6RwQFpCWhBAIhFdLLpm+ym+19p5/fH/fe2ZmtM5tMdiacz/PMMzNn7p05Z2buec9bDz94eqkR0ojhhG3zhzhGPodHvwob36bloHO4IfA9vI1VBP56HBVv3WVM4K213DN3I067jZ+YK2eAU8e4+E31z2DuzQQrVrE2MJTQ+rfguW8ZwsPfQv2JfyR89oNw5FWweT5Nj5zOlh07OX/KIGTJP5lZ+zoep41PNteiPryTZkcBVzZ/l9D5zxKe9X2+bf+A9z7suBT/t7KCCx5ZhNMuVDa1Ufn4JbDiGWwvXsjPdl7L31qvI3v9i+wafxENOeMJffow8rdjcDx2Ens+/Ae/eHF57ITXzeTnC4bYWtPKgo3V/HnuRs558GPG3/QWZz/4Mde9+DmflVXyXN7DHFnzCg+6HuCphWV8vqOBOWONiLbTRwW5ufwHHPTqGYzxtPLwxTNx2oXnutEulm6r4+pnlnHEH+ZxyaOLufudDV2O6Y4mb4D752/iv5/vgk8fhjtHw6K/GePZNA/+9X9GFNLLV6CCvi6+H6UUVc1ePt5Uw6WPLWZrbSv3fnsaTruNe+ZujDk2FFZc8+xyvvOPz3hhyc5u+7N+6QIAhk86OtI2Ii+Duy77KnXKWIze/L8y1lU0cdfbG7jrbVODGXMc5Aw3TK4muaVGBGJtplFN4ZPNNfzspS84vDSf7x2b3GLgfWoISqkFGH4L6/kW4MfJ7FR3iMhpwH2AHfinUurOpH1Y/TZOLb+fJpWBo3BMR7sVRjv+VCPGOYqDhmTjw8VTg37ADTW3weJ/kHvkVUywlbOdYUwcWdTz5zkz4PgbDCF0xJWGk3jFM+TOv43/Zvw/fvC+j2/NuoqCLBeh9gY2Nzs4+ZAhTBqe2+dQetQsgOCoOVC9lD1t8K1Zo7rEaH9z5kjeWlXBVc8sQ4TuzVBgmKKq1sZM0I4ZF4PDyeTT7uSJphBfu/8jrnnO8KmUFHSYd0YXZNLQ1sgx44sMH8PMy+D9240Xo4RFq3sYXr+TtrMfpcDTzbgPOQumXtghaLoRFiOGDIY1UF1bRzGwaEst98/fxNSRg/iivJE731rPd44s4Zpnl3J13mJOWvGgEZ548cvkZg0lb9AGfrj+WH5YfyezP7sdPjPe9/jQcUyYczNDckxTQjjERbt/Tya1vHn4E9yzPp/N1a0UehSvfNXLyEEu/ri1lEfe3MnssQXc/c3zqHdOYcKH1/JO5m8Z8lkb+FtwAHfmf4cPN0xBWhdwb+AiLj5mAicdMhRG/4q25c8yp+wv1LWcyeOfbOOB98qYOTqfRy6ZyYpnfsO4yiWsmXYLLy6v4MfOV8nLdPGL8O38e1UpAPmcz9UFyzjf9j5/bPkH725ZzpMLHuLy4ybC4kfggzvgmJ/CnB8RUvDx83cycdMjvBo8ib+FziIoTqaNyuOSOaNZvauR/62s4C/5rzC4cTVMu5gjP3+GFUvuxh+6kKPGFUHAy/crbsFGEEfQxxM5DzIi+1xOPXQYryzfxa9Om4jHaUcpxROfbON3b6wlP9PFpXNKqW/z8/AHmynOy+CS2R3mF0IBWPtfcGXTXnoSLy3bxX3zN1HX6uf/7G9xjvNpVM5w5O1fGRrFrmVG2OoRV8JrP+T5O77HnaGLmVaSz9iiLDZXt7B2d1OkrpnLYeNvF8/gxIlDKatq4cH3y/jBcWM5zKxAcN+8jXywoZqR+Rnc+toapo3K45BhOUb9px2L4Ijv01C2iCA2xk89Kub/OHlUHnXDJsOeT7jx7Okcf8RMbv7v6oh5Li8nG360NMZEVTxkCL8LXEx1w0xc//qCd1ZXMrowk39eenjXBeE+pk9hISIHAz8HSqOPV0qdmLxudemDHXgIOAUoB5aIyGtKqTgq7yVITRk8eRYZqo3/c9zKfcXFHa9lmWano7oW3R2Vn4HLYWNz/rFQdDLM/S0y/zZOsXn5xHMcB/UVpXD8L2Kfz7wMxn0F5+Nn8UjD7/n3SzZOPv4EMmsrqAuVcG0nLaAnrPyKmKQ8E8+4Y2H5AwTFyTUnjOvyelG2mxd/MIebXl3Nv5eXk+Xu4c8441JjE6jsqNDgktnGDRhVAH88bwrXPGsIi9Kijqz40YVZfFFuCguA6ZfAB3eCCsUIi0+KL+VPNbP5YPS0ngd7+h9h60eGKSt/TJeXRxUbv9+uRS9T1p7NHZ/5OSWvkftOULz4eS3Pf7ID34oKnucNDvVuNlZ2334GPIOwATecPhFOn0hD6+n8+sW5lJet5CTXGi6yv4lt7UVQ9AsYNAq2fEDerg/5f/J9HvvIRabLy30XTOOutzdw9lwXE4fl8NnWnZx66FAWltVy2r0LCIRzOS//Nm6Xh5HSE+Hw78GKpzh3+VMcq16nmlwC0y/n1q+ZsfWZBTQecT3HfHobt917O5+0FvPTSflcPduDa90znLTnn7wtx3LVooPJdE3i+1f/lqI8D7cEhUlLyxmR52FWaQFF2ReCUqjP/s7Jb9/A0vmXs3vzeIbveB1f9kjcc2+mbu0HbKrxcbxvIXtcI7leXubqwmWoI68ms8gGGXaY0IJ/1xpcH/7H0JRO/yO7WkJcVfY8jWQz25YJ/3uZQfWruTJ4PR7l5/6WB+F/1/PDYbMZvGYRy595j6G5HsqqWqgpb+TPw7L52rQSXJnbCTkyOai6gg9fX46UDcftsFHgK+eIimfJ8RqO9F1qJGXBk7m2KJuzD25m8LqneSt0OM/l3MLFhQs4acd9NLmLeaX0HhatEo4LnsKlvMawIXksrhnC1q0OZuc28f28WrJHF5AxahojR48jp/4teG0ZP8ZFc4aTF16p5NyZpexp8jL3w+1cO3kU3z1mGD976gNeenI5P895l6zqzwljQy15lOkqmz2eMYzwdDUTFYydAXs+4eTJo8Fu4/ZzJ+N22PnP57sYnOOGTgLA47TTPP1K1u1ooG1zLaVFWfz9kpmRoJpkIn3ZAUXkC4xd85YRVVBQKbUsuV2L6cMc4Fal1Knm8xvNPtzR0zmzZs1SS5cmuKFf0A8PzjLi8C/5DwzrlEQXChor6OLut/S48ZVVHDo8l4snAB//Bdw5LK0SghPPYvaswxPri0VLFRUPnk6xtyzS9E72uZz68yfjOv3pT7dx2+tr+fyWr3bJHlfeJkJ3lvLpkAs59pqHenwPpRTvra9i8ohBDMntfxz3ra+t4c1VFSy68SSj7LvZv0c/3sq864+PRB7xwkVQNg9uqoyYm/70zgaeX7yDZb89pfcPqVxtOLgnf7PLSwG/j833nMTB3tXYpOf/vTd3LJ5jr4Xpl8b4f6IJhxUPvV/Gn+dt5P7jhbO2/B6qojKup1/CT9quYN66Kp644ggOLy1gZ10bFzyyiOpmH78791C+fXgJ5fVt3PTqalp8QR69bFZHSWrjQ6h7+ScUrH2K14dezRk/uCPyvQEQ9LPrjqmMCHUTTVQ0gXePepYrX9rI7845lEvmlPb+vQGty17E9fo12FWIPwe/yUOhc7jUPpebHM8gwLpDr2fyN29EtnwAb/7ccM53ZtRsuOx1cLgI+dtZe8fxTFZR5qNjf8Y3NpyEx2nnudFvwCcP9Nmv3lgePogHgl9nsNPHTz1vUOyL6tNh5/Fs8Y38af5WWn0hBoVqacNDKxlkuuz89IQSvrvtemw7Po19U4fHDEOP+o9k5BtaTBzBERWqgHuC32KxfQa35r7GV1rexD/ju7jPvqfrwbtXGH6tb/wzsi8FGAEJjiSGwfaGiCxTSs3q0h6HsFimlJqZtJ7FgYh8EzhNKfU98/klGGXTf9jpuCuBKwFKSkpmbt/ej9DCLR8YdsJOZqaBxNdaz+r3XyYYDBK2ORh35BkMGTo8rnPb/EE2VDYzvaSbHA+gZd17eIon4MgbsS+73C1KKfyhcBdzllIqtgZ/U4VR+2Zch/La6gtS2+KnpHDvSzD7m+vY9cU8PO2VFI8aZ2hEQS/tDVU0qUyGTv1qxHnYF/WtfqO8SzhkONbb64yJZtSRtAYU3kCIwuyOsMi6Vj9N7YGYSKteUYqq9Z9QdPBsbPauml3tjvWEd3zG4PxBxiTnyTWi4QrGgtNDdbPPWKHGSeOmT9hUUU/jYGOusNuE3KYyRhdlUDhmeseB4RA0VxpaXHud8ZmZBTCoJGbS27KnEXfrbkZQZUy2475CozeMzQY5LjvsWgrODKqkkO0tdlwOG/kZro7fOeQ3AhL8Lcb3GmyPRHIpZwZteRNo9AYpyHLhcdgMAebKNib3ToI+FFaEzfnOJtKxkZe3CZp2G5GGeSWQPcxYMFathaZdRmmOgrGGz6NuCxVb19DmCxAMhRlT4MZFwPg+MgtYVi1UeMZyyKghlBZmGZ/RWG70xxXnbz7AJCwsRMQMHeHHQBXwKhCJx1NK1XV3XjIQkW8Bp3YSFkcopXrchKlfmoVGo9F8yelJWPTms1iGoYdZS75oo7oC9uc+3OXAqKjnI4EDP5NHo9FoUoQehYVSagyAiHiUUt7o10QkeQVIumcJMF5ExgC7gAuA7+znPmg0Gs2Xlnh8FsuVUjP6aks2IvI14F6M0NnHlFK393F8NdDfeghFQB+1wtMCPY7UQo8jdTgQxgDJGcdopdTgzo09ahYiMgwYAWSIyHQ6zFG5QPI2eu0BpdSbwJsJHN9lsPEiIku7s9mlG3ocqYUeR+pwIIwB9u84evNZnApcjuEf+HNUezPw6yT2SaPRaDQpRm8+iyeBJ0XkPKXUv/djnzQajUaTYsRTEHC0iFzfqa0RWKaU+jwJfUoFHhnoDuwj9DhSCz2O1OFAGAPsx3HE4+B+DpgFvG42nYERnTQR+JdS6q6k9lCj0Wg0A048wuId4DylVIv5PBt4Gfg6hnZxwO9todFoNF924qlpUAJEF7oPYIRWtROV0a3RaDSaA5d4hMVzwCIRuUVEbgEWAs+LSBaw76u+DiAicpqIbBCRMhG5YaD7Ey8iMkpE3heRdSKyRkR+YrYXiMhcEdlk3ndfICrFEBG7iKwQkTfM52k3DhHJE5GXRWS9+bvMSdNx/NT8T60WkedFxJMO4xCRx0SkSkRWR7X12G8RudG87jeIyKkD0+uu9DCOu83/1UoReVVE8qJeS9o4+hQWSqnfYRTna8BwbF+llPp/SqlWpdRF+7IzA0lUGfTTMbaNvVBE0sXEFgR+ppQ6BJgNXGv2/QZgvlJqPMb+6ekiAH8CrIt6no7juA94Wyk1EZiKMZ60GoeIjMCoDTdLKXUYRkLsBaTHOJ4ATuvU1m2/zWvlAuBQ85yHzfkgFXiCruOYCxymlJoCbMTYnC7541BK9XnD+JMMxzBJlQAl8ZyXTjdgDvBO1PMbgRsHul/9HMt/Mfb+2AAUm23FwIaB7lscfR+JcSGfCLxhtqXVODASV7di+gSj2tNtHCOAnUABRuTkG8BX02UcGHvwrO7r++98rQPvAHMGuv89jaPTa18Hnt0f4+hTsxCRHwF7MKTZGxj7cL/R13lpiHVhWJSbbWmFiJQC0zH2cRuqlKoAMO+HDFzP4uZe4JdAOKot3cYxFqgGHjfNaf80zbZpNQ6l1C7gT8AOoAJoVEq9S5qNI4qe+p3O1/4VwFvm46SOI949uCcopQ5VSk1RSk1WhvpzoCHdtPVzh/iBwYxU+zdwnVKqqa/jUw0ROROoUvtxY60k4QBmAH9VSk0HWklNU02vmDb9c4AxGJaFLBG5eGB7lRTS8toXkZswTNDPWk3dHLbPxhGPsNiJ4as40EnrMugi4sQQFM8qpV4xm/eISLH5ejHGviSpzNHA2SKyDXgBOFFEniH9xlEOlCulzF26eRlDeKTbOE4GtiqlqpVSAeAV4CjSbxwWPfU77a59EbkMOBO4SJk2J5I8jniExRbgA9PLfr1121cdSCEiZdBFxIXhKHptgPsUFyIiwKPAOqVUdB2v14DLzMeXYfgyUhal1I1KqZFKqVKM7/89pdTFpN84KoGdIjLBbDoJI3IwrcaBYX6aLSKZ5n/sJAxHfbqNw6Knfr8GXCAibjG2QRgPLB6A/sWFiJwG/Ao4WynVFvVSUscRT7mPHebNZd4OSJRSQRH5IYZTyCqDvqaP01KFo4FLgFUiYpVg+TVwJ/CSiHwX4zf81gD1b29Jx3H8CHjWXHhsAf4PY3GWNuNQSn0mIi8DyzHMHSswyktkk+LjEJHngROAIhEpB26hh/+RUmqNiLyEIdCDwLVKqdCAdLwTPYzjRsANzDVkOIuUUlclexx9ZnBHdTpLKdW6rz5Yo9FoNOlDPNFQc0RkLWbcu4hMFZGHk94zjUaj0aQM8fgs7sXY26IWQCn1BXBcMjul0Wg0mtQiHmGBUmpnp6aUsOdpNBqNZv8Qj4N7p4gcBSjTWfdjYksxpCRFRUWqtLR0oLuh0Wg0acWyZctqVCJ7cEdxFUadmxEYcbzvAtfs2+7te0pLS1m6dOlAd0Oj0WjSChHZ3l17n8JCKVUDxBQMFJHrMHwZGo1Go/kSEJfPohv6TMqTfpTN7qm8rojMFJFV5mv3mwlCmn2INxBiW42OjNZoNN3TX2ERz2SdUNnsPsrr/hWjTPp489a5ZK9mL/nX0p2cdt8CvAEdu6DRaLrSX2HRZyafUqpCKbXcfNyM4RQfgVGY7EnzsCeBc83H5wAvKKV8SqmtQBlwhFnDJVcp9alZA+WpqHM0+4jaVj/eQFgLC41G0y09+ixEpJnuhYIAGYl8SG9ls0UkukzwoqjTrPK6AfNx5/buPudKDA2EkpKSRLr4pccfDMfcazQaTTQ9CgulVM6++IDOZbN7cTf0VF437rK7SqlHMGrXMGvWrJQvMZxKWELCp4WFRqPphv6aoeIiwbLZPZXXLTcfd27X7EP8IS0sNJqBpLrZl9Jm4KQJi36Uze62vK5psmoWkdnme15K+pREThu0GUqjGVi+8deFPPzB5oHuRo/Ek5TXXxIqm91Hed2rMTYuz8DYQtDaRlCzj4gIi5AWFhrNQFDd7KO62TvQ3eiRpAkLpdTH9Bxie1IP59wO3N5N+1LgsH3XO01nfJYZKoXVYI3mQEUphS8YxhdI3cVaUn0WmvRBaxYazcARCCmUAm8wdRdrWlhogA7HtvZZaDT7H58pJLRmoUl5/NafVQsLjWa/Yy3S+qtZrK9sorE9sC+71AUtLDSAjobSaAYSa5Hm7admcf7fPuXRj7fuyy51QQsLDdDhq9DCQqPZ//giSbGJaxahsKLJG6Sxzb+vuxWDFhYaIDqDO3UdbBrNgYp13fVHs2gP7B8TshYWGkCX+9BoBpK9Way1+YMASc/+1sJCA+jQWY1mINkbn4XXv3f+jnjRwkIDRNlMUzh0T6M5ULGuu/5oB20BU7NIsglZCwsNoDULjWYg8e1F6Hq7f//kaGhhoQE6yn3oaCiNZv8THboeDie2u4IlLLRmoUk6SimdZ6HRDCDRGkWi2r0VDZUSPgsRuUtEckXEKSLzRaRGRC5Oas80+41AqGMlo0NnNZr9T/R1l6jfIhI6myLRUF9VSjUBZ2JsRnQw8Iuk9UqzX4leyWjNQqPZ/0RrFolqCG3+1MqzcJr3XwOeV0rVJak/mgHAvxcqsEaj2Xuir8FEtXtvxAyVGprF6yKyHpgFzBeRwUDq7tKhSYjoP2d/Iir8wTDVzb592SWN5kvFvtAsUkJYKKVuAOYAs5RSAaANOCeZHdPsP/ZWs3hm0XZOuucDQglGcWg0GoNof0OimkVHNFQKmKFEJBO4Fvir2TQcQ8vQHADEqsCJ/+HK69tp8gZpNcsOaDSaxNgbzcJycIfCimASzcjxmqEeB/zAUebzcuD3SemRZr/j20th0eQ16ui3+rSw0Gj6Q6yw6J9mAcnVLuIVFuOUUncBAQClVDs976+tSTMs05PTLv2KhmoyN11p8WphodH0h71ZsLX5+x92mwjxCgu/iGQACkBExgHao3mAYAmIHI8zsmNeIliaRbPWLDSafrE3eRbeGH9H8jQLR5zH3QK8DYwSkWeBo4HLk9Upzf6lQ1g4+vVnazY1Cm2G0mj6hy8YxmW34Q+F+6FZdFx3ydQs4hIWSqm5IrIcmI1hfvqJUqomab3S7FcsYZHtdvQrBNbSLLQZSqPpH/5gmNwMJzUtvn5ncEMKmKFE5OtAUCn1P6XUG0BQRM5NWq80+xVflGbRn9DZpnZDSGgzlEbTP3zBMLkZxtq9Pw5um+lBTmZ9qHh9FrfqbyC6AAAgAElEQVQopRqtJ0qpBgzTlOYAwB8y/pzZbmfCSXnhsKJZR0NpNHuFLxBiUIZRKCNRM1R7IERepss8d+Ad3N0dF6+/44BmXUUTX394YVpPlP690Cxa/UGsXDxthtJo+oc/FCbb7UAk8YKAbf4QeZagSQHNYqmI/FlExonIWBH5C7Asab1KIz7f2cCKHQ2U17cPdFf6TbSwSDSxpylKQLSkscDUaAYSXyCM22HH7bAlrFl4AyHys1yRx8kiXmHxI4ykvBeBf2HUhbo2WZ1KJyyNIp0nSl+UgxsSK/lh5VhAen8HGs1A4guGcDtseJz2hCf8Nn+I/ExDs0jmBkjxRkO1AjckrRdpTKvP+HHa0rjUhSUccjzGH84fDGOaQPtECwuNZu/xBcO4HTbcDltCTmqlVKzPIolmqLiEhYgcDPwcKI0+Ryl1YnK6lT5Y9ZAOBJ9FtscR8zweLDOUTbTPQqPpL/5gGLfT0CwScVL7gmGUokOzGOg8CwzT09+AfwJ6K7UorNW0pWGkI75gGKddcDtskefxYmkWQ3M9OnRWo+knhmZhx+OwJ6RZWHWhIj6LFMjgDiql/tr3YV8+2ixhkc5mKDN7tD/CwgqbLR7kSWvtSqMZSHzBEC6HDbfTlpBm0WZqEnkZyTdDJbL50TUiUiwiBdYtab1KI1pMjSKdNQt/MGz8UU1h0R8zVHFehvZZaDT9QCkV8Vn0V7PIcttx2mXgHdzAZeZ99L7bChi7b7uTfrT6DgyfhcthwxXRLOL/wzW1B8hy2cnLcGqfhUbTD4JhhVIYDm6nLaFFl+WjyHQ5TEEz8NFQY5LWgzTHioJKazNUyNIs7MbzhDSLADkeJ9luh9YsNJp+YJl9jTwLO7Ut/rjPtcqTZzjtuJ2JaSWJEvdOeSLyGxF5xHw+XkTO7OOcx0SkSkRWR7UViMhcEdlk3udHvXajiJSJyAYROTWqfaaIrDJfu19EUmofDWuCbEsBM9SKHfV878mlCe+W5Teda5ZmkVieRZDcDAfZbqNibX/2w9BovsxYGdsuhw2P05aQKckqIpjhspkJfQOflNefnfKeAE7r1HYDMF8pNR6Ybz5HRCYBFwCHmuc8LCJ285y/AlcC481b5/ccUCxfRUsKaBafbqll3ro91CSwMoGO8sguu2mGSmB10uQNkOtxRsJu09kcp9EMBB2ahaHdJ3L9tZvzTobTgcdpSwkHd8I75SmlFgB1nZrPAZ40Hz8JnBvV/oJSyqeU2gqUAUeISDGQq5T6VCmlgKeizkkJLPNTWwpMktZEbZUMj5foSAxIULPwBsjNcJJlZn9rU5RGkxiWNm7kWSSmHXRoFvZ+ZX8nwv7eKW+oUqoCwLwfYraPAHZGHVduto0wH3du7xYRuVJElorI0urq6n50LzGUUlEO7oE3Q1kO5uis6niIOLjt/YiGag+S63GQo4WFRtMvOvssEvE7WD6LTEtYpIAZqvNOefOBX+7DfnSnpahe2rtFKfWIUmqWUmrW4MGD91nnesIbCEcqrqaCg9tKimtOMCrJHzLC9voVDWVqFpYZSgsLjSYxrOvNZe+HZmEKC4/TLEI4kOU+TIfyeuAb7P1OeXtEpFgpVWGamKrM9nJgVNRxI4HdZvvIbtpTgmgBkQq2+ohmkaAZyh8M48pMPBpKKUWzN0iuR5uhNJr+4osyQ7kddgIhRSissNv6juVp76RZJHrtJ0KfmoXpK/iPUqrW2ilvL7ZUfY2OnI3LgP9GtV8gIm4RGYPhyF5smqqaRWS2KbQujTpnwLEEhMtho9U/8GYoS3j12wyVYAZ3mz9EKKzIzYgyQ6VgroU/GI5kmms0qYY/ygzlcSam3bcHQjhsgtPUSgY8dBZYJCKHJ/LGIvI88CkwQUTKReS7wJ3AKSKyCTjFfI5Sag3wErAWw9x1rVLK+rauxqhJVQZsBt5KpB/JxFpFD811p4SDu0OzSNwMFZ3BHa+wsFYx0dFQqahZPPR+Gec8uHCgu6HRdIslGKwS5RD/9qht/hAZLuMcjyOxIoSJEm8G91eAq0RkG9CKYYpSSqkpPZ2glLqwh5dO6uH424Hbu2lfChwWZz/3K5ZzaUiOh5117YTDClscqmOysHwW/dEs3P1wcFt7b+dmOCN7YaSCOa4z22tb2VHXhlKKFEvT0WgifoboBVu8UU3eQIgMU8C4U0SzOB2jtMeJwFnAmeb9lxprFT0kxw10hLGt3d3Et/72SVL3uNhS3cJtr68hHO7w9/dbszDNUDab4LRL3KGzlmaR43GQ5TKERaLO9f1BY3uAYFhFfh+NJpWIzrOwNItETMGZpmbhTnK5j7iEhVJqO4YD+kTzcVu85x7ItHYSFtbzxVtrWbKtnh11bUn77Llr9/D4wm1UNnm79CfxPIswLrvxh3PZbQloFh1mKJtNyHLZU9IMZQnPxgQ1Lo1mf9CRZ2FPWLNoD4QiAsbjTCyhL1HiLfdxC/Ar4EazyQk8k6xOpQtWiY8huR6AiJO7vs2YlBrbkjc5WROfdR8Kq8jn99fBDcYfNl67Z8RnYW4Wn+1xJN0MFQorrn1uOct31Md9jvUdWWYzjSaViA2djdUsrnp6Gf9ZsavHc9ujfBZuhw1/KBxjbdiXxKsdfB04G8NfgVJqN5CTlB6lEdYqenAnzaK+zSi3kcyVbGdhER3Gm4gZSikVcXBDopqF6bMwndtZbkfSN0CqbfHxv5UVLNgYf9KlJTyTGVao0fSXmNBZZ4dm4Q+GeXtNJQvLeg4+bQ90mKESNWElStwZ3GYIrZXBnZWU3qQZPZmh6loNYdGwH4VFdMhqcwKfa/knLPXX5UjcDGXt3Z3jdiQ9dLbOFMT1rfHXv+rQLLSw0KQenWtDgSEsqluMIhk1LT0Xy2jzdzi4Pc7ETFiJEq+weElE/g7kicj3gXnAP5LSozSixR/E5bAxyDTDWKv7hrbkT05dhIUpqAZlOBPSLCzBYEVCGZUr43dwZzg7qtVme5Jfpry+1RhvXZwmPm8gFBmP1iw0qYgv6hrsyLMIU2X6I2t7WRh5AyEyzOCSSNhtksJnew2dFRG3WdzvTyJyCtAETABuVkrNTUqP0og2X4hstyOSvWzVh7I0i/1ihmqLFRbFgzxsqWmN+30iwqJfmoVRntwiy+WgtiV5Tn2AhgQ1i2gBoX0WmlTEKuQpIjGaxZ4mU7No7k2zCJLh7FjoQfK2Vu0rz+JTYIaIPK2UugT40guIaFp9QTJd9oiwsEJlB8JnYZl/RuRlsL6yGW9UlERvdGuGijN0ttlnlCe3yPY4kh46awUP1MUrLKIEhDZDaVIRXyAcuf6iNQvr2q5p9feYI9TuD5GZCpoF4BKRy4CjROQbnV9USr2SlF6lCS2+oKFZmA4maz/uAREWlmaRZ0RmNXkDcQmL6IQgIKFiZIZm0SEscvbDbnnWd2vd90X0b6DNUJpUxCjk2clJHQhRZWoW/mCYFl8w4huMxhsIR4XO2iJtyaAvYXEVcBGQR9ckPAV8qYVFmz9EltsRkextviDt/lDkx2pIUuhsOKwiq+TOmsXwvAzAmMiHxBGvZmkRHWYoe9xCrskboCDLFXme5TZCZ5OZKW2Zn+p6WW117mPksTZDaVKQaM2iI88izJ6oHKqaFn8XYREMhfGHwjFJeca5A6NZFCulrhaRFUqpR5LSgxQk3rIdhrR3RPaCaPEHI9E6kDzNosUfjJRG76xZDB9kCIt4C+d1dnAnmpRXWtgRGJftcRAMK3zBcFxaTX+wzFC+YNgMG+z9L2wJVaddtGahSUl8wVCUGcoeaauK8lXUtvgYUxQbhBrZ+KiTZjFQobNWEt5VSfn0FORr933E9S99HtexraYZCiDLbafNF4qsfN0OW9Js5NHJfl3MUIMsM1R8q2hfJwe3O4F6+k3eWAe3VXk2mX6LaPNTPH4L6zcYkZehhYUmJfFFJcU6bIJNOjSLEaaloLvwWas8eUaKaBa1IvI+MEZEXuv8olLq7KT0agDJcNkjUQh9YZmhADJdhgnGmsxKC7N6jY/eGywBES2QWnxBPE4bhdmGWSheQdU5Gsodp2bhNx1wg6J8FllRxQStRMV9TbSwqG8NMDK/9+Ot72pkfiYN7YntTa7R7A/8wTBuUzsQEaNsh6lZzCjJZ1dDOzUtXf+7XTWLgRUWZwAzgKeBe5LSgxRjaK6bDZXNcR3b0kmzaPUHI6vd0YWZbK5uSYr93poARxVkRjSZZm+QbLczYteMdxXd36S8pdvrCIUV00Z1zNbZ+2EDpIa2AMMHedjd6I0x+fVEk9cQokXZrqTW6tJo+ku0GQqMa7HZa8wlhxTnMG/dHmq7ERZtXTSL5JqhehUWSik/xl4WRymlkr+pdQowJMfDR5v63tvJ2n/bci5luR20+UMRp/aYoiyCZr0maxLdV1jCYnRBJltrWiN9yXbbI6Gs8TpzO3wWZiHBOJPyFmyswWET5owrjLRZe1ok0wxV1+pnyshB7G70xpVr0dhmaD+5GU5thtKkJL5gOGaO8Djt7Kw3FjYj8jLIy3R2b4YKxAqL6EiqZNCrz0JE7jUfPiYir3W+JaVHA8zgHDfN3mDEHhhNMBRmybY6wFiRB8MqYnrJchlho3WtfkSgpDATSI6T23rPksLMSAHBFl+QbI8Dj9OG0y5xO7gjG69EJfbEo1ks2FjNzNH5MX/yZO9pEQormrwBxpqOvrh8Fl4jFyTX46SpPYBRtUajSR2io6HAmPQtLXhIrpvCLBe1rb34LFIkdPZp8/5PSfn0FMSq81TV7GV0YWz0wWtf7Ob6l75g3vXHUZBlHBdthqpu9lHf5ifX46TQDCltbAtEnFT7ioiwKOgQSC1ewyQmIsbEaAoLbyDEpj0tTB45qNv36hINFUdSXlWzl7UVTfzytAkx7ck2QzW2B1AKSgqzsEl8uRaWXyU3w0FYkRRNT6PZG6LzLMBYsO2oMoVFjoeibDc1zd34LKL234bk+yx61SyUUsvM+w8xtjxdq5T60LolpUcDzFCz3HhVNyn2K8sbAVhf2RxZPUfMUKZmUd9m5B5YyWrJ0iycdmGY2dfGtgDNPsNnAUbJcMsM9cyi7Zz78MJImYzOdCn3YbcTCiuCvQiMjzYaZrrjxg+OaY+YoZIkLCzhUJTtIj/TFb9mkeGMMs9pU5Qmtejis3Aa1yAYmkVRtpuabjSLtk4ObiuSakBCZ8XgVhGpAdYDG0WkWkRuTkpvUoAhuaZm0U1E1NqKJgA2V7VGigZ2aBYO2vxB6lv95Gc6I1FCyRAWDaYdPvozLJ8FGCXDLc1ize4mQmHF9trunbudk/Isc1Rv2sWCTdUUZbuYVJwb055jCqtkmaEsH0Vepov8LFeCmkVijn+LLdUtfByHD0uj6S++QEfoLHQ4qu02oTDLTVG2q9v6UN5ODm4rkmqgqs5eBxwNHK6UKlRK5QNHAkeLyE+T0qMBZkiOsVqPzp4Ew6G9zhQWZdUtkQkxEjrrttPqC1HX6qcgyxU1ke/7cM2mdnO1HCUsLJ8FGCXDrRX0xj1GZFdPkUBdNYve9+EOhxUfbarhuPGDuyQuepw2XA5br4XP9gYrIS8/00lBvJpFe5BcjyNhx7/FX+Zt4trnlmtfhyZp+IJdfRYAg7PdhsDIdtPkDXa5Jq1adBlRCbAepz1ptaH6EhaXAhcqpbZaDUqpLcDF5msHHPmZTpx26WKGKq9vj0T5bK5qidSBynJ3mKH8oTBVzT7yMl3kZZo+iySZofKiNIumiM/CMkMZBf1CYUVZVQtAJLqiM75ufBbR7Z35oryBulY/xx08uMtrIsLogky2JylE1dIk8jNd5Gc5I+XKeyJsOsQtnwUkbobaUt1CY3sgaaVbNJroPAsAj3kNWlYOK3eq8+LISrzNivLBuR22AXNwO5VSXXRwpVS1iHStanUAICIMyfFQ1RyrWVhaxYySPNZWNEVqMWVFmaHAyLQsyHKR5bJjt0nShEVRtotBmcZPUN3iwx8Kk2NqFpaDe2ddW2TS39mXZhG1n0V0u8X1L33OJ2W1VDZ5sQkcM76o2/crLcpiWwIl0hPBMkPlZ7koyHKxfEdDr8e3+IMoRazPIgEzlFIqMpatta3kR9XB0mj2BUopo0S5PdZnAR1WjqJsQ2jUtPgYZlZoANhW28qwXE9MaR0joW9gyn30pucfsOmwg3PcVHfSLNZWNCECZ0wZjjcQjph3slxW6GzHD5af6UJEGJThTJqwGJThJMftwG4TyuvbY/pgObitPnqcthgz1LaaVh56vyyyparTLhGTUneaRU2Lj1eW76KkMJOfnXIwT3/3yMgfuDOlhYZmkYx9gOvbDMd+lstOfqaLerOYYE9YZVGiTXaJaBbVzb7IvubJEoCaLzfBsCKsiDVDddIsikzNonOuxZbq1i71ogzNYmDMUFNFpKmbWzMwOSk9SgGG5Li7+CzWVTQxpjCLySOMENSV5caqtrNmAVCQZUxMgzKcSTFfWMLCCJN1sKvBEBbZ5uo51+OgPRCKOOSPHlcUIyyeX7yDu9/ZQHl9uxnjHRu2B8TUh9poZrT/+MTx/Oik8Rx9UPdaBRiahT8YpqLT99cfmrwB/vj2erZUG6a0hjY/eaYgLshyEQyrXiOvLC0i1+OMaF2J7CIYvYnUth4CBDSavSF6/20L6/HQLppFx/pcKcWW6hbGDo4VFgPm4FZK2ZVSud3ccpRSB6QZCgyJ3tlnsa6imUOKcxln/jhWGG3EZ+HumHAtf0VuAprFsu11lPfgV4gm2g4PhkDaZZ5nRWZZJT+Wba9nRF4GhxTnsrvBGwmHXbPbECKbqprxh0KdIjGMcUSbodabwmLCsL5rno8xc1P2diW+s66Nb/71E/76wWaeXrQdMGy2BeZ3m2/e95bFbX33gzKcOO02slzxl1+HjjF4nDatWWiSgnWdRS/YPObjoRGfhXFfG6VZ1LX6afIGu9UsBsoM9aVkaI6HhrZAZHXd7A2wo66NQ4pzKMx2k5/ppLbVj9PesQ1idKlsa4+HQRnOuMwe4bDi8seXcMdb6/s8ttnbYYe3PmN3g7GKj/gsTGfuih0NjB+aTUmBkeld0ehFKRXRODbuacEfDMfYS13d+Cw2VDZTkOWKqMO9Mdr8827di8l1ze5Gzn1oIZWNXkbmZ/DFTkOLa2gLkGf6aazvuLeIKCvyyfo+cuP8PSy21rTictiYUZLP9lotLDT7HmuOcXUTDWWZobJcdtwOW8xe3Nb1NW5wdsz7eZz2gSn38WXF+pEsv4W1sp403MgrsH6gaAERnRVsrXrz4tQsttS00OwNsnx7fZ/HRq+WwZgArRoxlinMcua2+IIcPDSHkQVGBvmOujb2NPkiE+wmS1g4ugqL6NXJ+j3NTBiaE1dBxOJcD26Hrc/JdU+TN5J41JmH3i8jrBSvXns0px46jDW7mwiEwtS3+SPfreVs7pxr8Y8FWzjj/o9QqmODqMh35UmsPtSWmlZGF2QydnBWpAaXpn8YIdfV+jvshLUrZedCgtDh4BYRM4u7Q7PYUm1cX501C48zedFQWlh0Q0euhfHjWJFQh5hJaAcNMYRFtIDIjHJwR2sW8QgLy6RV0eilorG912Ot97NMXdElwq3+RG91On5IdqQsyI66NtbsNj4r1+MwzVDdJwRZmkU4rNi0pzkuExSAzSaMLsxka03PJrXKRi/H3/0+Vz61tIvA8AVDfLihmtMOK2bc4GymjsrDFwyzobKZ+rZAREhY5qi6TuGz76ypZM3uJrbXtnX4LDI6QooTybPYVmM4EEsLs2jyBuPyP4XDite+2J20xMR05Z01lVzy6GLmr6sa6K6kFL5uzFCZ5nVsVZMAw8ldE6VZbKlpxWkXRubHlhIayDyLLyUdmoVh3lm7u4n8TGekvIalWUT7KayJWoQYf0Jje6DPyCBLWIBhOuqNzppFtLCIDp21GD80h+JBGThsws66Ntaa/orTDhvGpj0tRvZod2Yo079RXt9Omz/ExDiFBcDowqxeNYvnFu/AGwgzf30Vt/9vXcxrn22po9Uf4pRJQwCYata0+qK8gYY2IzseIN8MIoj2WfiDYVbuMr7LxdvqaGwPYBPIdsWGFMeDlfU+ZnBWZDfArXGYot5aXcmPn1/BPz7aEtfnfFn4bKtRgPPNVRUD3JOBJxxWnP3gxzz8QVmUz6LjGjx32nDuv3B6zJ4wXTWLFkoKMnHYY6dwt8MW0Vb2NVpYdIOlWVhO7jW7mzikODdihhk3xJg8os1Q1mpgUIYTuxmGOijDSVgZ8f698UV5A9NG5eFy2Fixo3dTVG/CokOz6OjX+CHZ2G3GCsTQLJooLcxkekk+7YEQW0y7vIUlOCxb6vpKQ7gcnICwGFOU1WP4rD8Y5vnFO/jKhMFcflQpjy3cGnFgA8xbt4cMp52jxhkRVyUFmeRlOvmkrJZgWEXMUNluB067xOxpsWZ3Y+TiW7qtjqb2ADkeZyQsOJEy5bsb2vGHwowpzKK0KD6nfSisuHfeRgBeXla+V+HDS7bV8e6ayn6fn2osNoXF3LV74t6J8UDl0y21rCxv5NlFOyJaQPQ1WJjt5uypw2POKcyOrTy7taaVsZ38FaA1i/1OYZYLu03Y0+Rld0M7q3Y1Mntsx74NBw02Js4YM5TplLLMI9AxkTf2Yr4IhMKs3d3ErNH5HDY8N2HNwnL4inSYwqxoqBF5GRE/xqiCTEOzqGji0OGDOHio8Ufb2klYWAlB1qRrbQR18ND4hUVpoRE+u7sbk9o7ayqpbvZx6ZxSfnvmJL4yYTC3vbaGDZXNKKWYt3YPx4wvijj5RIQpI/NYsKm603glkmthscz0+UwZOYgl2+q77OSX64nfDGU5EMcUZTGqIAOb9B0++8bK3WyqauG0Q4dRXt/Ooi21cX1WZ5RS/OrllfzspS/i3g89lWnyBlhf2cTUkYNo9gVZWGbk+bb5g/xr6c5ei1YeiPx7WTkAuxraWbTZ+I9EaxbdUZjtprbFyCuytN6xnfwVMIChs19WbDahKNtFVZOPN1buBoiR9CPyM3A5bDFmKJtNyHTZY7J8rQzr3vwWG/c04wuGmTIqj+kl+azc1djrBGFtDdpZs8h2OSKaT5bLjk2ICAQwhMWmqhZ21LUxaXguBw3pmPzd3WgWEWGxp5lRBRkJlfUuNffy6K544dOfbqekIJPjDx6M3Sb86VtTyfE4+PWrq1izu4ndjV5OOWRozDlTRw6KlFopiPp+C7Ji60Mt32GECp8xuZitNa1sqWmN0bJyM5w0e/s2C0KssHA77AzPy+hVswiFFffN38SEoTn85dvTyPU4+Jc5KSTKkm31bKlppdkX7LfASSVW7GggrOC6kw8mx+PgfysNjen/vb6WX7y8kjdXHzgaVF+0+IK8tbqSM6cU47LbeGXFLoCYch/dUVKQSTCsWLWrkV31htbbOccCOsp9JCOQQAuLHhia66Gq2cfrX1QwZeSgiCkCjGqQZ04p5vDSgphzMl2OiE0diKndBHQ7Sa0y/RVTRgxiRkk+/mA44lDvjsb2AC67LbLRSURYeDomRRFh6qg8jokqIV5SkBnZhnFScS6DMpyROG53L9FQGyqbmTA0trpsX5T2ED67vrKJxdvquHh2ScQ0VJjt5qYzJrFsez0/e+kLROArE4fEnDd1ZF7kcV6U5hZdplwpxbLt9cwcnc/hY4zfZWV5YyfNwmnuadG3drG1ppUslz1iNx5T1Lsf5j8rdrGlupWfnjKeDJeds6cN581VFf3ane/FJTvJdjvIcNqZu3ZPwuenGku21mG3CUeMKeCUSUOZu7aSd9ZU8sKSnQC8urx/QnV/sruhfZ8ELby1qoL2QIjLjyrl+AmDI9dIX5rFGVOKyXLZeWLhNjbXGEmqY4q6N0NB71Wj+4sWFj0wJMfNyvIGVu1q7GI/BPjz+dP43rFjY9pmjc5nxuiOPamtiaqhPcB/P9/FkXfMp6wqdn/vL8wJbXRhJtNLjEmxN79FU3uAQZnOiBZhRfp0Xvm/es3RfPeYMZHnVkQUwKFmCLBlWuouGsoXDOMLGj6NRJzbAMPM8NnolXiTN8CvXl6Jx2njWzNHxRx/3owRHDWukA17mpk+Ki/GsQcwZVTHxk3RwrggyxXxWexu9LKnycfM0fkcNnxQRJhGO/sjxQQ7ZXF3twrbWtPKmMFZke/ZiPDqPnx2e20rt72+hikjB/HVScMAOH/WKHzBMG980bdDt8kbiIRpN3sDvLmqgrOmFnPcwUXMXbsnoVViKKz4y9yNXPHEEv4ydyMfbqxOSumVRFiyrY5Dh+eS5XZwxuRimrxBfvT8CiYOy+F7x4xhwaaaLrXYkolRYLO57wNN3l1TyQl/+oCrnlnW4zHxmtL+vbyc0sJMZo7O58wpxZF2Vx/CItfj5FuzRvH6yt18tsXw/3SnWZwwYTB/PG8ytjjC3BNFC4seGJzjob4tgAicOaWrsOiOv10yk2tOOCjy3BIWu+rb+d0ba6lu9vHrV1fHXPwryxuYMnIQIsLwvAyG5Xp6LZDX2Q5vPc7qw0w0Kt8QFkXZrshkPN40RcVEQ0WZoTZXtRIKq4Sc29ARPmvZ+Ft8QS5/bDFrdjfx4IUzuhTkExH+8PXJZLrsnNHNdz0kx8Nws4BaZzPUnkYvDW3+iL9iRkk+LoeNaaMMwdtZs4DY+lCb9jRz5B/m8+xnHU52MIRFadROiT2Fz7b7Q/zgaWMSefDCGRGNafKIQUwYmsOjH2+JqenzzppKHnxvE2VVzYTDiucX7+C4u97nxD99wIcbq3ljpbHyPH/WKE6ZNIzKJi+rzAgvpVSv9mhvIMS1zy7nvvmb2FzdwgPvbeKyxxZzxZNL4tqvPFGUUnyyuYY73lrHgiihVFbVzKsryvEHw/iDYT7f2cCs0Ya2d8z4InLcDpRS3HP+VC44ooRQWPHa57t7HNNTn27je08uZXdD72Hl3VHX6o8poqmU4tZDOBsAAA//SURBVDf/WcXJf17Aba+v6THXx+KlpTu56pllZLnsfLSpJuJvieaJhVuZ/ru5EStBT+ysa2PRljrOmzESEeHkQ4ZGFjV9aRYAlx9VSjCseHzhVnI8jshunNEcOnwQ3z68BKd930/tabO/pIicBtwH2IF/KqXuTObnWdurHl5aEFPpMRGsierhD8poaA9w6ZzRPPXpdv61rJzzZ43CGwixobKZK4/r0FCml+SxeGsd983bxMLNNRx/8GCuOWFcZIXbk7DI8fT+U1qaRXRUl+XTiF7V2GxGob6/friZ101/TaKaBRiT67rKJp5YuJV/LStnfWUzD31nOidPGtr98UVZfPbrkyKFGTszZWQelU2VMZrCeTNH8uKSnVz9zHLGDs4iw2lnYrHR1yNKC1i0pS4m56Tz7oXeQIgfv/A5Vc0+bnt9LTNH5zNxWC6tviDl9W2cO61DcEWHz1rCLhxW3PDKSjbsaebxyw+P7LsOhgC86YxDuPLppXz94YX89aKZPP3pdl5caphe/vTuRnNvZT9HlBbQ5A1wxRNLKMhycfDQbKaNyqPU3D723TV7KC3K4tJHF7NqVyNTRw7i2PGDueLoMRG/WF2rn+8/tZTlO+r5zRmH8L1jx9LqC/Lv5eX8/o11nPnAx1xw+ChW7mpkW00rl8wZzcVHju6yJ4lFiy/Im6sqOP2wYZGAiWjeWLmb++ZtYpNZAv/vH25hRF4GbqctkjD27po9XHHMGHzBMEeMMTRut8POb8+ahMtu49DhhsY4dVQeLy8rj9HUlVI89el2HnhvEzUtfmwClU3t/OsHR0U2++mJdRVN3DdvE4u31UXMlJfNGc2vzziEpz7ZzvOLdzJ15CAeX7iN7bVt3PGNyQzJcUeui1BY8eHGKp77bAfz1lVx7Pgi7r9gOmc+8DF3vb2e/1x7dOTYDZXN/OHN9fhDYa59bjlv/PiYmP+oxcY9zfzwueU4bMLXZ4wAjAXeSROH8r9VFTF5Fj1RWpTFSROHMG9dFROjruP9RVoICxGxAw8BpwDlwBIReU0ptTZZn2klxHRngoqXTJcdh02obwtw/qyR3HrWoayraOIPb67j0OG5rKtoJhhWTImyyc8cnc9bqyu5d/5GSgoyufudDdS3+rnpjEMQMUqeW6G9EOWz6EOzGJTpZNzgLI6NKi0+vhszFMBT3z2St1dX8HFZLQcNye6SJRoP44Zk8+7aPdz6+lpKCjJ56DvTOe2w4l7P6W5Ssrh49mhKCjNjJrdpo/K487zJXP/SFyzaWsuRYwoiK6pZpj+pN83irrc3sK6iibu+OYW73l7PdS98zsMXzeBHz69AAbPHdUTAWSr/w+9v5vfnHoYI/PTFz/lkcy0//+rBnDAh1s8CcNzBg3nxyjl898mlnPnAx4jAtV8Zx8WzR/P26koWltVy5pRizpk2nFZ/iOteWMG8dVX84LixRrRXlosjxhTw1uoKPt1Sy5rdjVx0ZAkryxt54L1NvLpiF3+/ZCZOu3DFE0upbPLy4IUzOMM0b2S5HVw6p5SpI/O45tnl3DN3I2OKssj1OLj5v2t4/YvdnDV1OCt2NLCluoUzphRz8ezRbKlu5UfPr2BrTSsPv1/GwxfNjFQvCIUVd729nr8v2MLEYTnc/c0pfPXQYSzYWM3Ly8oJhRWXH1VKY1uAe+ZuZLlpUp05usO/d/6srmbIm/+7hrW7m5g03BDWv3x5Jf9bVcFR4wp58DvjafEG+f7TS7nhlZXc++1pkYlyZXkDLy7ZSV2rn6JsN3Wtft5cXUGO28HXJhdz0JBsdta18eSn21m4uZbN1S18bfIwHrxwBs8t3sEtr63hyD/Mx+O0UZjlxhcMRTYaKsp28+OTxvPDrxyEy2HjupPH84uXV/LOmkpOO6wYXzDEdS9+Tm6Gg9u/Pplrnl3Ojf9exS1nTeKlpTv5bGsdQ3I85GY4eH7xDrLdDh67/HBG5ncsKr5vLhQL4ix/f8XRY5i3rqrbSKhkI+mQfi8ic4BblVKnms9vBFBK3dHTObNmzVJLly7t92durWnld2+s5S/nT4us3vrDrN/PxRcI897PT2BwjptNe5r52v0fEQgZ37vdJnx6w4kMMYVTuz/ER5uqmTE6n8IsF7e9vpYnPtnGOdOGM3FYLo8s2MwJE4bwl29PA4wV2EE3vcU3po/g7m9N7bUv1m9tXWhN3gBTbn2XK44ew81nTer3GLujpsXHwrIaZpTkMyrKX5IM7np7PQ9/sJlrThjHL0+bCBhbu5794Mf89sxJkYl8e20rx9/9AScfMoShuR6e/WwHlx9Vyq1nH8r7G6r4v8eXYDej2u6/YHoXR/sD8zfxwPtl2EVwO43kp1vOmsS3Dx/V6ypvZ10bf3p3A9+cOZJjx3fdNMoiFFYsLKvhqHGFkWSrRz/eyu/eWIvdJjx44XROn2wIgmXb67nm2WXGfuw2G26njUcuncWMkvxu39sXDNHmC5Gf5UIpxcvLyvndG2tp8gYpynYzPM/DyvJGCrJctHiDFGS5uPbEg3jwvU2RxU6Ox8nqXY18tKmGS2aP5uazJvVq7rh33kbunbeJMUVZvP/zE3o8rr7VzxF/mMe4wdkcNCSbtRVNbKtp5ZenTYwITjDKwNz9zgaOKC0gy22nssnHuoomMpx2hud5qG31EwwpLpkzmquOGxdz3b69upJfvPwFYwdn88L3Z0e0kzW7G1mytY7y+nZqW/1kuOxkux1MG5XHKZOGxowvFFacdu8C2gOhSMTdu2v38M9LZ3HypKH87cPN3PnWemwCYWVo5I3tASqbvBxzUBH3nD81ZqHXH5RS3PzfNZw8aSjHd7MB2b5ARJYppWZ1aU8TYfFN4DSl1PfM55cARyqlftjpuCuBKwFKSkpmbt++vct77W8eer+M0YWZMX6PhWU17GpoZ1iuh7GDs2JWGp1RSvHHtzfw9wWbsX4qy8xgce5DCzlr6vAYh3a83P3Oeo4bP5gjo/JI0o1wWPHc4h2cMmloTImEzrT7Qxx/9/vUtvrxOGxML8nnn5fNikSQ3P3OehZsrOHeC6Z1KdBmsbOujTveWseeJh9/PG9KpPRLsqhs9HL544u5+oRxnDNtRMxrVc1ernvhc5q8Af528cxe/0fd0dgeoKk9wMj8DESEZdvrefj9MtxOG78/dzIFWS5qWnzc8O+VLNpShy8Ywm4TbjpjEpfMHt3n+1umpKJsd0Tb6Ym/zN3Iu2v34AuEcNpt/ObMQ7oIVqUUd7y1PhJO7HHaOXNKMedOH9Gt6aczTd4AboctLpNPTywsq+GnL35OY3sAfyjMd48ew2/ONBZa4bDi9jfXYbcJFx5REtHIQ2EVSdRNB9JdWHwLOLWTsDhCKfWjns7ZW80i1Wj3hxAxNJFkOK++LCil9rutN9nszzEdiN9ffzlQv4uehEVa+Cww/BTRhs6RQPfhEwcofTn1NPFxgF7cB+RnpTpftu8iXZaoS4DxIjJGRFzABcBrA9wnjUaj+dKQFpqFUiooIj8E3sEInX1MKbVmgLul0Wg0XxrSwmfRH0SkGuivh7sI6Jp9k37ocaQWehypw4EwBkjOOEYrpbqEWh2wwmJvEJGl3Tl40g09jtRCjyN1OBDGAPt3HOnis9BoNBrNAKKFhUaj0Wj6RAuL7nlkoDuwj9DjSC30OFKHA2EMsB/HoX0WGo1Go+kTrVloNBqNpk+0sNBoNBpNn2hhEYWInCYiG0SkTERuGOj+xIuIjBKR90VknYisEZGfmO0FIjJXRDaZ992XJE0xRMQuIitE5A3zedqNQ0TyRORlEVlv/i5z0nQcPzX/U6tF5HkR8aTDOETkMRGpEpHVUW099ltEbjSv+w0icurA9LorPYzjbvN/tVJEXhWRvKjXkjYOLSxMovbMOB2YBFwoIvu2bnfyCAI/U0odAswGrjX7fgMwXyk1HphvPk8HfgKsi3qejuO4D3hbKTURmIoxnrQah4iMAH4MzFJKHYZRPeEC0mMcTwCndWrrtt/mtXIBcKh5zsPmfJAKPEHXccwFDlNKTQE2AjdC8sehhUUHRwBlSqktSik/8AJwzgD3KS6UUhVKqeXm42aMiWkERv+fNA97Ejh3YHoYPyIyEjgD+GdUc1qNQ0RygeOARwGUUn6lVANpNg4TB5AhIg4gE6OAZ8qPQym1AKjr1NxTv88BXlBK+ZRSW4EyjPlgwOluHEqpd5VS1kbyizAKq0KSx6GFRQcjgJ1Rz8vNtrRCREqB6cBnwFClVAUYAgXoup1b6nEv8EsgHNWWbuMYC1QDj5vmtH+KSBZpNg6l1C7gT8AOoAJoVEq9S5qNI4qe+p3O1/4VwFvm46SOQwuLDrqrN5xWccUikg38G7hOKdU00P1JFBE5E6hSSi0b6L7sJQ5gBvBXpdR0oJXUNNX0imnTPwcYAwwHskTk4oHtVVJIy2tfRG7CMEE/azV1c9g+G4cWFh2k9Z4ZIuLEEBTPKqVeMZv3iEix+XoxUDVQ/YuTo4GzRWQbhhnwRBF5hvQbRzlQrpT6zHz+MobwSLdxnAxsVUpVK6UCwCvAUaTfOCx66nfaXfsichlwJnCR6kiWS+o4tLDoIG33zBBjF5ZHgXVKqT9HvfQacJn5+DLgv/u7b4mglLpRKTVSKVWK8f2/p5S6mPQbRyWwU0QmmE0nAWtJs3FgmJ9mi0im+R87CcMflm7jsOip368BF4iIW0TGAOOBxQPQv7gQkdOAXwFnK6Xaol5K7jiUUvpm3oCvYUQXbAZuGuj+JNDvYzDUzZXA5+bta0AhRtTHJvO+YKD7msCYTgDeMB+n3TiAacBS8zf5D5CfpuO4DVgPrAaeBtzpMA7geQw/SwBjxf3d3voN3GRe9xuA0we6/32MowzDN2Fd63/bH+PQ5T40Go1G0yfaDKXRaDSaPtHCQqPRaDR9ooWFRqPRaPpECwuNRqPR9IkWFhqNRqPpEy0sNJq9QERaEjz+BKuarkaTTmhhodFoNJo+0cJCo9kHmBrDB1F7WDxrZj1b+6SsF5GPgW9EnZNl7lewxCw4eI7Zfr2IPGY+nmzuJZE5IAPTaEy0sNBo9h3Tgesw9kMZCxwtIh7gH8BZwLHAsKjjb8IoaXI48BXgbrM67b3AQSLydeBx4AcqtqyDRrPf0cJCo9l3LFZKlSulwhhlGEqBiRjF+DYpo1zCM1HHfxW4QUQ+Bz4APECJef7lGOU1PlRKLdx/Q9Bouscx0B3QaA4gfFGPQ3RcXz3V1BHgPKXUhm5eGw+0YJQG12gGHK1ZaDTJZT0wRkTGmc8vjHrtHeBHUb6N6eb9IIxtWY8DCkXkm/uxvxpNt2hhodEkEaWUF7gS+J/p4N4e9fLvACewUkRWm88B/gI8rJTaiFFl9E4RSZfd6DQHKLrqrEaj0Wj6RGsWGo1Go+kTLSw0Go1G0ydaWGg0Go2mT7Sw0Pz/9upAAAAAAECQv/UIC5REAEsWACxZALBkAcAKhJlcHOfdKJkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEgCAYAAABFO1+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydd5xU1fXAv2c7XZpKURcRESmiomKCxhbFXkj8WZJYY4mxxwQ1KtGgaNTYa1QsIHZEARVRRKWXpYO0BZayCwu7LFtnZ87vj/dmd3Z2ypvZaQv3y+exb+67977z7ry555ZzzxVVxWAwGAyGUKQlWwCDwWAwpD5GWRgMBoMhLEZZGAwGgyEsRlkYDAaDISxGWRgMBoMhLEZZGAwGgyEsRlkYDAaDISxGWRgMBoMhLEGVhYj0F5FZIrJJRF4TkfY+1+YkRjyDwWAwpAKhehYvAyOA/sAvwE8i0tO+lhlnuQwGg8GQQmSEuNZaVb+yz58UkfnAVyLyR8D4CDEYDIZ9iFDKQkSknaqWAqjq9yIyDPgE6JAQ6QwGg8GQEoQahnoc6OMboKqLgdOBT+MplMFgMBhSCzFeZw0Gg8EQDmM6azAYDIawGGVhMBgMhrAYZWFIGiKSLyJnxCivi+01QXtE5OhY5GmwEJFXROSBENdHiMh7Ia4vE5FT4iKcIWEEtYYSkecJYSKrqrfFRSJD3BGRfOB6Vf02gfccDRSo6j/jdIsngb+q6udxyj8lEZERwGGq+od43UNVb/K53ynAe6raPYL0faO9t4go0EtV10Sbh53PCOJcTns7oXoW84D5QA5wDLDaPgYC7viLZjBExCHAslhkJCKhTMoNhn0TVQ15AN8DmT6fM4Hvw6UzR+oeQD5wRpBr5wF5QAkwAxjgl+5vwGKgFPgAyPG5/ndgK7AFuB6rZ3oYcAPgAmqAPcAXTvLzkysN+CewASgC3gHaAdl2ngqUA2uDpH8W2ATsxmoEneRzbQTwMfCeff16oAXwNrALWGE/W4FPGsVqqXo/jwb+bZ+fAhTYaYrsMrkIOAfLG8JO4D6/ZxsOrAWKgQ+BDva1XPteVwEbgR3A/fa1oXaZuuwyWGSHXw2sA8qA9cCVAcojB6gEOtmf/wnUAm3tz/8GnvF9NqCVncZj328P0NUuvw/t76QMS2kPCvS+hYvrJ+N0n+91D/B/Dt7RfwCb7bxXYZn6Bywnc0RYb4SNYBV4B5/P7YFVyRbcHE340oMoC6weZBFwApBuV1D5QLZPujl2BdEBqxK9yb42FNgG9AVaAu/iU6HiU5n6yREwvwCyXQusAQ4FWmOt9XnX53qDyjtA+j8AHbGGXu+2Zc2xr42wK5KLsCruFsAo4Af7fe+OpdAiURa1wINYjas/A9uBsUAbu4yqgEPt+HcAs+z7ZAOvAu/b13Lte71uy3UUUA308ZH9PR85WmEpvN725y5A3yBlMh0YZp9/g6Wszva5dnGQZyvwy2eE/TznYL03jwGzAr1v4eIGkNG/nIO+o0BvrAZBV5+y6xmonMwR+eFkgnsUsFBERtvjzguARx2kMzQ//gy8qqqzVdWtqm9jVUyDfeI8p6pbVHUn8AXWsCTApcBbqrpMVSuAfzm8Z7D8/LkSeFpV16nqHuBe4DKnQ0aq+p6qFqtqrao+RX3l4mWmqo5XVY+qVtrP86iq7lLVAuA5h8/jxQWMVFUXMA7oBDyrqmWqugyrRT3AjnsjVm+hQFWrsSq23/k9279UtVJVFwGLsJRGMDxAPxFpoapb7fsF4gfgN/Z9BtjP+BsRyQGOA36M4Hl/UtVJqurGaiiEki+SuP6EekfdWN/rkSKSqar5qro2grwNIQirLFT1LSwt/pl9nGh/QYa9j0OAu0WkxHsAB2G1/L1s8zmvwGrlY8fZ5HPN9zwUwfLzpyvWEJSXDVi9hAOc3ERE7haRFSJSaj9XO6wKPJi80T6Pl2K7MgRr6Aag0Od6JfXPegjwmU+Zr8Cq+HyfzVE5qWo58H/ATcBWEZkoIkcEkfEHrJ7CMcASYArwG6yKd42q7gj3kCHkywmhyCOJ60/Qd1StSfA7sJRtkYiME5GuIfIyRIBT09l0rG70LuBwETk5fiIZksgmrNbwfj5HS1V930HarVjDKF4O8rveVFcBW7AqCi8HYw31FAaOXo+InIQ1ln0p0F5V98OaI5EQ8oV7ngqs4TYvB4aTIwSbsIZ/fMs9R1U3O0jbqFxV9WtV/S3WENRKrCGsQMzA6l1dDPygqsuxyvVcLEXi6H4JJuQ7qqpjVXUI1ruiWG6LIPlyN3vCKgsReRz4GbgfuMc+/hZnuQzxJ1NEcnyODKxK5SYROUEsWonIuSLSxkF+HwLXiEgfEWmJNV7vSyHWfEO0vA/cKSI9RKQ11lDoB6pa6yBtGyzFsh3IEJEHgbZh0nwI3Csi7UWkG/BXv+t5wBUiki4iQ7Fa5NHyCjBSRA4BEJHOInKhw7SFQK6IpNlpDxCRC0SkFdbwzB6CWC/aw4XzgVuoVw4zsIbFgimLQqCjiLRzKF9T8X9vgr6jItJbRE4TkWyseZFK6p+9QTkZIsdJwV2ENVl2rqqebx8XxFswQ9yZhPVj8h4jVHUe1pjwC1i9yDVYljVhUdXJWGPe39vpZtqXqu2/b2CNJZeIyPgo5H0Ta3x7OpaFTxVwq8O0XwOTsSyRNthpww0rPYxl0bQe+BbLWqra5/rtwPlYFjlXAtE8k5dngQnANyJShjXZfYLDtB/Zf4tFZAHWb/purJ7YTiwl9pcQ6X/AmoSf4/O5DVY5N0JVV2Ip7nX2dxnvYZ4RwNv2vS4N845mY82x7sAa6tofuM++5l9OhggJ60hQRCYDv7cnFQ0GR4hIH2ApliWVk9Z/SiMiNwOXqWpTehAGQ7PFyaRSBZAnIlPxaVmpWcFt8ENELgYmYplvPo61nqJZKgoR6YI1/DET6IXVWn8hqUIZDEnEibKYYB8GQzhuxLLJd2MNZ4Qa/kh1srDWO/TAGmoaB7yUVIkMhiRi9rMwGAwGQ1jC9ixEpBfWKssjsVwEAKCqTbFsMRgMBkMzwskw1FvAQ8B/gVOBa2hon56SdOrUSXNzc5MthsFgMDQr5s+fv0NVO/uHO1EWLVR1qoiIqm4ARojIj1gKJCi2y4DpWOZsGcDHqvqQiHTAchiXi+XT5VJV3WWnuRe4DmvM+zZV/doOPxZrLLwFlsnn7Rpm/Cw3N5d58+Y5eDyDwWAweBGRDYHCnayzqLIXsqwWkb/aFi/7O0hXDZymqkdh+fsZKiKDsbxrTlXVXsBU+zMiciRwGZaTtaHASyKSbuf1Mpbn0l72MdTB/Q0Gg8EQI5woizuw3BrcBhyL5b3zqnCJ1MK7NiPTPhS4EMv1M/bfi+zzC4FxqlqtquuxFtscb5swtlXVmXZv4h2fNAaDwWBIAGGHoVR1rn26B2u+wjF2z2A+1p4GL6rqbBE5QFW32nlvFRFvL6Ub1spVLwV2mMs+9w8PdL8bsHogHHzwwZGIajDsG0weDjVlcOGLyZbE0MyI645gttfNgSKyH5ZXzX4hogeaNNcQ4YHu9xrwGsCgQYMaxXG5XBQUFFBVVRVWdkP05OTk0L17dzIzM5MtisGf2S9bf42yMERIQraPVNUSEZmGNddQKCJd7F5FF6yNTMDqMfh69uyO5d+mgIbeP73hEVNQUECbNm3Izc1FJOUNupolqkpxcTEFBQX06NEj2eIYDIYYETcPjLbnzP3s8xbAGVjukidQP+dxFfC5fT4BazObbBHpgTWRPccesioTkcFi1fB/8kkTEVVVVXTs2NEoijgiInTs2NH03gyGvYyoehYi8qCqPhwmWhcsb5HpWErpQ1X9UkRmAh+KyHVYewr/HkBVl4nIh8ByLHfSt/hsHnMz9aazk+0jKoyiiD+mjA2GvY9oh6Gux3LhHBRVXQwcHSC8GGsT9UBpRgIjA4TPA0LNdxgMBkNCKamooW1OJmlp+0bjKOgwlIjsDnKU0XCbTcNezKOPNtxu/dprr2X//fenXz+juw37LkW7qxj48BSe/25NfWBVKbibpZNlR4SasygBeqlqW7+jDdaWk4Y44HYH3NQsafgri6uvvpqvvvoqSdIYDKlB4W5rt4YpK3y2Ex91MHz65yRJFH9CKYt3aLjnsS9j4yDLPsFFF13EscceS9++fXnttdcAaN26NQ8++CAnnHACM2fOZNKkSRxxxBEMGTKE2267jfPOOw+AESNG8OSTT9bl1a9fP/Lz88nPz+eII47g+uuvp1+/flx55ZV8++23/PrXv6ZXr17MmWNtglZeXs61117Lcccdx9FHH83nn1t2AqNHj+aSSy5h6NCh9OrVi7///e8ADB8+nMrKSgYOHMiVV14JwMknn0yHDh0SVl4GQ7Ni2afJliBuBJ2zUNV/hrj2j/iIkzj+9cUylm/ZHdM8j+zalofO7xsyzptvvkmHDh2orKzkuOOOY9iwYZSXl9OvXz8efvhhqqqq6NWrF9OnT6dHjx5cfvnlju69Zs0aPvroI1577TWOO+44xo4dy08//cSECRN49NFHGT9+PCNHjuS0007jzTffpKSkhOOPP54zzjgDgLy8PBYuXEh2dja9e/fm1ltvZdSoUbzwwgvk5eU1uWwMhr2RfWmHB7N5eYJ57rnnOOqooxg8eDCbNm1i9erVpKenM2zYMABWrlzJoYceWrdGwamy6NGjB/379yctLY2+ffty+umnIyL079+f/Px8AL755htGjRrFwIEDOeWUU6iqqmLjxo0AnH766bRr146cnByOPPJINmwI6EvMYDDsoyRkUV4qEq4HEA+mTZvGt99+y8yZM2nZsmVdhZ2Tk0N6uuUzMZQz3YyMDDweT91n37UM2dnZdedpaWl1n9PS0qitra3L+5NPPqF3794N8p09e3aD9Onp6XVpDAZDcPYlK3HTs0ggpaWltG/fnpYtW7Jy5UpmzZrVKM4RRxzBunXr6noDH3zwQd213NxcFixYAMCCBQtYv359RPc/66yzeP755+sU0sKFC8OmyczMxOVyRXQfg2FfwQxD+SAiPUUk2z4/RURu867MNkTG0KFDqa2tZcCAATzwwAMMHjy4UZwWLVrw0ksvMXToUIYMGcIBBxxAu3btABg2bBg7d+5k4MCBvPzyyxx++OER3f+BBx7A5XIxYMAA+vXrxwMPPBA2zQ033MCAAQPqJrgvv/xyTjzxRFatWkX37t154403IpLBYNgb2Jd6FF7C7sEtInnAIKzNir7GcsvRW1XPibt0TWDQoEHqv/nRihUr6NOnT5Ikcs6ePXto3bo1qsott9xCr169uPPOO5MtVkQ0l7Le5xjRzv5bmlw5mjlLN5dy3vM/0bdrWybedpIVuJeUrYjMV9VB/uFOhqE8qloLXAw8o6p3YrnyMMSJ119/nYEDB9K3b19KS0u58cYbky2SIRWoLIHyHcmWwtBUZr4Eu/KTLUXEOFEWLhG5HMvp35d2mPE9HUfuvPNO8vLyWL58OWPGjKFly5bJFsmQSL6+H9Z+1zj8Pz2tw9B8qdwFX98Lb1+QbEkixomyuAY4ERipquttj7DvxVes1EFV2V5WTa3bEz6ywRALZr4A717cONxjLNRSjagnuCtLYipHInCiLH6rqrep6vsA9panlfEVK3WorHFTVrqTzbsqki3KPktljZtRk1dS5YqdK5RtpVWUVjqw8qoph1mvgMc0Frw8MH4pXy01Hn+iQiwTeTS13Po4wYmyCLTf9tUxliN1qa3i0LRttHcVJluSfZZXfljLKz+s5d2ZsVsoOPixqZz25LTwEb/9F3z1D1g1MWb3bu68O2sDN723IPDFReNgykOQ/5M14VtaEDjeXkLEVlHeBJ7mpyyCLsqz5ymuAHqIyASfS22A4ngLliqI3QLIpCbJkjQBT601Mdr6gGZp81djDwHWxHgosLjcwXdaucsWojym994b+GjeJob2O5A2OT5TmJ/Zxhilm6y/G2dB/98lXrgEEfUwVBx6Futmf0nbHoPotP+BMc8bQvcsZgBPYe1u95TPcTfW9qj7GM2vkq2jtADKtkJ15L6wfL3Obtq0iVNPPZU+ffrQt29fnn322VhKmZp4leu+tPrKIfd8vJjhny4JfDEJ5fXt8kKen7o64feNCLtcNNbzTx43h06+kj0vnRrbfH0IqixUdYOqTlPVE1X1B59jgW1Ka4gDcXFR7v3hauQtc19lkZGRwVNPPcWKFSuYNWsWL774IsuXL4+VlCmKt5GgTFleyLsz85MoSxOY+RJ8GGhEuWlsL6uOeZ7Rcv0783hqyi8JvWdLLbes12qdloNXWThUptV7nM2X2b/tXLY4lCNynKzgvkREVotIqXfzIxGJrbvWfYhkuCifMX8RYC32a4qL8i5dunDMMccA0KZNG/r06cPmzZsTVnahqKipZccenx9s9R7HaTcUl7OnOkj7x6dn8ed35vHA58uaIGUS+fpeWD4+9vlG0YH4PG8zSwqa98I1L3+qfNeyXlv0fuwzryyBx7rBtEfDx42iIRgpThwJPgGcr6or4i1MQpk8HLYF6UL7kOWuBXclWaRDVpj1Dgf2h7NHhYzSJBfl1Xughe3wr2yrNUnmcYNqSBflI596gYlvPsEjjz8VMxfl+fn5LFy4kBNOOCFsGSaC85//ibXby8kfdS4ULoeXT4RLXocBlwZN80LmczDiCn5TNbbhSlxfxNueisGwStFK8Lis92Rvw1XlNw4fvLxuH2e9T/mjzo2zUPEnwzvI4nRYKZLhuQp7anjJR3Ba0B0jIs83SpxYQxXudYrCIWr/iyVRuyhXhZoyKN9ufS7bZlU821fBjlUhXZRv3GRZpHz73bSYuCjfs2cPw4YN45lnnqFt27YxLZ9AdC1bQj9ZFzLO2u0+E9CFS62/q78Jmea89HpHjsuC7m3ifM6i30Nfkzs8hNXUSyfAK0NCehZutvy3Lzzqs9uy9xkTYVCx4B3Y4nzPFVWlaHdV+IhO8qrPNKJ0aRJJ/PoyVFXu/nARs9f52RilSM9inoh8AIwH6vr5qtq8t4QK0wPA7WLjzkpqqyvombaVGmlBiy5HNOmWTXZRnp6Bx+OmrMpFG6Cquhrv6xrKRbl3HiQWLspdLhfDhg3jyiuv5JJLLom4DKLhj8uu54/Z8CJnR5YwFpVy3e80fF6+Q1mqykfzCrhgYFdyMtMbxPvr2IUM7tmRPw4OthFlMyP/Z6hIohuSCbfaJ8428Hx/zibu+2wJX946hH7d2sVProA07Z2scXv4ZEEBXyzawi8jfX8PqdGzaAtUAGcC59vHeeESichBIvK9iKwQkWUicrsd3kFEptjzIFNEpL1PmntFZI2IrBKRs3zCjxWRJfa150QS0FwpXErXmvzg1z21Vtc7AprsovygLixYspL1O8pZsGQF6zc6m8zyvkannXJKk1yUqyrXXXcdffr04a677nJ072iYtGQrm3ZGsAiytoZ7M8bQGm+a4K/HGz+tZ/KSSBaUeXsWkbXcvl1RxN8/WcyTX69qdG3ikq08MH6ps4wqdsLm+RHdO+Es/bhp6ddPhzfOBHfTXOHflfEhj2e8FjbeTLtVvna783mtQAyUNWQRoa1PjHqVjczIE9BbDduzUNVrosy7FrhbVReISBtgvohMwVrQN1VVR4nIcGA48A8RORK4DOgLdAW+FZHDVdUNvAzcAMwCJmGZ7k6OUq6wlFa6aAdkiju4wvbOd+zfFzKyHOU7dOhQXnnlFQYMGEDv3r3Duijv1KkTxx9/fN21YeeczjsfT+TSs07ipIG9OPzQgyN6rjvuvJ1HRj7OgAEDUFVyc3P58ssvQ6bxuig/5phjuPnmm3n33Xfp378/AwcOBCxrqXPOia0D4r+MWUC7FpkseujMBuGTlmzl/Tkbmfa3U8hI92nn5I3hxoyJZOABfh8y70e+XE5XdpCfc5szYaJsl5RVWRVfg0l3m/bsppNTG5G3zoHtK5qhJ1PvD8dB+Y3/i7Uuo2wr7BfZO+3LbRlxmMAPQubuDYzPfhDv8quaWjfOaoEICDCUF1QnpMIwlIgcjlVZH6Cq/URkAHCBqv47VDpV3Qpstc/LRGQF0A24EDjFjvY2MA34hx0+TlWrgfUisgY4XkTygbaqOtOW5x3gIuKkLFxuDxuKyxlg10VhX3V3jWNlkZ2dzeTJjcXes6dhC+fUU09l5cqVdS7KBw2yvAW3aJHDN++/xGJPDwakNdz4aOnS+pbq6NGj685zc3OZMXUisIe2rVrx6quvNrr/1VdfzdVXX1332VeBPP744zz++ON1nxM13h7IFYd3XmFPdS37tawvc1dtDZlAFv5p1FpMl9WqQejp6Y1XH/8u/QdYWAJHX+l3pX7OYj/KHMsfSsd8mX0/3aQYcOBNeHtqTxfGek4PYNycjTz5zSrm3n8G8RhEiEWOGTUNlfe/Jy7n4bi5V3UicWoMQ70O3AvWL1FVF2P1ABwjIrnA0cBsLKXjVSJbgf3taN2ATT7JCuywbva5f3ig+9wgIvNEZN727dsjEbGOVJh8jLWL8ky7FZ6R3owXFvrg/xUt3OjnlM1bwaycaE26bpobNs8nM1+Fz//S+MKCt+2besjLuZG8nMi+i0Bvk6Uo4OQnvueCF36KKL+9gfycK3gl879Brw//dAk79qS2xwT/dzDQL2vkxOXc+r491FtaAONvsRqXgfC4A6zVUJ//G1NSUUNNrd2jSEDPwomyaKmqc/zCHA/UiUhr4BPgDlUN1fcOVN4aIrxxoOprqjpIVQd17tzZqYgOxAjN9rJqNhbHzh1Eyrko37IQtid2sZNTinZXsTyYJVOtPaf0xhmwcXYT7xRZI0Ls9yhU22PjzgoWp8p6A1eV5em20OkiS+WP6d/QyhO4t+X2LiQL0jMYmh5egcebWLYLMwJUia//uJ4vFtnzil/eCXnvBXY9D/DRVfDv/RsEeYcyd1UEnssZ+PAU/vyOvcFbipjO7hCRnti/FhH5HfbwUjhEJBNLUYzxsZ4qFJEu9vUuQJEdXgAc5JO8O7DFDu8eIDwq4tFz2FpaSUmlC4qWWxOSewkFuyrY5jUxdDlXhvHunfnmftlrs1hjm80KCjNegE+ua5wo/8cm3jT8M+1HGS2IjUlmwtk8z6rIJv0tbNSjZA1D0pbySOZobi59JmCcpZstBR7K/9aqbaGH9RoV+TP94fvHwsoXjliMbPnn8UDmGGcJg71HK75oFLS70iq7QAtGe8tGOlHKD79EN4ISDU6UxS3Aq8ARIrIZuAO4OVwi22LpDWCFqj7tc2kC9Z5srwI+9wm/TESy7T0zegFz7KGqMhEZbOf5J580EZGTk0NxcXFcKjMBqxtZUr8+odbtobImVp5RHMhcWQJVsVtcv7O8Jrg9+s71DZ7Vi6pSXFxMTk5OzOQIyK4NULyWdTv8lNg39wdJ4Pw7d7k9vPj9GqprI3O9kpdzI99k/SOCFH4ybVsC636I6J5Rs+JLmB3ecqgRHg+fZz/Ie1lWpd3GE/h9223POVXWBC/Ds56ZHvZ2LreHkgpb4ZRshB/CmLynPLGpe77OHs60bGur5dzhE/nbh+EtG5uKE2uodcAZItIKSFNVp7N8vwb+CCyx9/EGuA8YBXwoItcBG7HNV1R1mYh8CCzHGua6xbaEAks5jQZaYE1sRzW53b17dwoKCgg1n+H2KIWlVawQK852raZaSnFJFpklPl90id0hKhYKyzwISobsAARKrUnJbaVV1HqU7u1bRCMubo/icnssO31VKLXuWahaJ18dpSusHxM0siip3r2dbE8lNdkuslo4dxhcuKuSNDyssMfYtWRFfYuq7l6NTVwzs7KZttnNtYcoaWmxnydRVXh2gP3JmW09CpRs5EAHDpPfm7WB/3y9Co9H8Vrwh+tZuD1KOnBQmvW91HkJCZFGUBShyuW2vuNXhoSVzRJFG078lm6GcZfDlR9D6/2DJ/TlA3si/4QbmLF2B571OxhiZd4o6v+9OpONOyuYee/pjsfGRbzj7U37/v/+8WI+W7iZ9Y+d4zynvLEw8AoA1u8oJ7djy4AT5fGYnA9IbU3dAlHvexKUfx8Ad62Alh3qXh5tsCivPmprqW/Ifb+yEOLcPnNiDbUfVms+F8jwFrqqhrQ9VNWfCD4BcHqQNCOBkQHC5wH9wskajszMzLqV0cHYUlLJee9+R36O9bI9UnMfY7MeZVnWUfS5z6clNMI2e73uW84eU0gP2cb32Xdb7iEestxan22v5o3IrUF5seUWu9NhnPrYZFruXsfEx26xbNAfOdHKt2psnXz18pTWyzSi1Nrjd/cWOORXzH7qAQaWTSHv2Mfoc36ASdwgnD18YoP7fHnJCs4b0LXh8wcw6fzn+CW8N2sjXdu35pz+9du1vz0jny7tcjizb9NcKC/cWMIZAcJDVyYKz/RnVg6Mrj0zeDSPhyqXVSF2Lvo5cJxpj8MpDXsQw16ega/hZpq7mgPYiWUFDgs27uKYILc84oGvInpHZq3byYk9O9YHzHkVti6CvDEw5E77MZRb31/I1b/O5bjcDiHzu+L12RwvaxiSDYHU2/r1a2kh1eCqhLSGVYaErXAdVMhBFLEC4/Ms32PfzZgZuNIIxPibYeAVbNpZwalPTuPW0w7j7jPthageN8fsnsoEeofOI5ZM/0/d6dMT5nBPqBe1tgoK5sLhZ/kEWgl63jeJW04JvK1uWopYQ03CUhRLgPk+xz6B98fQp2YJTP8PpRUulm72qSBFGJb2o6UoYsELx1oHcGfFs0zMvg/2bI98AuvZo+CtsxukC9gm/OVrKF7Lnupajhz+ibVhzc/PBcyyzvLCF1VYOMZqPdnsqbKG3vyHcR6asIwb3m386ny/sohxczY2Cg+2k52/W2xHrVefFvHVGSHcgDzcnoN3Wkri2MIPA8eZ9iio4vYopz01jW8WbWDDpobyHz/7Vmbn/BVVZfa6Yi55aUajbCJpc3+/sn7zrUpXLVUuN9tK7ZZlgHejtNLFxCVb6ydAQ9CN7RyeFmSTop3rmZNzCz9k3wUfXR3Bexh+gt95LnD6lAhX7wNFtkfcn9b4rC6f/SpXbXmE36WHHwKLlkY7OpYX1Z3eI+80vLZ+utr6WCwAACAASURBVPWb86Wu0BoWntujPPfdmoD37J22KWB4LHGiLHJU9S5VfUtV3/YecZcsSQSb/ErDA9/9m8ten8V5z/uaOwpHpa2t/6getpdVc8QDk7knY1xdy3zBxl1MWLQF1nxr7b6GNZzg8XdV7N1sBzha7BcjgsllsMZ5vWzL+8pHtgC/3LGXwvPHsLl4D29lPWGFzXkdgIvSwpt1rvnubfj8L3z07J0U+y1Ac1pRXDN6bsB9EYa93LiCDcWVGVODX4yg1sottiqSXaE2R5rzOrsrXazbXs6Bnw1jYc5N9dfmvckBRVbZKbCttIJT0kL7Lioqazw3pD67zF07uqFB4o3vzmfwY/7PK/UKxKaVu4zhz/4v5L1/zrmdf2e+VR9QW13vnWC3j1fhX76Cav9R6MDlWtfjcDKbHCJOLNZZ1FRV8MEDFzJt/hLYsw2Ajuxu9EoU7a4id/hEflrt57pk/ttWhe5w3+wjHvjKLyTEM8x4vlGQu25LAetvjVtDzrO+mPlM3RxSPHGiLN4VkT+LSBfbVUcHEQndr92LWbF1N+n4tBwCvAc/r9lBlcvDLRnWBoNVleVc8tIMbnt/Ibw3DH6y5vvfnpHPofdNYmeQSsk77ptfXIEngsrOtwdw/0dz6yya5q7fGXT/gRYlKzkhbaX1oXQjlePv5JmslxrECSTCatvhYOWuQkZOXGHLHfoHvnJb4ElR34ruENnGtqIiZqyt/+GOzQy8DtTZuLjz8pu/waoUdlcFN04o2Viv3AbQcMMd98R6i6KJi7eyavJLjPYqYh/qh3CU40d+2/j6f/v6xG3ID79s5wB2oh9dYw0PAUu37GbwY1OZm19vkfeijmTUrhC93m9HNA57qjeMPCBw/JL84Hn5ym7/zdkZ/aJCVSUWU16H7JzJ/6VPI/Ore0LGu/fTJfSXdfw8+n5WLfOZMJ79ivU3yi1ig+3w+NexC3AHeC2XbbHev6tHW+bFCnyeF9wA9Nz0+oaER+O3lsqJsqgB/gPMpH4IKnzfthnTlvoV1YGK/qZ0XzO38F/OI18s5eb0Cbye+VRd2LbSKkZ8Ydm0b95V2TiRz4Ynf3hjDq9/52v/Hrrim/VDvefTVliT7ACrCvdw3duB7dsz/N6EFnlvNooT6K6HlswE4E8ZU3h6xW8ayB1IuQyQtZz7zDQ2l1Q2ai0Nfmxq3XDUD9l38UHWI1zxev36iF+lJ3ajpYZKqKGsXyzaAqqclzazUTrfukHwkO4zDOFLBm5yqGZs5kjyc/xXjjck0NzAvZljkWWf1pldbrLfo5U+JqkDfXu9gfjJb3GcaoPebViCNWLsott/QejdFD+aF3r4RKKcILd615ZsVfbUbDiz5umrt/NF9j/5R+Y4en90SlT39eLbKPtqaWHAOL8smUP6msZDooGKdGupM5PseM5cOPE6exdwmKom0a1kYrkz45OQ1+/J9BnLdtBNXl20hw8zxzUIu+jFn0nDw4HsDNxr8Fu8U/PjM3Xf1oEEWMtRVv9Cblv8fd35c1kv8om73somoGIC0h08R6CucO/dfpWlenz2lmtIP1nHhOwHeK72Iv78+Cb+cNH5XHFCQ8st3+GovmnB3KRH8ZMI0TO7Lb2hA2WnuWf98jkvZDUeRvBVMutz/hA0/aqcqx3eCQ6X+lZtsArUO1d0zoxLaVlwNJbPzxjjVzhdXRuAExtFE4c94Z/W7OD3fnEFDwNknb2wKzox1xT5uNAJYFUUKNu24vfbcLugYJ61fsqPcEpsdVG9wt5d5QpY036THdjMesOOClpv39OggeB2sltenHHSs1gGROACtHkjCOk+U8HZNBwiau1fFNK4CF+d3nDvhaUFjcc6++yZybqcPzAj5zbS9wRY4+iub5moQot67/DMyrm1cfyn692nF/gphK4+yqU60CQ10HZOcPcLdXKEjQHuTXN5esVvOFLyGymXLmLJcVvGeCZl38cVk/vD6ikOcg3OPzPe5aS0xQ5iBpf+rsyGXlMV4SAp9GuVN64cCjZHNywRDZenB1n5C3ifzVtBddy9kuylMdq5bb7/9GTDcmwnwaoGZ7V8oN1Fb07/gs+zH0Q2zgyfS0jPzxLiU+P2wwPd/HyGPX8svDU0nASNuCOjaV54JyzazKVPTeAfGVYDUxHHU25NNVUOhRNl4QbyRORV2z34cyIS2FxmL8C/gX1VesNuYqOJpAB25yu2hl8Y91ZWvTldWoC9ADYUl9e1LH7OuZ1Tw0yQ+srRO62hZc6J9vDN01mvcJ4GXvTVYm1s/DKmrbKGwE5JW9ToWkAzyzG/o7v/mpEIuD5jMmc7cR0RwZyPoPyYfSedxdcs2L/1q2wpCbbvcux/sFUBfJrWVQzxXDG/xM8iLMb38qg2+tEdYb+/FTs2hu+4B12EWY93PUWD9Qo0bj7MLvDrWTRadOrs2e/I8O+pRv4+PJb5P05Pj/9Cu0hwoizGY619mME+aDp7cnpDK51GY8CexitUO7CbtzLrPbWGtUUPoHAen9Sw69szzfkeDBelB7ciGpX2ouN8/Pn7x4sZ/fP6kHG8vYm/Z35Ai8ptDa4FK4f3MhvuMXxiWhz2uV7v3FSyu6TeiGtaYMNnm9gsgAOoDTvc4azCdGrEpKpBFdCKLaWkiXBZsF5VTQXMDW3pZd8l6JXaBWOofv9PTFqyNaatcu8w1ZSse/hjRmPjhVCk424wkqBIQjYcDIeTFdx7rZlsICJ27FZbRU9paKlwfcYkTk2vb1mHWzATaC4gEYtsomHEF8u5+tehFjbWy92peC5wXN3nYO/7flI/vtyJUt7ParQus+kU+PvCDE74hWb2swR5oHh8cyHfB42dsghLrHsWgZbueNdoYBXxqMzACqFo+v9wsl69zhLVr8ZVVTK++AsZwF8W/R+XhVxaTVTP3ittc/hIfrya1dDfltq3npJ1D6+5z+Uj9ylB0yrC+IWbuejogI65m0TYnoWIrBeRdf5HzCVJEZwsYmrA6HNpJ6HXQdyY0dhJmC+BJrjTJPkTWk3G77HaBiknQelIKZ3ZRY4EG9rxyTYZerRsW6OgDE9gWeNRaTdQYHWuRJLR3HRa+PXxXEFMRyHwu+9LKDPsPVXOdtYTv7/BCF+evt9B6Ljx6An0StvMfzJD+/NS4KkpjXdnjAVOhqEGYTUPjwNOAp4D3ouLNM2U2jDFeH4A80pfAvcsnLVwoyGiLUsjxedZvly8uc7NMsATma8HTCIo83NuZm7OLTgZ709Kn+unpxt8PES2cdK6wEYB8ajEfYeh3IGM821yCK9sm4RDTe1bAi9PC26+69F6r6qVLv+tQkO/Da2Lgxs2rNteztbSSjpT4rMpVqjcnHmKKq1w8Xne5iS1WJJLWGWhqsU+x2ZVfQY4LQGyJY30kOPDjXH7uQY7UBqath6SFtjO3ksgZRHPMcqTnvg+fKQAtKbCWpG+JLi1x/i8eguh8mo3/52yOmjcaEmFDaoOSwu+SCrew1DPf7eavpLPJeneFfb112Zn39K0G4Ut28iVxdNTfgm6Gl5V65RFaaV/HE/I38H+64Nvo/reuHd58/0PmJvzF17OtNZ6ZFIDPz9bJ5/vkzhtmN3+wUJuH5fHltLAJuj1+cUW5/25+FUcThwJ+vo/S8PqabSJm0QpQEi3EQE4WBoqg3Y0fSOkdPEkZZAhFAd5rZZ+fDponJLymgZvVaghCC8Nlr4lXw+kJL7KYuPOChZm31f32aNKGlaFEtyUNUZE+QVdM3ou42/5daNw32GotEZzCvYwVBS39J33SrM9IbTwBK/g02wPwOHYWmKZ6taE6N3FHuGNn9bjZNf4bKllXOVNQOw3K3OyKO8pn/NaIB+4NOaSNGMamlhG8243TuGq9UDc9vSNDic/Jt8WmuWC28lkcWQlFo99mSPlQAm+yjk+cxb1Ste/Ui2tqKG9wOXp0fUYgzI5kr05QpO3KbxfJX/XHnVWQLGql33KzTt5XnfJoXdcbxbxGiIORmmly7EL8m4aeMV4U3FiDXVqXO5sqCeINVSiX0inlFXVxLRrGelzxnsYKhXLPd1HpsNo7KEXQg+NRYXXJ1IDnA5DRV6GjRoBGlu128sVfOK3hzQ2YAhEMnq+oUshcQI5GYa6K0BwKTBfVcOsFDM4IdAPS9CQrdemEd0L5k3lKd0cdFC2Yc/CoqKmlppaD/sFybehB6bkT3D7mj1HQzx6FoPT6tfdfOAO9JOMFeHWBMVeWXh7n94ek9aFx7cXmbux3q3PlOy/M8N9ZJgUvs8UerpXROhEbPZXD1WSbQg9dxJLnAxDDbIPr/3nucBc4CYR+UhVG7vTNITFo1I3lhrodYjnQMtZaXOB86JOH2pcvIGyEEUVjnzwawDyg3SjfdOcnr4gcCQfUn1eIx7ihTKSiGVPaHFBCceErAcb36ti7hha+r2w0dTxqh5Y8jEZ9pCb0nhoKlYIcNzihxqE9U8LveC0IeHLfF5O2N2nHd4peCEk8qfgRFl0BI5R1T0AIvIQ8DFwMtZKbqMs/Ii4ZRmg9nsqK9AQQGzYX5z55ffHyXNdldHQ15MCQ9KWkBuim+9b2T2SOTpk/p3ZRedU1xYJJqHDZgHKvmWAtTG+MnWXIgo08PI539yyVk2A6Q9zXgPjwsTNT0VSiunu0CbK/53yCzHyzkW/tHyuSv86RrlFj5N1FgdDA296LuAQVa2EeBt1N1fCv+D1vYrE8/eMDyj/9yGc/3z4zY2awmGyhQxPNe9lPdZwcx0/IqkO5ubcwiT+2nTh4kpiJ+ATebcr/jfLWUSf1/un7DscxZ22cGWjC4m1ZXB+s2Nmh7ZNmrnO+V73Tngg492A4YlcmOmkZzEWmCUin9ufzwfeF5FWQGI3GGgmRKwGEqw32kgl1FayZHNpRJu8n+zIu2s9N2V8waTtBzmIuXf1FBL9NG1jaC4brupx3IuJog7btKuyYY0UZPOjufk7w+4rHg1hn0yVzrqD36ZPorUrwDYBcSQjiEeHRCoLJ4vyHgH+DJRgTWzfpKoPq2q5qobesaUZ8tf0z5qcR6RfYEll8+ig1e2kFwHpGt4lQypaHzWF5LjhSAxOnywW36ll3tr4jr9/ZSbl1cF3MXSadzTcXz6Kv2V+1KR7N5VDfIZ0E/nLCaksRCRNRJaq6nxVfVZVn1FVR86TRORNESkSkaU+YR1EZIqIrLb/tve5dq+IrBGRVSJylk/4sSKyxL72nMTZyD4ZL8Lr08PsZpYiRPNiOnbKZ2gWOFUCweKFWqTZSMmGmJuqbeKiuOjeOaVn7Zom3TcW/JAdT2u44IS2e1D1AItE5OBQ8YIwGvDfOWQ4MFVVewFT7c+IyJHAZUBfO81LIuKd5noZuAHoZR+R70aS4qhHueCFnzjn2R+TLUpIomkx7229Bifs3T2LyN19+OLdp92XLhJkfF89tNcgxhhxKGIn31uWNN6SIJkk8k1zMmfRBVgmInOg3o+Fql4QKpGqTheRXL/gC4FT7PO3gWnAP+zwcapaDawXkTXA8SKSD7RV1ZkAIvIOcBEQm5164kSklYWI1rtGj2AOoelEuBguilfzt4VvhI0TqgJKJ7V+nE5IhHrcrB3pFqySbQLxVu4z1waXufGdlRdqHwoQMz6+08K938V7qukY+9s2iUQ2xpwoi3/F8H4HqOpWAFXdKiJee7pugK+ZRYEd5rLP/cMDIiI3YPVCOPjgaDpDsaG5tKUjfdHi5a0qlBxdU3Ajon2Zps5Z+FbyD2e8xXf8ve5zoGGonrqpSXJEQnuffVUCUVrpSjllkUicTHD/EOiIsRyBvnt/9y2+4QFR1ddUdZCqDurcuXPMhIsUR9t8+hALx4PRcGZaZBsexksJpocwI26OAzodwlQ6zZmmzlkcUVo/1PqnjND7r7euDOy+5MS0ZbR842RHcsSSsJsIJoGU6lmIyGDgeaAPkAWkA+Wq2jaK+xWKSBe7V9EF8C5LLQB8bSy7A1vs8O4BwvcqXkh/miz3TWyhU0Lv+2DmOxHF35vH4psbTnZSlAhd7TvDWeWU6wpstPFMCIcP/u/X0esDb/TzftZIiH7b9qhxB9j+OBht2fsaDE4W5b0AXA6sBloA19th0TABuMo+vwr43Cf8MhHJFpEeWBPZc+whqzIRGWxbQf3JJ81exdNZrzAu698JvWeklf956bPjJElwEun7pjnRRcLb+Ufac7QIrQzuyxjrKJc2nt0R5essRuyI5l7hdvXzZXHODVHcIXJSbYIbVV0jIumq6gbeEpEZ4dKIyPtYk9mdRKQAeAgYBXwoItcBG4Hf2/kvE5EPsRb51QK32PcCuBnLsqoF1sR2Sk9uNye6N4P5gIk++zYYIqN1HBTt4VHsKZ2KRFPJpsKmW8nEibKoEJEsIE9EngC2Aq3CJVLVy4NcOj1I/JHAyADh84B+DuQ0GAw+SBJdyvjTwoFnoFQf5vR4Uqc8vSRyzsLJMNQf7Xh/xTKdPQgYFk+hDAZD00mlNS5Ls69zECu1lcW+jpPNjzbYp1XE1ozWYDCkGPGqrtNFYee6RuHNaWSnrCQVh21Tq2dhMBiaIR3xn2ROMmP/r1HQ7qp632GXp3+XMFGiqWJPnHljzOVoKomaSAejLAyGvZbhmeOSLUJDahvPWyzcWO/OI9p9VqLBDHhFTlBlISLv2n9vT5w4BoNhb6UZjTgZAhCqZ3GsiBwCXCsi7W2PsXVHogQ0GAyJIx7mtvUYddGcCTXB/QrwFXAo1vapvj03tcMNBsNeRM+0rckWwZCiBO1ZqOpzqtoHeFNVD1XVHj6HURQGg8GwD+HEdPZmETkKOMkOmq6qke2vaTAYDM3JTtbQiLDWUCJyGzAG2N8+xojIrfEWzGAw7AskR4H8I9UsxZoBTtx9XA+coKrlACLyODATyxOtwWAwOCLQngP5OVcmQxRDFDhZZyHQYLsyN8ZM2WAwREhpRU2yRTA0ASc9i7eA2SLymf35IiD8XpkGg8Hgi9soi+aMkwnup0VkGjAEq0dxjaoujLdgBoNh76K9Z1eyRTA0Aaf7WSwAFsRZFoPBYDCkKMY3lMFgMBjCYpSFwWAwGMLiZJ1FKxFJs88PF5ELRCQz/qIZDAaDIRrisaufk57FdCBHRLoBU4FrsPbENhgMBkMK4onDanlH6yxUtQK4BHheVS8Gjoy5JAaDwWCICe5kKQsRORG4EphohzmyojIYDAZD4pHy4pjn6URZ3A7cC3ymqstE5FDg+5hLYjAYDIaYkNVu/5jnGVZZqOp0Vb1AVR+3P69T1dtiLkkYRGSoiKwSkTUiMjzR9zfsm4x0XZFsEQyGiLi85v645OvEGupwEXlNRL4Rke+8R1ykCS5DOvAicDbWfMnlIhKXeZO/1CRcDxpSlB3alnme3skWY69hufZgurt/ssWIOU+5fkeNpidbDAB+dvdlpqdvXPJ2Mgz1EbAQ+Cdwj8+RSI4H1ti9mhpgHHBhPG406sEHKRr2Ka+1v4vSFgcB0K/qfw3ifOI+qVG612rP5aqaf3B9u9e4seYONhx6edB75FaNCRh+TacxrL65oO7zW7VnMa72FDYO/ldEz7DBsz8T2lwGwKfuIQHjrPccAMC0Dr9ndO2ZQa8XHnt32Ptt8nRu8HlXVleqNYNJ7uMZU3t6XfgLtReyXds5eoYKza47H3Pyd9xYc2fI+BOzz23w+YYA8S+u/pejxsB4968AuK/zCyzUXnXls85zYNi0vtzjuqHu/L+uYQHjbMQq55Wegziu6sUG166t+Vuj+KszejUK+6frGnZoWwAmu4/judqLGsWpIZNarf+5R/os4XjIdRXX1NzDTm0dNE5Bh8G85j4vZD6rPN3rzt+oPbvBtU/83uUi3a/B57+5bmR9q6P4n186X/7FDbxd+1sACv3SR8IU9zF15xM8v+KZ2vrvd5GnJxUZ+1GmLaLOP1o+cJ/CnPtPDx8xCkTDzJqLyHxVPTYud3eIiPwOGKqq19uf/4jlNv2vfvFuAG4AOPjgg4/dsGFD025cuQu2LYEeJ9dt3KLAsi27qXK5mbZqO1f9KpeaDXPo1ncIiKCqVLrctMzKAI8HUDbnTUFa7Ef7rocxL28BNfsfxWnttiItO1KdP4vl0pPu+7Wk8yFHAFC+q4glBSWc0K8XIraDX7cLJJ2y4gLS09Jo2bE7VO2GzJaQnoGrOJ9lhdUcmLaT9I496dy5fszylyVzye3VjzULptK17xDSi1czdlMHzj+qK+1aZFJS6WLHto0s3pVFn5IfOKhzezZ0PInjcttb9y9awcaKLNbsrOG07e/BkDupSG/NhsISenbpSFaWtexm+86d7CjcQp8+/aiscZOWZnkazS7N5/2VLo7vfRCbt23jCCnAXVJApyNPpk2WsKvKQ+tVn5Ex6E+sr2xBZrpwaKfWpKUJLreHzPQ0qlxuFheUcnzXLMjI5pcdVRzSsSXZ66bCISdCdhtqKstZMHUcPQefT+dO+1NcWEBmRgZtO1oVY1FZFcV7ajg0rZC1edPxHNCffgOPZ8u65WS33o/lpZkcc3B7WmU3tN9YuW03HWu2sTurE9N/2cExnT30PexQdpRVs7u8kv12L8fduisHdmhLdXkZVXPepOXQh3Gp0EqqQT0Uu7JYsbWM43t0oGrLMhaWtqK3ayWdjvwNGTmtUFW+XraN0w/vwOJf1pLToRsdWmXRvmUWP67ewUnkkXPoYMhpBzXlkNWqTr7FBSX079aOGreHNUV76Nw6ky3LZ1Hcri8n9epMVoalJLZt2UjL8s207XEMm0sq2LJqLvulVZG7XyYccCSfLNtNpquMw9p6KNWWdOp6KF0yyvh24Wp+e/IQ2mydyfqswzlsvzSWb9xKdXprVIVqTafnQQfi9ig5Gemw4xeKlkyhRe/TaJuVRnmr7uRN/4Izz7uUPa401haW0Hf3dGoO/g3t2raF3ZuZvbGMozpnkN31SKSmHKrLKM3ohMvjoVPr+oaDa+cGVuTNos+vLyAzuwW1bg/pm+dQJq1pe1A/AGrdHgCmL13Pkd3acWBGBex3cIPvdMbaHRx3yH64p4xgy2GXU1peRU3lHnKyszjkiGNZunotOW07M6hHJ9i9hYryMjxLPqbVKXcgWa0o2FnOnoWforknccShhyDqYcfKn2jdawg5mVYvo6SihhZaTlpWazIzM9HC5Uinwymt8tDOswvaHAClm6G8CLoezfwNu+jfYjtZpRvZ1XEgtdUVdG6TA5JG6fYCPO0OoX379hSVVbF/mxyrPtpTRG1OR1SVNT9/Su+Tfkd6etPWWtt1/qBG4cGUhYh0sE9vA4qAz4Bq73VV3dkkiSJARH4PnOWnLI5X1aCbMA0aNEjnzZuXKBENBoNhryCYsghlAjufhvuV+A49KZDIfbgLgIN8PncHtiTw/gaDwbBPE1RZqGoPABHJUdUq32sikhNvwfyYC/QSkR7AZuAywJipGAwGQ4JwMmexQFWPCRcWb0TkHOAZIB14U1VHhom/HYh20qITsCPKtInGyBp7moucYGSNF/uyrIeoamf/wKA9CxE5EOgGtBCRo6kfjmoLtIyhYI5Q1UnApAjiN3pYp4jIvEBjdqmIkTX2NBc5wcgaL4ysjQk1Z3EWcDXW/MDTPuFlwH1xlMlgMBgMKUaoOYu3gbdFZJiqfpJAmQwGg8GQYjhxCHiIiNzlF1YKzFfVvDjIlAq8lmwBIsDIGnuai5xgZI0XRlY/nExwjwUGAV/YQediWScdAXykqk/EVUKDwWAwJB0nyuJrYJiq7rE/twY+Bi7G6l2YvS0MBoNhL8fJuvCDgRqfzy4s06pKfFZ0GwwGg2HvxYmyGAvMEpGHROQh4GfgfRFpBSyPq3QJJhXdoItIvogsEZE8EZlnh3UQkSkistr+294n/r22/KtE5Kw4y/amiBSJyFKfsIhlE5Fj7WdcIyLPSZ1DrLjLOkJENttlm2ev5UmqrCJykIh8LyIrRGSZiNxuh6dcuYaQNRXLNUdE5ojIIlvWf9nhqViuwWRNbrmqatgDa87iduAOYJCTNM3twFrstxbLjUkWsAg4MgXkygc6+YU9AQy3z4cDj9vnR9pyZwM97OdJj6NsJwPHAEubIhswBzgRay3PZODsBMk6AvhbgLhJkxXoAhxjn7cBfrHlSblyDSFrKparAK3t80xgNjA4Rcs1mKxJLVen7gkXYrkq/xQoEpGDw8RvjiTMDXoMuBB42z5/G7jIJ3ycqlar6npgDdZzxQVVnQ74O5SMSDYR6QK0VdWZar3d7/ikibeswUiarKq6VVUX2OdlwAqsxbEpV64hZA1GMmVVteddsSrgTCwfd6lYrsFkDUZCZHWy+dGtQCEwBfgSax/uL6O9YQrTDdjk87mA0C9+olDgGxGZL5YLdoADVHUrWD9YwOuPPBWeIVLZutnn/uGJ4q8istgepvIOQaSErCKSCxyN1bJM6XL1kxVSsFxFJF1E8rC8aE9R1ZQt1yCyQhLL1eke3L1Vta+qDlDV/qo6INobpjCBxvJCm4olhl+r5YfrbOAWETk5RNxUfQYILlsyZX4Z6AkMBLYCT9nhSZdVLKvDT4A7VHV3qKhBZEqmrClZrqrqVtWBWF4pjheRfiGip6KsSS1XJ8piE9YivL2dlHSDrqpb7L/ePUWOBwrtLib23yI7eio8Q6SyFdjn/uFxR1UL7R+lB3id+iG7pMoqIplYle8YVf3UDk7Jcg0ka6qWqxdVLQGmAUNJ0XINJGuyy9WJslgHTLNn2+/yHtHeMIWpc4MuIllYbtAnJFMgEWklIm2858CZwFJbrqvsaFcBn9vnE4DLRCRbLHfuvbAmuBJJRLLZXf8yERlsW2r8ySdNXPFWEjYXY5VtUmW1830DWKGqvj7ZUq5cg8maouXaWUT2s89bAGcAK0nNcg0oa9LL1cHM/EOBjmhn1FP5AM7BsuhYC9yfAvIcimXlsAhY5pUJ6AhMBVbbfzv4pLnfln8V9/bSowAAIABJREFUcbAq8pPvfazusAurFXNdNLJhWdstta+9gL1YNAGyvgssARbbP7guyZYVGII1VLAYyLOPc1KxXEPImorlOgDLUGexfZ8Ho/0tJVHWpJZr2BXcXkSklaqWO4psMBgMhr0KJ9ZQJ4rIciyzOETkKBF5Ke6SGQwGgyFlcDJn8QzW3hbFAKq6CGuBk8FgMBj2ERwtylPVTX5B7jjIYjAYDIYUxcl+FptE5FeA2lZCt2EPSaUynTp10tzc3GSLYTAYDM2K+fPn79BI9uD24SbgWepXA34D/CW24sWe3Nxc5s2bl2wxDAaDoVkhIhsChYdVFqq6A7jSL7M7sOYyDAaDwbAP4NSRoD9746I8g8FgiJqNxRVU1uy907nRKouY7zdgMBgMzZmT//M9146em2wx4ka0yiJVnNMZDAZDyjBzXXGyRYgbQecsRKSMwEpBgBZxk8hgMBgMKUdQZaGqbRIpiMFgMBhSl2iHoQwGg8GwD2GUhcFgMBjCYpSFwWAwNBGn3rubM0ZZGAwGgyEsRlkYDAZDE9kHOhZGWRgMBkNT2Qd0hVEWBoPB0FTMnIXBYDAYDBhlYTCEpKKmljd/Wo/Hs/e3HA3Rsy+8HUZZGAwhGDV5JQ9/uZxvlhcmW5Rmwa7yGjbtrEi2GAlnHxiFMsrCYAhFaaULgCrX3ut6OpYMefw7Tnri+2SLkXA0BfoWRWVV1NR64pa/URYGgwNSoTJoDpTvxfs5hCKSnkWt2xPzCfFat4fjR07lbx8timm+vhhlYTCEwGzcYoglVS43h90/mae++SWm+bpt5fPV0m0xzdcXoywMBgfsC2PShsiZta6Y3OETWbe93FH88upaAMbO2RhPseKCURYGQwhETN/CEJzP87YAMGPtDkfxm3ObwygLgyEE+8JiK4PBCY6UhYg8ISJtRSRTRKaKyA4R+UO8hUs2r01fS+7wicbG3mAwhMRpm6I591Od9izOVNXdwHlAAXA4cE+oBCJykIh8LyIrRGSZiNxuh3cQkSkistr+294nzb0iskZEVonIWT7hx4rIEvvac5KgsYEnvloF1E8eGfY9zDCUIZY055rEqbLItP+eA7yvqjsdpKkF7lbVPsBg4BYRORIYDkxV1V7AVPsz9rXLgL7AUOAlEUm383oZuAHoZR9DHcrdJJrzF2uIPdvLqtlYHHzBWUVNLWVVrrrPte742bwbUotITaubYxPEqbL4QkRWAoOAqSLSGagKlUBVt6rqAvu8DFgBdAMuBN62o70NXGSfXwiMU9VqVV0PrAGOF5EuQFtVnanWAPI7PmkSQnP8Yg2xRRWOG/ktJ/8n+IKzwY9Opf+IbwBYXVjGYfdPZvKSrYkS0eAQVWVneU2scotRPs5ZXVjG1tLKhN/XkbJQ1eHAicAgVXUBFViVuyNEJBc4GpgNHKCqW+18twL729G6AZt8khXYYd3sc//wuOLxKJ4UG356e0Y+67bvSbYY+xSRNBR2V9XWnS/ZXArA18viZ/duiI6P5hVwzCNTWL5ld8zyTGRV8dv/TufEx75L3A1tnE5wtwRuwRoOAuiK1ctwkrY18Alwhz3vETRqgDANER7oXjeIyDwRmbd9+3Yn4gXlqIe/SSnberdHeWjCMi568edki7JPEumr4J3qSKFXyGDz4xrLzHV1UVkMcrO+aCffs6uZD0s6HYZ6C6gBfmV/LgD+HS6RiGRiKYoxqvqpHVxoDy1h/y3yyfMgn+TdgS12ePcA4Y1Q1ddUdZCqDurcubOT5wpKmU8rMdCLsHzLbi59dWbCfQaVVdeGj2SIHVGOQYoZvExZvN9MbBqDzjL5aN4met0/mY3N2MmiU2XRU1WfAFwAqlpJmJ+RbbH0BrBCVZ/2uTQBuMo+vwr43Cf8MhHJFpEeWBPZc+yhqjIRGWzn+SefNEljxBfLmLN+J3mbSurCZqzZEcOx0IbE9gV3Rk2tp9m3hprKpws2Nyl9KvVOw7FoU0mz/L43Flew28ewIBzxMHAL9z1Psueu1hQ132Fkp8qiRkRaYKtREekJVIdJ82vgj8BpIpJnH+cAo4Dfishq4Lf2Z1R1GfAhsBz4CrhFVb3N9puB/2FNeq8FJjuUO374vRwej3LF/2ZzxeuzEnG7hHD4Pydz6pPTknDnxhTsqiB3+EQmLArYqUw5mtsw1JqiMi588Wcem7QybNzSCldKWXqd/J/vufCFyIdnY+Mc0vqiHc9vBom2rbSK2euKo5YiEY2SDIfxHsKqwA8SkTFYiuDqUAlU9SeC9z5OD5JmJDAyQPg8oJ9DWROK9wG9L8svhbEYB00dCnYl3uoiECu3WuU6fuFmLjiqa5KlcU5zWQG+Y4/VI15qT8wHw+1Rjnr4G4Yd052nLj0qEaI5Yv0OZ76ZINbWjZF9v14F5d+7GfrsdEoqXOSPOjdWgsUcp9ZQU4BLsBTE+1hWUdPiJ1ZqEej3nmiX1c2l0tlbibT8vYv5mvqtrd9RzqcLCsJHbCJOK1Bvo2h8XtOG51KBWP6k/vP1qialL6lwPozmZeHGXU26Z6Q4tYa6GKhV1Ymq+iVQKyIJXeuQqiRrhW9ljTuuG52kKoFKOxU3JqqTs4kV0jnP/shdH8ZvjwJ/wjWCmvu0vdujTLTnD2KjLJyVSF3jIYYK6uKXZsQuMwc4nbN4SFXr+qeqWoI1NGWw8b4DiVIefR78ijP/+wMTF2+NaQtjS0lls5rk3FBczhEPfEXu8Il8PD82LfCKmlru/2xJg9XYkeL0NVhTtIcFIb6/yhRUhNB8e7qjZ+TjcsdS9sjyevIbqwfSHBt6TpVFoHhO5zuaPYFaW76/leVbdvPdSssCOJaqoqKmlrn5O20ZGpNfXMEtYxfErIVRUlHDr0Z9x7++WBaT/OKBfzmsLqy3LonVLmFvz9jAmNkbeeWHtQHvG8kPXVEKdlVw+lPT2FZaxbbSho4Pznj6By5p4vdXWuHijnELgyq3ez9dzCkhVp5HQvNUEfUUldWXfzKexTs3VOUK/w59s2wb36bQ3u9OlcU8EXlaRHqKyKEi8l9gfjwFS3XmbbBagyJwznM/cuO7sS+OOz/I4/evzGR7WTjDs9jgXVvy/cqmLWhMdVxuD7nDJ/LOzPyA173j8sGcDTupeL3rLCYt2cY/PlnM2u3lnPbUNAY/NrXOv9TdMRpeemnaGsbnbeG9WYE31Hl/zibyQ/i0gsh7xM1dacSO+I0k3PDufK5/Z17ION6Gi7fx6vIkfw/uW7EW5X0AfITlF+qWeAm1N/P/7Z13nBRVtsd/BxwJBoKisqgExQC6qCDosiJiQtE17LKGFcNTWRNPDOggihHDPhEXM64googroiggAkNGwswQhzAwJGcYosAMMAOTzvujqnuquyt3VXf1zPl+Pv3p6tu3qk7dqrrnhnPPKSmrwK5iU7daYVar7gi8GJOvqmIMnpjjubXWpJWFeGdafJN7TvDi1TyoKsV3prsLbVlYZH3/tHXvgjzFJLJEjU+9Q73/33k8ce3FCKhtC9AaoC28GUqzd4zQyEMYj3RMSJnMylWO7+d9sWsNdYiZ09XV0R2ZeSAz27dVS3G8vAF//2QhOr+e4fj8TmWYt2E3cndUK4Zt+0vxxcKt+J/PMw33cVPZPDZ2GYbPzHO0T/Hhcjw7fmU4xKQZz45fiW+z8i3zJRqzWMdWcZCNbPLLK6vCZTI7dxdWFZibsXqJ3XuvFX3k/M2YnbvLOHMQYd3NlGXuemUUYM9B/0cf7FpDnUVEI4hoGhHNDH38Fi4ViH7HrF66nG32nZfF01Ls89kSXPvu3PBvM2Vz8EgFJiwt0Fhs+PMa9Ro+D8+MX4FP5mzEN1n5+PzXLTF5theVRqxy/SYrHwPGrwz/jpbsUJl/7k/MiuGhL42HHYdnbEAdk3v3+YItuun3jcpE+xd/AQDcOyoTN74/346YnuLkzr8yaQ3uHWXc+PCKrm/OtLXYdXn+fryXscF3eawYZzO+dnlllSejBkWl5Xht0tq4j2OF3UnqbwF8DGUVdTDNM2owXq7p0FNAz01YFbEy2q8W1+rCYqwuLMYj3c9QzqNTG4e8aUYvTjJSnI+PW256zsPllfhwVh4e7XEm6h2lhEexur6Nep59HReKsbbYtEff5cP8PHtxnP0geuI9RFUVY9iM9ehzaUucdFz9hK8vApRe8bb91otDQ042+13Z1t6BfbqU9AmrcHvn0y3z3fLhAuRsK457Id4703JRlgALRrvKooKZP7LOJnhJaJJ0055D4YrOKdlb96FjyyamL/kOm3MoXuGmx/TDcntuPuas340LT2+M4+ungZlxzgtTAQDHN0jDA5e1sXWMkD8oJy7qW6VPtp13f0k5ilwswjLCizqv39fLACDGoir7t314b2Yelufvx5j7uzg6ZllFFYiAtLp2p0a9oaikHI0aplnmS4bi0+JklMGMMk9NgY1xEvzoESJqroZFbUpETX2VLECYWSNFV3x+eBu9b1Smax9Ng75fFfFbT75kLbRyMtr1k9rzmblul+kw2T0jl6Df2GX4fllBxH17bfJa5EW5pN5fUo5/z9jgy7CbmULcdeAIOrwyzdHx7Mho9z5WVjFKDIbvoi3AQmtuoq1u7HDW8z/jyqFz7O/gER1emebZGH5VFfuy7igVFzfaVRb3QIm5/SsUk9lsAOY2XTWIy/6lmEpu2XMIrdInI3urNqps5G0vq6xCn88Wh38XlZZj7OLf0Cp9MvaXuPdIm8jFWX5bukQrrMWbfsfklZER5cwWxBWVmrfK56zfjSe+WRFj7fS6jpO8YTPWY+12awsxJ63QvYfKPF9V7tU9Wbjxd1z77ly0G/yLZTkqJ1a+3M6fJcslt1EDT1uMdsq0z8jFaDvIe7+lqTi5btcaqrXOx16fvgYxb4NieWDltnreBmXsuXB/KTq8PA3Pqa17p075vDCFtONmIPo8brrnTkxyQxVp6Cy3jViER8cujXAz/djYZYb72604QwugqvcztkLSP4+7V3pH8WHLuRQz9Ia0qpiRtWWvTm5n3PHporABwZPfxMoYfc2hXxWVjHU7vIssF3RKyypRVcVhs+dk8vmCzThSkfypYtuR8ojoeSIaof5uS0Q3+CtacthZfNgydKndSjxaOXjlCSSeYZPf9pboT+BGHN/5ca8ZNhfTbIYQ/c/8zbrpg3/ICW974fc/2iLJ6LKWbN4bsbI3nJ/1t/2g1/B5pv9//usW/O3jhZgVba8fxcNfZuPG9+xZUelNGkdfZui6s7buQ89352G7jTUmQYAZeHTsUtO5pOhrLSotR/HhclRWMc4dPBXPT8zR3U/L10v8N+t+6ac1+MChebof+BopLxXp8noGehiMs+rVF24VQDxj0Pl7nbsN154tehzZq3mWDQ4r+Ogi0A6LmE0uMxS78i0O3FLrnS/EkClr0XlIBvqPW4btRdVlm8ihgtUW8aBDbk2ytpr3Ln7O2RGO/23Fuh0HUFZRFbbV1yO6lxnPUKqWqirGCz/kOL6HTggNbQ74dgX26QQli34eOrw8DX98aRoq1FXQYxfbM4FNBNr47tH8nLPd8D8v8S1SXk3GbeWq3c/IlYQWoyzdPPLz4/S8VjhVnNEVkfaXlSXSn96Yie4Wk/6xw2vm/LC8MGy6C0RWJu/PSn7LDgA+mLUxJi2enuZbU9fh7pFLDP93e+hsC6W2Znsxxizaike+WuruBBZon61vswscrdb/LjsB7tctytUqrogWN+7N3eBnpLwah5dDEUYvODPjxYk5yN7qzpPsvkNl+HWjM3t9q0q+85AZeGC0s8VX5ZVVePuXXNNV2lVRGtPusA8zu7Ird1qpaiscvfmmVumTbQ+9xYvRPBIz49N5yrCe1X0887kpMWmWQ5L2xIvh81+3hreDsMpb1xmowdUNm+HODYwTrOYFJ0bFC0lSJIQIbLsoR2SkvAwAz/gmVcCxe+MyoyYktfsZPSr/mbcZoxduRe+Pf3XVf7nlwwW489PFMelmFWX09ew+cCRirHfXgSOYsdb6hdf2nL7LLsD7s/IwzKRFF+0mJLJnYXk6R/JEnMem0rCT7ZvMxLgiMSqPpb/t1/9DhwoXhWo04W2FtuR/Wb3D0DosUZWgWdviwOHyiMaQXZHemOJ+1bTRs2X0bPphku8US2VBijnNOtTiSHluMYueZTZ+7oaQB9Vo76LJesRCLf8jTtx5awrFrEK3W2HNjGrR+jFJXXy4HKsL/ffhFC17xtqdGJ6xwfdY2F4U2ddL8sOLI8PH9eheGA139RoeOcmv9zyFkr7LLohoDNkV7ZO5m2zmtE9IpiA6arRUFqyU8g/M/HsoUh4zJ88vQRIxe+DsENmz8PZpGJ5hPqaeiGdPe32hTbfX6YW8iQgwk7llX0zFlAjuH52Fd6av9z7YVow5VNRPmzfGrljxiL9uRzH++tFCW3n15sCMLiURFbW2l5extjpmhdGpU2kYahERXeyrJClE5H1zWRna2M2LiiCRD1m5tnJ2EUZSm9dsgrvYzmIyveM7vFdO3H34jVb2OSbWS17jVxnoBxRjTFu9A5UGw2XRQ1m/H7RvmVUVbrEH556GuH907Prmr6OcEQZAV9hWFldAURgbiWglEa0iopWWe9Uw4n3MgjDuqIdXcu3UW6vgYH9txRQ9+a3lCZdBg5zWE4GqVzSy3KOxXjJqDJRVKAGePo1zqCQ2doe9QrH7RGmfvak5O9B3TDZGGMgcvX7Eyf3RfZ4MDxCbPmqB/togrwkps0NlsXM8fg85WmFXWVwHoA2AHgBuBHCD+l0rGb2w2tLDbYVi5Q6iioPRmnCC9sW3K3up5qWwW5bbHK6Ed3r8cP4AOWUwHJ6I2K7+dVC1Qvtgtvnw5OzcyF7Kpqh1Dy/8ELkwzSsFqnecXaqLjkIDD7PR63ic3J9KB4LrZX35pzW2948HQ8OX+Ztx5qCfbfWMbh9hb2jOKXbdfWwFcBqAHup2id19axLxvijaVuCQyWtRfLgcPYbOdmRTbYy5cE7cfRixssDc8sbNkMXT46t7CX5XzkGq/J1iaCXjU4tif0mZ7TmfqiqOabnbHUKNR363Q5zhNPen9g0vlPGiTfG7hdHDrruPFwE8C2CgmpQG4EuLfUYS0S4iytGkNSWi6US0Qf1uovlvIBHlEVEuEV2rSe+oDnvlEdFw8nxGLz7c3tu1O4rR94ssbNp9yHV4zwg5LAWJ/ynctNt8te1XmhWvobtkJdeK/GoF5PewT0oPQxniz+twwSvTcb/O2hq9Imnz3BS0eW6K7aA/RsdxvqjTPj+uKMT7MyMDIxmarzoTQ/8YzPhwdh5+d+j91qpBk8xn0m7v4BYAfwFwCACYuRDAcRb7fA6gZ1RaOoAMZm4LZa1GOgAQUTsAtwNor+7zIRGFAjh8BKAvgLbqJ/qYCUPvPhndvB5DZ8ekad+FnG3F1i0ATxwJxn+MRGEnwE08cNS3FW4XRvqBHSsZvXsdz+0POcS0S/qEanf4Ruf9/eCRCDca2nzOlbmzHd6eFtsom5qzHS9FDTHt1XENEmJ7USl2FB22DPWbvXUf/jU1F8+MX4mpDtxxBLmBYjf4URkzMxExABDRMVY7MPNcImoVlXwTgO7q9mgAs6H0WG4CMI6ZjwDYTER5ADoT0RYAxzPzQvW8XwC4GYD3PoMtMHKZbbRCWa8VbrSwzQsLDasjJPohJI3xrF2ceuV1jMMyWLfDviddvzG6f4luC8T7HPX7ehl+3RjpyXVW7i78tLwQHU5rDMBBPHAX59fK/+KPqx3vr3UHY0a5GpDo4JEKTz3XJiIinhF2exb/JaJPADQmogcBzADwqYvznczM2wFA/T5JTW8BQKuqC9S0Fup2dLouRNSXiLKIKGv3bm/NC3t/vFC3Uh863XjhXTRvTY2NpwB41+11SyLGl73F7doNZb8gt96MMO5ZxLdKPdHEtNqJcN+oTExY5sIfUzAvMYLColIcVTcwL05cmCoLIqoHAMz8NoDxAL4DcDaAwcz8nody6JUmm6TrwswjmLkTM3dq1qyZZ8IBxq1Mr0Ij+s3Vw+ZG/NZ6V/XzUY6nzvK6wgto/WkLYzcQ5riZ4jMzE02EEiqrqMJOG6F+g2ywECr2/L2lOCraV74JVsWbzLU/Vj2L0PDPGGaezswDmPlpZp7u8nw7iai5eszmAELjMgVQrK1CnAqgUE0/VSe9RmF0/40WJznBaA2F3e60G1YXFmHvofj9THrhH0pL9ZxFcCsZI+zE9/CqHvHTTDS60RU5Z6FcwLjMfHR5PcNSMbm53mQM43y5yMnEP5suuvT6nXCClbI4mojuAfAnIro1+uPifD9CCdEK9XuiJv12IqpHRK2hTGQvUYeqDhDRJaoV1N2afWoMXtz/fSXlrpWL08bnlFXbcbi80nDhXK/h88OTieMy800nDM3wuhW791AZ8veWIG9n/IGVEo1Rz9bIhYxflYrdw7qaT4j63XrgFMN4F8zs6nn/QrNGyk+0r5STkMjMkYsuo0lmz8JqgvshAP8A0Bixi/AYwASjHYnoayiT2ScSUQEUz7VvQpn/uB/AbwB6AwAzryai/wJYA6ACwKPMHCrhh6FYVjWAMrGd8MntEIm+T07P924CXCsv2bwXj3y1FC0aN8AjV5xha59XJ63BsNsucHwuw/W1Lu/D5j2HwvHUawranqO2XD7wKf5G5mZ7Nvx2Fb1W2elNBBuZlT/85VJMTZB7+CCRzKFUK2XRnJkfJqJlzDzCyYGZ+Q6Dv640yD8EwBCd9CwA5zk5d6rhVQt6jU60NbNew7dZ+ejd6TTjDDqE/DJt21+KoTqmiHphLL9fts1xDGEiMnwxrFa/1ybGZ+ubcPoVPW2ozTVBbp5ovWfEaO4i6IrC7XIwq3Izc4PjN1bDUKFFeA/5LUgqkOixbr+7nAPGr0Sr9MmuK18nw0tTVjl/uY2uX89vTm0lwvWMzv/JssOZuNze1KJWPr37vdhmT6amYNVwDPIw1O9ENAtAayL6MfpPZv6LP2IFk9en6Ju++kWinotdxbUu6GGNRFuRpKLlVyrKbIRbM3OrInju+1UWOfzDSln0AnARgDEAhvovTu3EadQsw+O4PL8jJ2suz+GGmlR5JAJteYWc8gUd7XBNkFzCx4vbHp1VEfyyeqd5Bh8xVRbMXAbFNfmfmDlxTvRrGYbxlZ0ex+XLZteqZMLSbbjrkpauzuGUotJyjEyQW2ghGNgdju/6pn9m32YUG3hx0MNNCFsAgV5oaKosiOhdZu4PYGTI1YeW2jYMlWic1v2zct3pc7uTZnPW78b155/i6hxGmLn4SIR1V00iqKu2zYhogdsU328fYkbk7y2xzqRiZ1GhHq9NTowrdDdYDUONUb/f9luQ2oyx90svFuXZyONggPXZ7xI3ZpqCdV9S0Suv4LhoscbOMNQeh15cvaQqAev5vs0usM6UJKyGobLV7zlE1EzdluEojzGes4j/2CsKvIiVoQ+RvxW66658LSUVS0urzOwoi0vfyPBRGnMqHGiLmtjQsfINRUT0EhHtAbAOwHoi2k1EgxMjXu3Gqwm/9oOnmv5fx2UYqzqp1GytBXw2X2+OJ3XuUfNGDSzzhLy5JgMv3O+kMlbVRH8AXQFczMwnMHMTAF0AdCWiJ3yXrpZQUl6JB7/IihmL3eMgIL0ZVusS8ve6GwN24B9NSABFpXoTsMGu4LQr0INuDVXblYXVnMXdAK5m5nAUFGbeRER3AZgGYJifwtUWQtHi6qfVtcgZLJS5jtr9AgUdrxociSDoysIJqeis0gqrnkWaVlGEUOct0vwRqfZSmYgZNA9Jk66FEC8RcxbJE8MOt41YlGwRkoqVsjBrlqROkyVFCFJkNjvUS7GekBBspq9J3oIzr9nmd9THJGA1DNWBiPSi+xCA+j7IU6vRC8UqCDWFCp1YEjW1b6oX7zvVsTKdlaajYEgqLgITkscrk2IXnNU2R4GpjEujSUEI/hizECx+cBNnWwgMoiwE19Qk6xXBf4oPVyRbBCEORFkIrhFdIQi1B1EWgmtkzkIQag+iLATXSMQ6Qag9iLIQBEEQLBFlIQiCIFgiykIQBEGwRJSFIAhCDcMP4xNRFoIgCDUMPwwVU0ZZEFFPIsolojwiSk+2PEGiflrK3EZBEBKAHwtmU6KWIaK6AD4AcB2AdgDuIKJ2yZUqGMx+ujuWvXBNssUQUojmjcQHaE3HD1c8KaEsAHQGkMfMm5i5DMA4ADf5fVKjcA3nnHKc36e2zelNG6LB0eLv0Q4j+nRMtghxMeDasyN+N2noPKRM+nXnYOHAK3H2ybHPcLvmxxvul/HU5fjfHmc6Pl8yOKPZMb4ev3fHU309vhf4EXwpVZRFCwD5mt8FaloERNSXiLKIKGv37t2uTvTU1Wfh2vYn45/d2mBBeg9MfLRrxP8v/6U9pvbvhjkDukcoje5nN0PnVk0BALdeWC3a5jeux8d3XYTMQVeh5QkNAQBv3Ho+xj7YBetfuw53XXK6qTxtTjwGPz6myHBnl8i8Yx/sgjqqRrut02kx+/a5pGVMWgODGBT3XNoSGU9dHv495X8vAwAQAZe1PTGcPnfAFfj4rthK962/nh/evq9rK1zT7mS88/cOERXcmScdi8vPagYAeOGG2I5hj3NOCm+3PelYPNNT2ffUJg0wqd+fMfvp7mh2XD0AwKh7L8bsp7ujeaP6aNG4Afpf1Ta873ktIiu9nu1PQeagq3BN+1Pw6s3nhdO7tG4aI8PgG9phzoDueOPW85H1/FWY8WQ31DuqDhoeXRf9r2qLhQN74PwWjcL5P4lSQCccc3TMMT/6x0XIfa0n+nZrE5P//TsvxJY3e2HLm73wfK9zY/bV0ufSlhHnnvPMFfjqgS7o1LIJcl/ric1vXI+ZT12Oh7ufAQAY2rtDxP5j7u+Mhy5X/htyy3kRjaFWJzTElMcvi3h2AaUXckfn03FGs2PxxNXLags3AAAGrUlEQVRnRfwX2v/8Fo0wtHcHzHiyGyb1+zPu6Bz5nJ6rUUKnHB/ZqxnRpyOaNEyLeX4HXR9ZFu3/YKzIfn78MvyhUf3w+/X+nRdF/B965q4692QAwLM9zzE8lha9xuKcAd3x6s3n4fErleftuHpHYdHAKzHvmStMj5Xz8rUxaZ/06Yi2Jx2rm9+sIXDBaY2x9pWeyBtyHerWIdStQ/h7p2oFNrR3B6TV8b5qp1Rw2UBEvQFcy8wPqL/7AOjMzP2M9unUqRNnZWUlSsS4YGY1RKm/VFUx6tShhJ1PMEfugxBEiCibmTtFp6dKz6IAgLbpcSqAwiTJ4jmJqjBCvRCpoIKB3AchlUgVZZEJoC0RtSaiowHcDuDHJMskCIJQa7AKqxoImLmCiB4D8AuAugBGMvPqJIslCIJQa0iJOQs3ENFuAFtd7n4igD0eiuMnIqv3pIqcgMjqF7VZ1pbM3Cw6scYqi3ggoiy9CZ4gIrJ6T6rICYisfiGyxpIqcxaCIAhCEhFlIQiCIFgiykKfEckWwAEiq/ekipyAyOoXImsUMmchCIIgWCI9C0EQBMESURaCIAiCJaIsNAQxZgYRbSGiVUS0nIiy1LSmRDSdiDao3000+Qeq8ucSUaz3Mm9lG0lEu4goR5PmWDYi6qheYx4RDScf/GAYyPoSEW1Ty3Y5EV2fbFmJ6DQimkVEa4loNRE9rqYHrlxNZA1iudYnoiVEtEKV9WU1PYjlaiRrcsuVmeWjzNvUBbARQBsARwNYAaBdAOTaAuDEqLR/AUhXt9MBvKVut1PlrgegtXo9dX2UrRuAiwDkxCMbgCUALgVAAH4GcF2CZH0JwNM6eZMmK4DmAC5St48DsF6VJ3DlaiJrEMuVAByrbqcBWAzgkoCWq5GsSS1X6VlUk5SYGS65CcBodXs0gJs16eOY+QgzbwaQB+W6fIGZ5wLYG49sRNQcwPHMvJCVp/sLzT5+y2pE0mRl5u3MvFTdPgBgLRR3/IErVxNZjUimrMzMB9WfaeqHEcxyNZLViITIKsqiGlsxM5IAA5hGRNlE1FdNO5mZtwPKCwsgFAgiCNfgVLYW6nZ0eqJ4jIhWqsNUoSGIQMhKRK0AXAilZRnoco2SFQhguRJRXSJaDmAXgOnMHNhyNZAVSGK5irKoRm8sLwh2xV2Z+SIoIWUfJaJuJnmDeg2AsWzJlPkjAGcAuADAdgBD1fSky0pExwL4DkB/Zi42y2ogUzJlDWS5MnMlM18AJcRBZyI6zyR7EGVNarmKsqgmkDEzmLlQ/d4F4Hsow0o71S4m1O9davYgXINT2QrU7eh032HmnepLWQXgU1QP2SVVViJKg1L5fsXME9TkQJarnqxBLdcQzLwfwGwAPRHQctWTNdnlKsqimsDFzCCiY4jouNA2gGsA5Khy3aNmuwfARHX7RwC3E1E9ImoNoC2UCa5E4kg2tet/gIguUS017tbs4yuhSkLlFihlm1RZ1eN+BmAtM7+j+Stw5Woka0DLtRkRNVa3GwC4CsA6BLNcdWVNernGO3Nfkz4Arodi0bERwKAAyNMGipXDCgCrQzIBOAFABoAN6ndTzT6DVPlz4YNVUZR8X0PpDpdDacXc70Y2AJ3UB38jgPehehZIgKxjAKwCsFJ94ZonW1YAf4YyVLASwHL1c30Qy9VE1iCW6x8BLFNlygEw2O27lERZk1qu4u5DEARBsESGoQRBEARLRFkIgiAIloiyEARBECwRZSEIgiBYIspCEARBsESUhSDEAREdtM4Vkb87EU3ySx5B8AtRFoIgCIIloiwEwQPUHsNsIhpPROuI6KtQ7ABS4qSsI6L5AG7V7HOM6hAuk4iWEdFNavqTRDRS3T6fiHKIqGFSLkwQVERZCIJ3XAigP5T4Am0AdCWi+lD8+NwI4DIAp2jyDwIwk5kvBnAFgP9T3bq8C+BMIroFwCgA/2TmksRdhiDEIspCELxjCTMXsOLobTmAVgDOAbCZmTew4i7hS03+awCkq66oZwOoD+B0df97obh3mMPMCxJ3CYKgz1HJFkAQahBHNNuVqH6/jHzqEIC/MnOuzn9tARwE8AfvxBME90jPQhD8ZR2A1kR0hvr7Ds1/vwDop5nbuFD9bgTg31BCwZ5ARH9LoLyCoIsoC0HwEWY+DKAvgMnqBPdWzd+vQgmZuZKIctTfADAMwIfMvB6Kd9w3iegkCEISEa+zgiAIgiXSsxAEQRAsEWUhCIIgWCLKQhAEQbBElIUgCIJgiSgLQRAEwRJRFoIgCIIloiwEQRAES/4fTWQfA/qWGH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_lengths(df, slicen=None, abs_diff=True, title=None):\n",
    "    if df is None:\n",
    "        print(\"no lengths to plot\")\n",
    "        return\n",
    "    \n",
    "    arg1_lens = df['argument1_len']\n",
    "    arg2_lens = df['argument2_len']\n",
    "    arg_diff_len = df['argument12_len_diff']\n",
    "    \n",
    "    if abs_diff:\n",
    "        arg_diff_len = np.abs(arg_diff_len)\n",
    "    \n",
    "    if slicen is not None:\n",
    "        arg1_lens = arg1_lens[slicen]\n",
    "        arg2_lens = arg2_lens[slicen]\n",
    "        arg_diff_len = arg_diff_len[slicen]\n",
    "\n",
    "    x = np.arange(len(arg1_lens))  # arange/linspace\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, arg1_lens, label='argument1')  # Linie: '-', 'o-', '.-'\n",
    "    plt.plot(x, arg2_lens, label='argument2')  # Linie: '-', 'o-', '.-'\n",
    "    plt.legend()\n",
    "    plt.title('Lengths of arguments' if not title else title)\n",
    "    plt.ylabel('Lengths of arguments 1 and 2')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, arg_diff_len)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Differences')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_lengths(within_traindev_df, slice(None, None, 500), title='Length of arguments within train/dev, every 500')\n",
    "plot_lengths(cross_traindev_df, slice(None, None, 500), title='Length of arguments cross train/dev, every 500')\n",
    "plot_lengths(within_test_df, slice(None, None, 1), title='Length of arguments within test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.494728Z",
     "start_time": "2019-11-27T12:08:28.492841Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "names_columns_X = ['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']\n",
    "names_columns_y = ['is_same_side']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.506096Z",
     "start_time": "2019-11-27T12:08:28.495837Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[names_columns_X]\n",
    "    y = df[names_columns_y]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinct train dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.517591Z",
     "start_time": "2019-11-27T12:08:28.507338Z"
    },
    "code_folding": [
     3
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def load_distinct_data(name=\"within\"):\n",
    "    fn = \"data/distinct_sets/{name}/{name}_{mode}_arg_pickle.pkl\"\n",
    "    fn_train = fn.format(mode=\"train\", name=name)\n",
    "    fn_dev = fn.format(mode=\"dev\", name=name)\n",
    "\n",
    "    with open(fn_train, \"rb\") as fp:\n",
    "        train_df = pickle.load(fp)\n",
    "    with open(fn_dev, \"rb\") as fp:\n",
    "        dev_df = pickle.load(fp)\n",
    "\n",
    "    X_train = train_df[names_columns_X]\n",
    "    y_train = train_df[names_columns_y]\n",
    "    X_dev = dev_df[names_columns_X]\n",
    "    y_dev = dev_df[names_columns_y]\n",
    "    \n",
    "    return X_train, X_dev, y_train, y_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### within as a dev set for cross etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.529941Z",
     "start_time": "2019-11-27T12:08:28.519175Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def split_within_by_topic(within_df):\n",
    "    groups = within_df.groupby(['tag'])\n",
    "    abortion_df = groups.get_group(\"abortion\")\n",
    "    gay_marriage_df = groups.get_group(\"gay marriage\")\n",
    "    \n",
    "    X_abortion = abortion_df[names_columns_X]\n",
    "    y_abortion = abortion_df[names_columns_y]\n",
    "    X_gay_marriage = gay_marriage_df[names_columns_X]\n",
    "    y_gay_marriage = gay_marriage_df[names_columns_y]\n",
    "    \n",
    "    return X_abortion, X_gay_marriage, y_abortion, y_gay_marriage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.547412Z",
     "start_time": "2019-11-27T12:08:28.531954Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyBERTDataset(SimpleDataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        super(MyBERTDataset, self).__init__(self._convert())\n",
    "\n",
    "    def _convert(self):\n",
    "        allsamples = list()\n",
    "\n",
    "        if self._y is not None:\n",
    "            df = self._X.merge(self._y, left_index=True, right_index=True)\n",
    "            for _, row in df.iterrows():\n",
    "                # allsamples.append([\n",
    "                #     row['argument1'], row['argument2'],\n",
    "                #     \"1\" if str(row['is_same_side']) == \"True\" else \"0\"\n",
    "                # ])\n",
    "                allsamples.append([\n",
    "                    row['argument1'], row['argument2'],\n",
    "                    1 if str(row['is_same_side']) == \"True\" else 0\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            for _, row in self._X.iterrows():\n",
    "                allsamples.append([row['argument1'], row['argument2'], None])\n",
    "\n",
    "        return allsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### my own `BERTDatasetTransform` for extracting chunks from arguments or last part etc.\n",
    "\n",
    "```python\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, 512,\n",
    "                                         labels=['0', '1'],\n",
    "                                         label_dtype='int32',\n",
    "                                         pad=True,\n",
    "                                         pair=True)\n",
    "```\n",
    "\n",
    "http://localhost:9001/edit/bert/dataset.py @454\n",
    "```python\n",
    "# substitute with my own (e. g. last part, many parts etc.)\n",
    "def __init__(...):\n",
    "    self._bert_xform = BERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "```\n",
    "https://gluon-nlp.mxnet.io/master/_modules/gluonnlp/data/transforms.html#BERTSentenceTransform\n",
    "```python\n",
    "# substitute with my own (e. g. only last part (trim from start))\n",
    "self._truncate_seq_pair(tokens_a, tokens_b, self._max_seq_length - 3)\n",
    "```\n",
    "\n",
    "https://mxnet.incubator.apache.org/_modules/mxnet/gluon/data/dataset.html#Dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.577497Z",
     "start_time": "2019-11-27T12:08:28.549839Z"
    },
    "code_folding": [
     3,
     8,
     25,
     30,
     94,
     109
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "\n",
    "class LastPartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(LastPartBERTSentenceTransform, self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "\n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop(0)\n",
    "\n",
    "\n",
    "class FirstAndLastPartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(FirstAndLastPartBERTSentenceTransform,\n",
    "              self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        # convert to unicode\n",
    "        text_a = line[0]\n",
    "        if self._pair:\n",
    "            assert len(line) == 2\n",
    "            text_b = line[1]\n",
    "\n",
    "        tokens_a = self._tokenizer(text_a)\n",
    "        tokens_a_epi = tokens_a.copy()\n",
    "        tokens_b = None\n",
    "        tokens_b_epi = None\n",
    "\n",
    "        if self._pair:\n",
    "            tokens_b = self._tokenizer(text_b)\n",
    "            tokens_b_epi = tokens_b.copy()\n",
    "\n",
    "        if tokens_b:\n",
    "            self._truncate_seq_pair_prolog(tokens_a, tokens_b,\n",
    "                                           self._max_seq_length - 3)\n",
    "            self._truncate_seq_pair_epilog(tokens_a_epi, tokens_b_epi,\n",
    "                                           self._max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > self._max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
    "            if len(tokens_a_epi) > self._max_seq_length - 2:\n",
    "                tokens_a_epi = tokens_a_epi[0:(self._max_seq_length - 2)]\n",
    "\n",
    "        vocab = self._tokenizer.vocab\n",
    "        tokens, tokens_epi = [], []\n",
    "        tokens.append(vocab.cls_token)\n",
    "        tokens_epi.append(vocab.cls_token)\n",
    "        tokens.extend(tokens_a)\n",
    "        tokens_epi.extend(tokens_a_epi)\n",
    "        tokens.append(vocab.sep_token)\n",
    "        tokens_epi.append(vocab.sep_token)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        segment_ids_epi = [0] * len(tokens_epi)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens.extend(tokens_b)\n",
    "            tokens_epi.extend(tokens_b_epi)\n",
    "            tokens.append(vocab.sep_token)\n",
    "            tokens_epi.append(vocab.sep_token)\n",
    "            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n",
    "            segment_ids_epi.extend([1] * (len(tokens) - len(segment_ids_epi)))\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids_epi = self._tokenizer.convert_tokens_to_ids(tokens_epi)\n",
    "        valid_length = len(input_ids)\n",
    "        valid_length_epi = len(input_ids_epi)\n",
    "\n",
    "        if self._pad:\n",
    "            padding_length = self._max_seq_length - valid_length\n",
    "            padding_length_epi = self._max_seq_length - valid_length_epi\n",
    "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
    "            input_ids_epi.extend([vocab[vocab.padding_token]] *\n",
    "                                 padding_length_epi)\n",
    "            segment_ids.extend([0] * padding_length)\n",
    "            segment_ids_epi.extend([0] * padding_length_epi)\n",
    "\n",
    "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
    "            np.array(segment_ids, dtype='int32'), np.array(input_ids_epi, dtype='int32'),\\\n",
    "            np.array(valid_length_epi, dtype='int32'), np.array(segment_ids_epi, dtype='int32')\n",
    "\n",
    "    def _truncate_seq_pair_prolog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "\n",
    "    def _truncate_seq_pair_epilog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.589943Z",
     "start_time": "2019-11-27T12:08:28.578846Z"
    },
    "code_folding": [
     6
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class LastPartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, labels=None, pad=True, pair=True, label_dtype='float32'):\n",
    "        super(LastPartBERTDatasetTransform, self).__init__(tokenizer, max_seq_length, labels=labels, pad=pad, pair=pair, label_dtype=label_dtype)\n",
    "        self._bert_xform = LastPartBERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "\n",
    "class FirstAndLastPartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self,\n",
    "                 tokenizer,\n",
    "                 max_seq_length,\n",
    "                 labels=None,\n",
    "                 pad=True,\n",
    "                 pair=True,\n",
    "                 label_dtype='float32'):\n",
    "        super(FirstAndLastPartBERTDatasetTransform,\n",
    "              self).__init__(tokenizer,\n",
    "                             max_seq_length,\n",
    "                             labels=labels,\n",
    "                             pad=pad,\n",
    "                             pair=pair,\n",
    "                             label_dtype=label_dtype)\n",
    "        self._bert_xform = FirstAndLastPartBERTSentenceTransform(\n",
    "            tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi = self._bert_xform(\n",
    "            line[:-1])\n",
    "\n",
    "        label = line[-1]\n",
    "\n",
    "        # if label is None than we are predicting unknown data\n",
    "        if label is None:\n",
    "            # early abort\n",
    "            return input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi\n",
    "            \n",
    "        if self.labels:  # for classification task\n",
    "            label = self._label_map[label]\n",
    "        label = np.array([label], dtype=self.label_dtype)\n",
    "\n",
    "        return input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.607853Z",
     "start_time": "2019-11-27T12:08:28.591124Z"
    },
    "code_folding": [
     4
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import Block\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "\n",
    "class BERTProEpiClassifier(Block):\n",
    "    \"\"\"Model for sentence (pair) classification task with BERT.\n",
    "\n",
    "    The model feeds token ids and token type ids into BERT to get the\n",
    "    pooled BERT sequence representation, then apply a Dense layer for\n",
    "    classification. Does this also for an adversarial classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert: BERTModel\n",
    "        Bidirectional encoder with transformer.\n",
    "    num_classes : int, default is 2\n",
    "        The number of target classes.\n",
    "    dropout : float or None, default 0.0.\n",
    "        Dropout probability for the bert output.\n",
    "    prefix : str or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    params : ParameterDict or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=0.0,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTProEpiClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self,\n",
    "                inputs,\n",
    "                token_types,\n",
    "                valid_length=None,\n",
    "                inputs_epi=None,\n",
    "                token_types_epi=None,\n",
    "                valid_length_epi=None):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Generate the unnormalized scores for the given the input sequences.\n",
    "        From both classifiers (classifier + adversarial_classifier).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : NDArray, shape (batch_size, seq_length)\n",
    "            Input words for the sequences.\n",
    "        token_types : NDArray, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one.\n",
    "        valid_length : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "        inputs_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Input words for the sequences. If None then same as inputs.\n",
    "        token_types_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one. If None then same as token_types.\n",
    "        valid_length_epi : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : NDArray\n",
    "            Shape (batch_size, num_classes), outputs of classifier.\n",
    "        \"\"\"\n",
    "        # if inputs_epi is None and token_types_epi is None:\n",
    "        #     inputs_epi = inputs\n",
    "        #     token_types_epi = token_types\n",
    "        #     valid_length_epi = valid_length\n",
    "\n",
    "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
    "        _, pooler_out_epi = self.bert(inputs_epi, token_types_epi, valid_length_epi)\n",
    "        pooler_concat = mx.nd.concat(pooler_out, pooler_out_epi, dim=1)\n",
    "        return self.classifier(pooler_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.625307Z",
     "start_time": "2019-11-27T12:08:28.609520Z"
    },
    "code_folding": [],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_bert():\n",
    "    # change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "    ctx = mx.gpu(1)\n",
    "    # ctx = [mx.gpu(i) for i in range(2)]\n",
    "    # ctx =  mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "    # ctx = mx.cpu()\n",
    "\n",
    "    bert_base, vocabulary = nlp.model.get_model(\n",
    "        'bert_12_768_12',\n",
    "        dataset_name='book_corpus_wiki_en_uncased',\n",
    "        pretrained=True,\n",
    "        ctx=ctx,\n",
    "        use_pooler=True,\n",
    "        use_decoder=False,\n",
    "        use_classifier=False)\n",
    "    # print(bert_base)\n",
    "\n",
    "    # model = BERTProEpiClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "    # model = BERTProEpiClassifier(bert_base, num_classes=1, dropout=0.1)\n",
    "    model = bert.BERTClassifier(bert_base, num_classes=1, dropout=0.1)\n",
    "    # only need to initialize the classifier layer.\n",
    "    model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.hybridize(static_alloc=True)\n",
    "\n",
    "    # softmax cross entropy loss for classification\n",
    "    #loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    # sigmoid binary cross entropy loss for classification\n",
    "    loss_function = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "    loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "    metric = mx.metric.Accuracy()\n",
    "\n",
    "    # use the vocabulary from pre-trained model for tokenization\n",
    "    bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "    # maximum sequence length\n",
    "    # max_len = 128  # + batch_size: 32\n",
    "    # 384 - 12\n",
    "    max_len = 512  # + batch_size: 6 ?\n",
    "    # the labels for the two classes\n",
    "    #all_labels = [\"0\", \"1\"]\n",
    "    all_labels = [0, 1]\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    # transform = FirstAndLastPartBERTDatasetTransform(bert_tokenizer,\n",
    "    #                                                  max_len,\n",
    "    #                                                  labels=all_labels,\n",
    "    #                                                  label_dtype='int32',\n",
    "    #                                                  pad=True,\n",
    "    #                                                  pair=True)\n",
    "    transform = LastPartBERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                             labels=all_labels,\n",
    "                                             label_dtype='int32',\n",
    "                                             pad=True,\n",
    "                                             pair=True)\n",
    "\n",
    "    return model, vocabulary, ctx, bert_tokenizer, transform, loss_function, metric, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.642706Z",
     "start_time": "2019-11-27T12:08:28.627443Z"
    },
    "code_folding": [
     0,
     6
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_dataset(X, y, transform):\n",
    "    data_train_raw = MyBERTDataset(X, y)\n",
    "    data_train = data_train_raw.transform(transform)\n",
    "    return data_train_raw, data_train\n",
    "\n",
    "\n",
    "def predict_out_to_ys(all_predictions, all_labels):\n",
    "    y_true, y_pred = list(), list()\n",
    "\n",
    "    for _, y_true_many, y_pred_many in all_predictions:\n",
    "        y_true_many = y_true_many.T[0].asnumpy()\n",
    "        # https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss\n",
    "        # pred: the prediction tensor, where the batch_axis dimension ranges over batch size and axis dimension ranges over the number of classes.\n",
    "        #y_pred_many = np.argmax(y_pred_many, axis=1).asnumpy()\n",
    "        y_pred_many = y_pred_many.asnumpy()\n",
    "\n",
    "        y_true.extend(list(y_true_many))\n",
    "        y_pred.extend(list(y_pred_many))\n",
    "        # TODO: convert label_id to label?\n",
    "        # y_pred.extend(all_labels[c] for c in list(y_pred_many))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-GPU?\n",
    "- https://gluon.mxnet.io/chapter07_distributed-learning/multiple-gpus-gluon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.681720Z",
     "start_time": "2019-11-27T12:08:28.645389Z"
    },
    "code_folding": [
     0,
     11,
     12,
     16,
     19,
     27,
     36,
     82,
     105
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          data_train,\n",
    "          ctx,\n",
    "          metric,\n",
    "          loss_function,\n",
    "          batch_size=32,\n",
    "          lr=5e-6,\n",
    "          num_epochs=3,\n",
    "          sw=None,\n",
    "          checkpoint_dir=\"data\",\n",
    "          use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    global_step = 0\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                global_step = epoch_id * len(bert_dataloader)\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               label) in enumerate(tqdm(bert_dataloader)):\n",
    "                    global_step += 1\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = model(token_ids, segment_ids,\n",
    "                                    valid_length.astype('float32'))\n",
    "                        label = label.astype('float32')\n",
    "                        ls = loss_function(out, label).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    ls.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    out = out.sigmoid().round().astype('int32')\n",
    "                    label = label.astype('int32')\n",
    "                    metric.update([label], [out])\n",
    "                    stats.append((metric.get()[1], ls.asscalar()))\n",
    "\n",
    "                    if sw:\n",
    "                        sw.add_scalar(tag='T-ls', value=ls.asscalar(), global_step=global_step)\n",
    "                        sw.add_scalar(tag='T-acc', value=metric.get()[1], global_step=global_step)\n",
    "\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def train_proepi(model,\n",
    "          data_train,\n",
    "          ctx,\n",
    "          metric,\n",
    "          loss_function,\n",
    "          batch_size=32,\n",
    "          lr=5e-6,\n",
    "          num_epochs=3,\n",
    "          sw=None,\n",
    "          checkpoint_dir=\"data\",\n",
    "          use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    global_step = 0\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                global_step = epoch_id * len(bert_dataloader)\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               token_ids_epi, valid_length_epi,\n",
    "                               segment_ids_epi,\n",
    "                               label) in enumerate(tqdm(bert_dataloader)):\n",
    "                    global_step += 1\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "                        valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "                        segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = model(token_ids, segment_ids,\n",
    "                                    valid_length.astype('float32'),\n",
    "                                    token_ids_epi, segment_ids_epi,\n",
    "                                    valid_length_epi.astype('float32'))\n",
    "                        label = label.astype('float32')\n",
    "                        ls = loss_function(out, label).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    ls.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    out = out.sigmoid().round().astype('int32')\n",
    "                    label = label.astype('int32')\n",
    "                    metric.update([label], [out])\n",
    "                    stats.append((metric.get()[1], ls.asscalar()))\n",
    "\n",
    "                    if sw:\n",
    "                        sw.add_scalar(tag='T-ls', value=ls.asscalar(), global_step=global_step)\n",
    "                        sw.add_scalar(tag='T-acc', value=metric.get()[1], global_step=global_step)\n",
    "\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.705636Z",
     "start_time": "2019-11-27T12:08:28.683036Z"
    },
    "code_folding": [
     0,
     111
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_multi(model,\n",
    "                data_train,\n",
    "                ctx,\n",
    "                metric,\n",
    "                loss_function,\n",
    "                batch_size=32,\n",
    "                lr=5e-6,\n",
    "                num_epochs=3,\n",
    "                checkpoint_dir=\"data\",\n",
    "                use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(),\n",
    "                                'adam', {\n",
    "                                    'learning_rate': lr,\n",
    "                                    'epsilon': 1e-9\n",
    "                                },\n",
    "                                update_on_kvstore=False)\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               label) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = gluon.utils.split_and_load(\n",
    "                            token_ids, ctx, even_split=False)\n",
    "                        valid_length = gluon.utils.split_and_load(\n",
    "                            valid_length, ctx, even_split=False)\n",
    "                        segment_ids = gluon.utils.split_and_load(\n",
    "                            segment_ids, ctx, even_split=False)\n",
    "                        label = gluon.utils.split_and_load(label,\n",
    "                                                           ctx,\n",
    "                                                           even_split=False)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = [\n",
    "                            model(t1, s1, v1.astype('float32'), t2, s2,\n",
    "                                  v2.astype('float32'))\n",
    "                            for t1, s1, v1, t2, s2, v2 in zip(\n",
    "                                token_ids, segment_ids, valid_length)\n",
    "                        ]\n",
    "                        ls = [\n",
    "                            loss_function(o, l.astype('float32')).mean()\n",
    "                            for o, l in zip(out, label)\n",
    "                        ]\n",
    "\n",
    "                    # backward computation\n",
    "                    for l in ls:\n",
    "                        l.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    for l in ls:\n",
    "                        step_loss += l.asscalar()\n",
    "                    for o, l in zip(out, label):\n",
    "                        metric.update([l.astype('int32')],\n",
    "                                      [o.sigmoid().round().astype('int32')])\n",
    "                    stats.append((metric.get()[1], [l.asscalar() for l in ls]))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def train_multi_proepi(model,\n",
    "                data_train,\n",
    "                ctx,\n",
    "                metric,\n",
    "                loss_function,\n",
    "                batch_size=32,\n",
    "                lr=5e-6,\n",
    "                num_epochs=3,\n",
    "                checkpoint_dir=\"data\",\n",
    "                use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(),\n",
    "                                'adam', {\n",
    "                                    'learning_rate': lr,\n",
    "                                    'epsilon': 1e-9\n",
    "                                },\n",
    "                                update_on_kvstore=False)\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               token_ids_epi, valid_length_epi,\n",
    "                               segment_ids_epi,\n",
    "                               label) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = gluon.utils.split_and_load(\n",
    "                            token_ids, ctx, even_split=False)\n",
    "                        valid_length = gluon.utils.split_and_load(\n",
    "                            valid_length, ctx, even_split=False)\n",
    "                        segment_ids = gluon.utils.split_and_load(\n",
    "                            segment_ids, ctx, even_split=False)\n",
    "                        token_ids_epi = gluon.utils.split_and_load(\n",
    "                            token_ids_epi, ctx, even_split=False)\n",
    "                        valid_length_epi = gluon.utils.split_and_load(\n",
    "                            valid_length_epi, ctx, even_split=False)\n",
    "                        segment_ids_epi = gluon.utils.split_and_load(\n",
    "                            segment_ids_epi, ctx, even_split=False)\n",
    "                        label = gluon.utils.split_and_load(label,\n",
    "                                                           ctx,\n",
    "                                                           even_split=False)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = [\n",
    "                            model(t1, s1, v1.astype('float32'), t2, s2,\n",
    "                                  v2.astype('float32'))\n",
    "                            for t1, s1, v1, t2, s2, v2 in zip(\n",
    "                                token_ids, segment_ids, valid_length,\n",
    "                                token_ids_epi, segment_ids_epi,\n",
    "                                valid_length_epi)\n",
    "                        ]\n",
    "                        ls = [\n",
    "                            loss_function(o, l.astype('float32')).mean()\n",
    "                            for o, l in zip(out, label)\n",
    "                        ]\n",
    "\n",
    "                    # backward computation\n",
    "                    for l in ls:\n",
    "                        l.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    for l in ls:\n",
    "                        step_loss += l.asscalar()\n",
    "                    for o, l in zip(out, label):\n",
    "                        metric.update([l.astype('int32')],\n",
    "                                      [o.sigmoid().round().astype('int32')])\n",
    "                    stats.append((metric.get()[1], [l.asscalar() for l in ls]))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.718623Z",
     "start_time": "2019-11-27T12:08:28.706870Z"
    },
    "code_folding": [
     0,
     37
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data_predict, ctx, metric, loss_function, batch_size=32, sw=None):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                       label) in enumerate(tqdm(bert_dataloader)):\n",
    "            global_step = batch_id\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            label = label.astype('float32')\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "            out = out.sigmoid().round().astype('int32')\n",
    "            label = label.astype('int32')\n",
    "            metric.update([label], [out])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "\n",
    "            if sw:\n",
    "                sw.add_scalar(tag='P-ls', value=ls.asscalar(), global_step=global_step)\n",
    "                sw.add_scalar(tag='P-acc', value=metric.get()[1], global_step=global_step)\n",
    "\n",
    "            all_predictions.append((batch_id, label, out))\n",
    "\n",
    "    return all_predictions, cum_loss\n",
    "\n",
    "\n",
    "def predict_proepi(model, data_predict, ctx, metric, loss_function, batch_size=32, sw=None):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, token_ids_epi,\n",
    "                       valid_length_epi, segment_ids_epi,\n",
    "                       label) in enumerate(tqdm(bert_dataloader)):\n",
    "            global_step = batch_id\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "            valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "            segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'),\n",
    "                        token_ids_epi, segment_ids_epi,\n",
    "                        valid_length_epi.astype('float32'))\n",
    "            label = label.astype('float32')\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "            out = out.sigmoid().round().astype('int32')\n",
    "            label = label.astype('int32')\n",
    "            metric.update([label], [out])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "\n",
    "            if sw:\n",
    "                sw.add_scalar(tag='P-ls', value=ls.asscalar(), global_step=global_step)\n",
    "                sw.add_scalar(tag='P-acc', value=metric.get()[1], global_step=global_step)\n",
    "\n",
    "            all_predictions.append((batch_id, label, out))\n",
    "\n",
    "    return all_predictions, cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.736007Z",
     "start_time": "2019-11-27T12:08:28.720022Z"
    },
    "code_folding": [
     0,
     33
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def predict_unknown(model, data_predict, ctx, label_map=None, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm(bert_dataloader)):\n",
    "            global_step = batch_id\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "\n",
    "            # to binary: 0/1\n",
    "            out = out.sigmoid().round().astype('int32')\n",
    "            # to numpy (not mxnet)\n",
    "            out = out.asnumpy()\n",
    "            # get mapping type\n",
    "            if label_map:\n",
    "                out = [label_map[c] for c in list(out)]\n",
    "\n",
    "            predictions.extend(out)\n",
    "\n",
    "    # list to numpy array\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def predict_unknown_proepi(model, data_predict, ctx, label_map=None, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, token_ids_epi,\n",
    "                       valid_length_epi,\n",
    "                       segment_ids_epi) in enumerate(tqdm(bert_dataloader)):\n",
    "            global_step = batch_id\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "            valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "            segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'),\n",
    "                        token_ids_epi, segment_ids_epi,\n",
    "                        valid_length_epi.astype('float32'))\n",
    "\n",
    "            # to binary: 0/1\n",
    "            out = out.sigmoid().round().astype('int32')\n",
    "            # to numpy (not mxnet)\n",
    "            out = out.asnumpy()\n",
    "            # get mapping type\n",
    "            if label_map:\n",
    "                out = [label_map[c] for c in list(out)]\n",
    "\n",
    "            predictions.extend(out)\n",
    "\n",
    "    # list to numpy array\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.753421Z",
     "start_time": "2019-11-27T12:08:28.737482Z"
    },
    "code_folding": [
     0,
     21,
     45
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def print_infos(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s' % vocabulary)\n",
    "    print('[PAD] token id = %s' % (vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s' % (vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s' % (vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s' % data_train[sample_id][0])\n",
    "    print('valid length = \\n%s' % data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s' % data_train[sample_id][2])\n",
    "    print('label = \\n%s' % data_train[sample_id][3])\n",
    "\n",
    "\n",
    "def print_infos_proepi(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s' % vocabulary)\n",
    "    print('[PAD] token id = %s' % (vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s' % (vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s' % (vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s' % data_train[sample_id][0])\n",
    "    print('valid length = \\n%s' % data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s' % data_train[sample_id][2])\n",
    "    print('epi token ids = \\n%s' % data_train[sample_id][3])\n",
    "    print('epi valid length = \\n%s' % data_train[sample_id][4])\n",
    "    print('epi segment ids = \\n%s' % data_train[sample_id][5])\n",
    "    print('label = \\n%s' % data_train[sample_id][6])\n",
    "\n",
    "\n",
    "def plot_train_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"no stats to plot\")\n",
    "        return\n",
    "\n",
    "    x = np.arange(len(stats))  # arange/linspace\n",
    "\n",
    "    acc_dots, loss_dots = zip(*stats)\n",
    "    # if isinstance(loss_dots, tuple):\n",
    "    #     loss_dots, loss_dots2 = zip(*loss_dots)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.title('Training BERTClassifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, loss_dots)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:08:28.770998Z",
     "start_time": "2019-11-27T12:08:28.754899Z"
    },
    "code_folding": [
     0,
     12
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(np.unique(y_test)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test, y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within_traindev_df = within_traindev_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "    # X_train, X_dev, y_train, y_dev = load_distinct_data(\"within\")\n",
    "\n",
    "    X_abortion, X_gay_marriage, y_abortion, y_gay_marriage = split_within_by_topic(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi512_BCE_0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data/within_traindev_epi512_BCE_0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=600) as sw:\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=5, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        # stats = train_multi(model, data_train, ctx, metric, loss_function, batch_size=4, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - last part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:09:59.270846Z",
     "start_time": "2019-11-26T13:09:59.232160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split]: 0:00:00.033282\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "    # X_train, X_dev, y_train, y_dev = load_distinct_data(\"cross\")\n",
    "\n",
    "    X_abortion, X_gay_marriage, y_abortion, y_gay_marriage = split_within_by_topic(within_traindev_df)\n",
    "    \n",
    "    # cross:  abortion\n",
    "    # within: abortion + gay marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:10:02.882980Z",
     "start_time": "2019-11-26T13:10:00.465136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2 - setup BERT model]: 0:00:02.414871\n"
     ]
    }
   ],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:10:07.224901Z",
     "start_time": "2019-11-26T13:10:03.948614Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i thank pro for pushing me to find evidence to prove my case due to pro providing evidence as well. it is only fair to do the same. even without all of this information, a fetus still responds to stimuli at 8 weeks of development even though pain is not known to register at this stage. responding is the different to actually feeling it. at 8 weeks i clearly stated the fetus would not even have the neurons connected to the brain in order to actually feel tha pain. if the baby does feel pain at 8 weeks then how would it know without the neurons connected to the brain? pro left that unaswered. why is it that 'pain' quantifies human life? it wasn't pain instead it was the defintion i gave to be a human being. the case was given in order to find out what is a moral time to abort a fetus if the woman cared about the fetus feelings pain and acutally knowing it is. knowing it is important because if a person is braindead they are actually dead. brain does so much for a human and if they do not have it they lose out on many fuctions. memory, articulate speech, think etc. if person does not even have a functioning brain the person should and i think be considered dead. if the fetus lacks the capability of knowing about pain then it is comparable to a braindead person who is dead. first of all you are leaving out a great deal of factors of what exactly influences the crime rate. political factors, socio-economic factors, welfare factors, environmental factors. yes i do know that but that was not necessary in providing a point. the reason why i didn't talk about other factors is because what started these adults into a bad path was their parents failing the children and sending them to a care home. a select are emancipated and then 50. 8% engage in some sort of criminal activity. i am not denying a rich emancipated adult would not resort to crime but i highly doubt that is the norm instead would be the exception. not having a stable household with parents that can provide and meet your benefits does put a lot of the burden on a child. a care home cannot given the attention parents do due to the amount of children they have to take of which leaves the children to their own devices. what happens is that they do not know right from wrong until it occurs to them that the act of stealing is wrong. if someone does not have their undivided attetion on children then the children would most likely do something wrong due to their lack of ability to know right from wrong. if banning abortion does lead to increase emancipated adults then crime will increase. pro has not stated what was wrong instead there are many issues while also not stating what was wrong about my assumptions. you'd rather allow human beings to die at the perceived benefit for societythat is a way in looking at it. another way is that i much rather bring humans into a world where they are cared for instead the opposite. a hypothetical if i may. i much rather have a population of 100 people who are cared for by society rather then having a population of 1, 000 people who are not cared for by society. the numbers are quite small but if someone is not willing to care about the child they should abort it instead of allowing it to the enter the world where most likely they will commit crime. then it is the welfare system that needs overhaul. a welfare system does not help women love their children and if you decide to allow a mistake to stop women's career paths then all that is going to do is emotionally scar the women and blame the child for the governments ban on abortion. if there was no ban on abortion the women would be able to find career opportunities be fulfilled and then when she is ready have a child. my example gives the women more choice and would result in more affection given by the mother to the child due to it being her choice to bring about a child into the world not a mistake which cannot be undone. if it was directly as a result of the legalization, then crime should have started falling amongst the young population first. i didnt realise there was a report debunking the claims of that source. thank you for showing me so that now i require others sources to provide my point or maybe turn to the pro-life position but that remains to be seen. ill concede this point. to state that freedom is 'always' better is a ridiculous notion in this regard. just after i made that claim i stated this the blanket statement does only work at a point since i do not agree with someone taking someone elses life but in general the less restriction we oppose the freer the people are. freer people will have more options to live a fulfilling life thus not revolt against the state.  i dont really think pro did that on purpose but if his premise to his arguments are false like i just represented here then i can dismiss his argument that were gained from the false premises. the evidence supplied by rape kits has been reported; both by the journal and by a individual's account, to be often mishandled by police. rape kits sometimes go into evidence lockers for years before it is produced in a court. i will also drop this claim because i couldnt really find enough evidence to state it to be effective nor the opposite but you did and the professional does help me understand why rape kits dont actually work. there is no way to effectively stop all abortions because anything that the government deems as against the law will always have a black market. i highly doubt it would be effective whatsoever. the only thing it would do is increase the illegal activity of abortion or if people have the money go abroad to abort the baby. the united states have also gone through long enough with abortion that removing it would be too much of a big enough cultural change and would not work. burden of proof is not based upon 'hypothetical scenarios', it is based upon overall effectivenesspro does not realise it wasnt some far-fetched idea which was appealing to the minority instead it was the opposite. more households have knives than dont. most households have stairs that dont which means if a person really wanted to abort a baby they could do it. instead of allowing publicly funded abortion you instead resort to people using illegal abortion which cannot have the same effectiveness. a country that only allows abortions based upon life threatening scenarios. as per my source below when the law was tightened in 1993, the abortion rate fell 95% from reported cases. this alone is enough to support the enforcability of an anti-abortion law. case closed. first problem is that it is difficult to find out the data for illegal abortion because it is illegal. similar to saying x amount of illegals voted in elections. another problem i would like to add is that women that cant get abortion in poland just decide to go to another country. instead of stopping abortion it just increases illegal abortion and abortion rates in other countries. source: poland's abortion ban proposal near collapse after mass protests  the guardian to summarise: i have made my position clear on when it is right to abort a baby. i have conceded rape kits and abortion leading to less crime because of my lack of knowledge. i have still yet to see how pro would be able stop abortion and have shown above why simply banning abortion doesnt actually stop abortion.\n",
      "\"you get to choose a lot of things in life. you don't get to choose another human being's death. \" - ben shapiroyour profiles states you are agnostic and support tottenhum hotspur. meaning you are a non-theist living outside the usa. i am to also and also agreed with ben shapiro until people like sam harris shown how bad his foundation is. this thought that he has is based on religion. yeah sure you can get the idea and remove it from religion but then you wouldn't have added this quote about ben shapiro instead paraphrased it as your own words. ben shapiro makes the abortion very simple and misses out scenario's that can occur. even though he agrees that pregnancy can happen due to unforeseen circumstances of the woman and he would still ban abortion. so basically a rape victim would have to carry the child. a baby is a human being. human being: a man, woman, or child of the species homo sapiens, distinguished from other animals by superior mental development, power of articulate speech, and upright stance. (wikipedia)my definition provides a much better conditions for it be a human being. the genetic makeup is already decided. the sex of the baby is determined. the neural network begins to form. by the time four weeks has passed, the heart is already pumping blood around the body. the lungs are forming. the liver, the stomach, the kidneys. all of this happens while the baby is still within the mother's womb. you are saying the reason life stats at contraception is because of the genetic makeup right? if you go by that you can provide no case for why a person in a vegetative state is able to commit euthanasia. terri schiavo comes to mind. she was in a vegetative state which means you lack even the bare minimum of awareness. if we go by what you said we would have to allow her to carry on her existence until she dies. turns out she was in a vegetative state for 15 years. if the factor which makes a life is cells. you can't give an argument for terri schiavo's euthanasia while also remaining consistent. 1) a unborn baby is still a human beingeven at the first trimester of pregnancy, a baby is still a potential human life. one that (if not interfered with) will develop into a fully developed beautiful little lifeform that will soon open its eyes for the first time. you are not being consistent here. if you cared consistently about human life then you would consider masturbation mass murder. even with women when they are menstruating if you are consistent you would not be able to defend them not fertilizing the egg because like you said is still a potential life. so basically if you applied this to women and men individually they would be murderers. reason is during masturbation sperm is being lost which removes the potential life that could have been with the sperm. same principle with women. if they are not fertilized then that potential life is lost and by your stance it would be considered murder or maybe you are not consistent with your views. even though the baby is technically (at least scientifically) not alive within the first trimester, abortion is still unacceptable. if you wanted a unborn baby do die without feeling pain it would need to happen before 20 weeks. this provides a point for me because if the unborn baby feels nothing then we are not actually making the procedure painful. source: do fetuses feel pain? what the science says (livescience)drawing the line of killing a baby who is not yet alive is no different from killing someone who's in a coma or surviving on medical equipment. this has got to be a joke. a potential life is not yet born or can function in society but an already functioning member was put into a coma is somehow the same? it is not. a baby which is not yet alive is a fetus or a clump of cells. does that mean we have the right to kill him the same way we would kill a unborn child? personally, i think not. it is not about what you personally feel instead what you propose is a ban. the best you have is your thoughts without justification that can be done with evidence or explanations that are consistent. which means you have not provided a well thought through ban. 2) choice is not the mother's call in abortion in this case, including the potential citizens who will be a part of this world after 9 months. if i attempted to go over to my neighbours house and kill my neighbour with a knife, the government is obliged to stop me. this analogy links into the case of a mother killing her unborn baby. the government should and must step in to prevent murder as killing an innocent human being isn't our choice to make. i could have made a better point than this but i am not defending pro life. if aborting a fetus is not the responsibility of the woman carrying it. is it the responsibility of the state? this might be a false dichotomy but there are the only two choices for abortion. the government should not have this much power. it leaves to much to corruption and if the leader wills it he can do what he wants due to the amount of power you allowed president to use. there is virtually nothing that has 'forced' a mother to conceive a child if she has not been raped. we live in the 21st century, and assuming that we live in a modern and developing society, the access to information regarding safe sex and practicing it is widespread. saying it is the 21st century does not provide you point. you want abortion banned as an absolute. since you are not consistent when the life of the mother is threatened it has ceased to become an absolute. a case can be made that an individual does not see relevant information about sex and did it for the fun of it without knowing the consequences. with this in mind you are saying lets say a 16 year old should live with the consequences of her mistakes even if she did not know what they were. there are examples of 16 year old women pregnant in a show called 16 and pregnant. since you do not allow dumb people to make mistakes you allow women to be pregnant to up to 40 weeks. go through childbirth then decide to set the child up for adoption or raise it. raising it limits what the women can do with her life and giving up the child does lead to psychological effects. bearing in mind this could have been avoided if we keep abortion. the woman cannot aspire to do well in career opportunities, find the right person and not be left emotionally scarred while also being a good mother. lets say the person was not able to make an informed decision when committing the act. you are basically saying they can't make mistakes and have to live with it for the majority of their life or give it up for adoption. the bottom line is, if you're stupid enough to get pregnant with your partner while you were none of these things then it's clearly your own fault. your inconvenience and the burden of a baby does not justify that baby's death. this is where the state comes in. so basically there isn't path to redemption. mistakes should be with you for the rest of your life. stopping a better future you could've had only to raise a baby you did not even want. would also like to know how you are going to make abortion illegal when knifes exist. 3) rapehowever, making an exception for a marginal amount of cases would set a dangerous precedent which would eventually be manipulated and soon exceptions for abortion will grow greater and greater in percentage. eventually abortion as a whole would be undermined as the subject of rape in a lot of these cases can be very complex and convoluted. your defence for abortion not be allowed to rape victims is that it sets a dangerous precedent. that is the slippery slope fallacy. you are saying a small amount of fetuses being aborted due to rape will lead to major consequences. not saying why this is bad instead say it will lead to bad things. the moral argument is that the baby should not be punished for the offenses committed by his/her father. morals are relative and i only need to show an outcome where it is more moral to abort the baby instead of bringing it into this world. what if the mother was in chernobyl? what if the mother was in a battlefield? i gave you two scenarios were i think you would agree aborting the child is a good thing due to the chances of it being born with injuries. as times has changed we can provide more concrete views on where life starts. what you propose is us as a civilisation strip freedom in order for authoritarianism. woman should be able to fix mistakes instead of allowing them to living with it for a large amount of their life. your points for abortion banning for rape victims was a slippery slope fallacy and a women should not be able to fix her mistake instead keep the baby and would have to give up her life in order to raise child for a minimum of 15 years or adoption. 4) life threatening casessorry about that. i'll drop it. as pro i do not find my burden to prove its omnipresent effectiveness if you cannot enforce the law why are you advocating for it in the first place? it is basically a meaningless law that people can choose to follow. my opponent saying that we can't stop every abortion is about the equivalent of me saying that i know i'll break my leg on the pavement today because i can telepathically see into the future. this is absolutely absurd. to stop abortion we require surveillance of the individual to make sure she does not stab herself with a knife or jump down the stairs. what pro is proposing is if he wants to actually stop abortion by enforcing it is some sort of surveillance or something to keep an eye on the women so that she does not abort the baby. giving this power to the state allow them to do other things since with this law you have stripped away your private life and gave it into the hands of the state.\n",
      "1\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  1056  2029  2965  2065  1037  2711  2428  2359  2000 11113 11589\n",
      "  1037  3336  2027  2071  2079  2009  1012  2612  1997  4352  7271  6787\n",
      " 11324  2017  2612  7001  2000  2111  2478  6206 11324  2029  3685  2031\n",
      "  1996  2168 12353  1012  1037  2406  2008  2069  4473 11324  2015  2241\n",
      "  2588  2166  8701 16820  1012  2004  2566  2026  3120  2917  2043  1996\n",
      "  2375  2001  8371  1999  2857  1010  1996 11324  3446  3062  5345  1003\n",
      "  2013  2988  3572  1012  2023  2894  2003  2438  2000  2490  1996  4372\n",
      " 29278  3540  8553  1997  2019  3424  1011 11324  2375  1012  2553  2701\n",
      "  1012  2034  3291  2003  2008  2009  2003  3697  2000  2424  2041  1996\n",
      "  2951  2005  6206 11324  2138  2009  2003  6206  1012  2714  2000  3038\n",
      "  1060  3815  1997  6206  1521  1055  5444  1999  3864  1012  2178  3291\n",
      "  1045  2052  2066  2000  5587  2003  2008  2308  2008  2064  1521  1056\n",
      "  2131 11324  1999  3735  2074  5630  2000  2175  2000  2178  2406  1012\n",
      "  2612  1997  7458 11324  2009  2074  7457  6206 11324  1998 11324  6165\n",
      "  1999  2060  3032  1012  3120  1024  3735  1005  1055 11324  7221  6378\n",
      "  2379  7859  2044  3742  8090  1516  1996  6697  2000  7680  7849  5562\n",
      "  1024  1045  2031  2081  2026  2597  3154  2006  2043  2009  2003  2157\n",
      "  2000 11113 11589  1037  3336  1012  1045  2031 15848  9040 18628  1998\n",
      " 11324  2877  2000  2625  4126  2138  1997  2026  3768  1997  3716  1012\n",
      "  1045  2031  2145  2664  2000  2156  2129  4013  2052  2022  2583  2644\n",
      " 11324  1998  2031  3491  2682  2339  3432 21029 11324  2987  1521  1056\n",
      "  2941  2644 11324  1012     3  2005  9040  5694  2001  1037 22274  9663\n",
      "  2991 15719  1998  1037  2308  2323  2025  2022  2583  2000  8081  2014\n",
      "  6707  2612  2562  1996  3336  1998  2052  2031  2000  2507  2039  2014\n",
      "  2166  1999  2344  2000  5333  2775  2005  1037  6263  1997  2321  2086\n",
      "  2030  9886  1012  1018  1007  2166  8701  3572 21748  2854  2055  2008\n",
      "  1012  1045  1005  2222  4530  2009  1012  2004  4013  1045  2079  2025\n",
      "  2424  2026 10859  2000  6011  2049 18168  3490 28994  4765 12353  2065\n",
      "  2017  3685 16306  1996  2375  2339  2024  2017 20324  2005  2009  1999\n",
      "  1996  2034  2173  1029  2009  2003 10468  1037 25120  2375  2008  2111\n",
      "  2064  5454  2000  3582  1012  2026  7116  3038  2008  2057  2064  1005\n",
      "  1056  2644  2296 11324  2003  2055  1996  5662  1997  2033  3038  2008\n",
      "  1045  2113  1045  1005  2222  3338  2026  4190  2006  1996 14271  2651\n",
      "  2138  1045  2064 10093 13699 20972  3973  2156  2046  1996  2925  1012\n",
      "  2023  2003  7078 18691  1012  2000  2644 11324  2057  5478  9867  1997\n",
      "  1996  3265  2000  2191  2469  2016  2515  2025 17079  2841  2007  1037\n",
      "  5442  2030  5376  2091  1996  5108  1012  2054  4013  2003 21991  2003\n",
      "  2065  2002  4122  2000  2941  2644 11324  2011 27455  2009  2003  2070\n",
      "  4066  1997  9867  2030  2242  2000  2562  2019  3239  2006  1996  2308\n",
      "  2061  2008  2016  2515  2025 11113 11589  1996  3336  1012  3228  2023\n",
      "  2373  2000  1996  2110  3499  2068  2000  2079  2060  2477  2144  2007\n",
      "  2023  2375  2017  2031 10040  2185  2115  2797  2166  1998  2435  2009\n",
      "  2046  1996  2398  1997  1996  2110  1012     3]\n",
      "valid length = \n",
      "512\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "label = \n",
      "[1]\n",
      "Time for [3 - prepare training data]: 0:00:03.271424\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:10:08.292871Z",
     "start_time": "2019-11-26T13:10:08.290538Z"
    }
   },
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_epi512_BCE_0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:10:09.518011Z",
     "start_time": "2019-11-26T13:10:09.326176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory data/cross_traindev_epi512_BCE_0.1: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir data/cross_traindev_epi512_BCE_0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-26T13:10:03.694Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33433d436aa74447bf49cc4ce489cf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54943), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [setup training]: 0:04:25.959248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bfb2b512b54b009c88c1e8e19483f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9162), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 14:14:37,746 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574774077.cuda\n",
      "2019-11-26 14:14:37,791 : INFO : wrote 1 event to disk\n",
      "2019-11-26 14:14:37,792 : INFO : wrote 1 event to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 500/9162] loss=0.6764, lr=0.0000050, acc=0.579 - time 0:07:29.582800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 14:24:38,571 : INFO : wrote 1342 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1000/9162] loss=0.6220, lr=0.0000050, acc=0.618 - time 0:07:23.269249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 14:34:38,728 : INFO : wrote 1344 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1500/9162] loss=0.5301, lr=0.0000050, acc=0.656 - time 0:07:29.849516\n",
      "[Epoch 0 Batch 2000/9162] loss=0.4382, lr=0.0000050, acc=0.688 - time 0:07:30.711848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 14:44:39,092 : INFO : wrote 1332 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 2500/9162] loss=0.3639, lr=0.0000050, acc=0.716 - time 0:07:27.666973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 14:54:39,432 : INFO : wrote 1340 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 3000/9162] loss=0.3656, lr=0.0000050, acc=0.734 - time 0:07:29.073182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:04:39,663 : INFO : wrote 1336 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 3500/9162] loss=0.3715, lr=0.0000050, acc=0.746 - time 0:07:30.132334\n",
      "[Epoch 0 Batch 4000/9162] loss=0.3709, lr=0.0000050, acc=0.755 - time 0:07:29.690588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:14:40,356 : INFO : wrote 1334 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 4500/9162] loss=0.3434, lr=0.0000050, acc=0.765 - time 0:07:30.169179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:24:41,211 : INFO : wrote 1336 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 5000/9162] loss=0.3111, lr=0.0000050, acc=0.774 - time 0:07:28.427568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:34:41,398 : INFO : wrote 1336 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 5500/9162] loss=0.3028, lr=0.0000050, acc=0.781 - time 0:07:30.406369\n",
      "[Epoch 0 Batch 6000/9162] loss=0.3134, lr=0.0000050, acc=0.786 - time 0:07:29.811242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:44:41,467 : INFO : wrote 1334 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 6500/9162] loss=0.3170, lr=0.0000050, acc=0.790 - time 0:07:31.537196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 15:54:41,575 : INFO : wrote 1330 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 7000/9162] loss=0.2870, lr=0.0000050, acc=0.794 - time 0:07:29.050002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:04:41,894 : INFO : wrote 1336 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 7500/9162] loss=0.3149, lr=0.0000050, acc=0.798 - time 0:07:30.796250\n",
      "[Epoch 0 Batch 8000/9162] loss=0.2897, lr=0.0000050, acc=0.801 - time 0:07:30.603429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:14:42,593 : INFO : wrote 1332 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 8500/9162] loss=0.2886, lr=0.0000050, acc=0.805 - time 0:07:28.643814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:24:42,715 : INFO : wrote 1338 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 9000/9162] loss=0.2790, lr=0.0000050, acc=0.809 - time 0:07:30.315734\n",
      "\n",
      "Time for [epoch 0]: 2:17:15.596925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdeb6b2a1674f56b83111668d6cdcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9162), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:34:42,932 : INFO : wrote 1330 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 500/9162] loss=0.2603, lr=0.0000050, acc=0.886 - time 0:07:30.209460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:44:43,233 : INFO : wrote 1336 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 1000/9162] loss=0.2694, lr=0.0000050, acc=0.885 - time 0:07:29.636948\n",
      "[Epoch 1 Batch 1500/9162] loss=0.2480, lr=0.0000050, acc=0.887 - time 0:07:30.775304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 16:54:43,419 : INFO : wrote 1330 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 2000/9162] loss=0.2642, lr=0.0000050, acc=0.888 - time 0:07:30.856149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:04:43,497 : INFO : wrote 1332 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 2500/9162] loss=0.2809, lr=0.0000050, acc=0.886 - time 0:07:30.857964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:14:43,610 : INFO : wrote 1332 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 3000/9162] loss=0.2629, lr=0.0000050, acc=0.886 - time 0:07:30.261237\n",
      "[Epoch 1 Batch 3500/9162] loss=0.2737, lr=0.0000050, acc=0.886 - time 0:07:29.705852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:24:44,071 : INFO : wrote 1334 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 4000/9162] loss=0.2570, lr=0.0000050, acc=0.886 - time 0:07:31.296349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:34:44,282 : INFO : wrote 1334 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 4500/9162] loss=0.2675, lr=0.0000050, acc=0.886 - time 0:07:27.568322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:44:44,766 : INFO : wrote 1340 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 5000/9162] loss=0.2602, lr=0.0000050, acc=0.886 - time 0:07:27.947311\n",
      "[Epoch 1 Batch 5500/9162] loss=0.2587, lr=0.0000050, acc=0.887 - time 0:07:30.920262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 17:54:45,225 : INFO : wrote 1334 events to disk\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"4 - train model\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=600) as sw:\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=5, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:35:31.321714Z",
     "start_time": "2019-11-27T12:35:30.992715Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcoholism and drug-use are common after abortions.\n",
      "uncertainty over whether fetuses are \"life\" should halt abortions.\n",
      "1\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2 25519  1998  4319  1011  2224  2024  2691  2044 11324  2015  1012\n",
      "     3 12503  2058  3251 10768  5809  2229  2024  1000  2166  1000  2323\n",
      "  9190 11324  2015  1012     3     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "29\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[1]\n",
      "Time for [5 - prepare eval data]: 0:00:00.324033\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:39:02.739269Z",
     "start_time": "2019-11-27T12:35:34.750034Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f4aaa5141d4b90bf9d9e3590e68d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 13:35:35,002 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574858135.cuda\n",
      "2019-11-27 13:35:35,044 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:35:35,045 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:36:35,146 : INFO : wrote 596 events to disk\n",
      "2019-11-27 13:37:35,328 : INFO : wrote 604 events to disk\n",
      "2019-11-27 13:38:35,487 : INFO : wrote 574 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:03:27.717370\n",
      "Accuracy: 0.9307125307125307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 13:39:02,736 : INFO : wrote 261 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2846  178]\n",
      " [ 245 2836]]\n",
      "\n",
      "Accuracy:  0.93 \n",
      "\n",
      "Report for [BERTClassifier - cross BCE epilog 0.1 split]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3024\n",
      "           1       0.94      0.92      0.93      3081\n",
      "\n",
      "    accuracy                           0.93      6105\n",
      "   macro avg       0.93      0.93      0.93      6105\n",
      "weighted avg       0.93      0.93      0.93      6105\n",
      "\n",
      "Time for [6 - evaluate]: 0:03:27.981411\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:15:08.152827Z",
     "start_time": "2019-11-27T12:15:06.976900Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay marriage devalues marriage, frequency of obtaining it\n",
      "being unaccustomed to gay marriage is no argument\n",
      "0\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  5637  3510 16475  2389 15808  3510  1010  6075  1997 11381  2009\n",
      "     3  2108 14477 27631 20389  2098  2000  5637  3510  2003  2053  6685\n",
      "     3     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "25\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "Time for [7 - prepare eval data - for within foreign topic]: 0:00:01.170764\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"7 - prepare eval data - for within foreign topic\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_gay_marriage, y_gay_marriage, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:31:24.278956Z",
     "start_time": "2019-11-27T12:15:14.015342Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11532), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 13:15:14,364 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574856914.cuda\n",
      "2019-11-27 13:15:14,372 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:15:14,374 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:16:14,378 : INFO : wrote 1444 events to disk\n",
      "2019-11-27 13:17:14,401 : INFO : wrote 1452 events to disk\n",
      "2019-11-27 13:18:14,470 : INFO : wrote 1448 events to disk\n",
      "2019-11-27 13:19:14,518 : INFO : wrote 1462 events to disk\n",
      "2019-11-27 13:20:14,522 : INFO : wrote 1444 events to disk\n",
      "2019-11-27 13:21:14,550 : INFO : wrote 1426 events to disk\n",
      "2019-11-27 13:22:14,570 : INFO : wrote 1426 events to disk\n",
      "2019-11-27 13:23:14,632 : INFO : wrote 1418 events to disk\n",
      "2019-11-27 13:24:14,667 : INFO : wrote 1386 events to disk\n",
      "2019-11-27 13:25:14,670 : INFO : wrote 1422 events to disk\n",
      "2019-11-27 13:26:14,684 : INFO : wrote 1412 events to disk\n",
      "2019-11-27 13:27:14,709 : INFO : wrote 1446 events to disk\n",
      "2019-11-27 13:28:14,743 : INFO : wrote 1478 events to disk\n",
      "2019-11-27 13:29:14,825 : INFO : wrote 1422 events to disk\n",
      "2019-11-27 13:30:14,876 : INFO : wrote 1406 events to disk\n",
      "2019-11-27 13:31:14,884 : INFO : wrote 1410 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:16:07.559614\n",
      "Accuracy: 0.6531240515110783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 13:31:24,276 : INFO : wrote 161 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6455 3331]\n",
      " [4669 8608]]\n",
      "\n",
      "Accuracy:  0.65 \n",
      "\n",
      "Report for [BERTClassifier - within foreign topic BCE epilog 0.1 split]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.62      9786\n",
      "           1       0.72      0.65      0.68     13277\n",
      "\n",
      "    accuracy                           0.65     23063\n",
      "   macro avg       0.65      0.65      0.65     23063\n",
      "weighted avg       0.66      0.65      0.66     23063\n",
      "\n",
      "Time for [8 - evaluate - within foreign topic]: 0:16:10.255350\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"8 - evaluate - within foreign topic\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within foreign topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:55:42.428321Z",
     "start_time": "2019-11-27T12:55:40.153967Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted. pro may extend their arguments to the next round - then i will provide my opening arguments, followed by rebuttals/closing arguments.\n",
      "i\"m pro-life. just think about it, your murdering. not just anyone, your own child. it doesn\"t stop you from being a mother. it makes you the mother of a dead child. furthermore, one of the most common things pro-choice people say is \"her body, her choice.\" well excuse me, but that makes no sense at all. abortion is killing another person's body, killing one's own body is called suicide.\n",
      "0\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  3970  1012  4013  2089  7949  2037  9918  2000  1996  2279  2461\n",
      "  1011  2059  1045  2097  3073  2026  3098  9918  1010  2628  2011  2128\n",
      "  8569 28200  2015  1013  5494  9918  1012     3  1045  1000  1049  4013\n",
      "  1011  2166  1012  2074  2228  2055  2009  1010  2115 21054  1012  2025\n",
      "  2074  3087  1010  2115  2219  2775  1012  2009  2987  1000  1056  2644\n",
      "  2017  2013  2108  1037  2388  1012  2009  3084  2017  1996  2388  1997\n",
      "  1037  2757  2775  1012  7297  1010  2028  1997  1996  2087  2691  2477\n",
      "  4013  1011  3601  2111  2360  2003  1000  2014  2303  1010  2014  3601\n",
      "  1012  1000  2092  8016  2033  1010  2021  2008  3084  2053  3168  2012\n",
      "  2035  1012 11324  2003  4288  2178  2711  1005  1055  2303  1010  4288\n",
      "  2028  1005  1055  2219  2303  2003  2170  5920  1012     3     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "130\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "Time for [7 - prepare eval data - for within same topic]: 0:00:02.269127\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"7 - prepare eval data - for within same topic\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_abortion, y_abortion, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:25:13.466982Z",
     "start_time": "2019-11-27T12:56:04.292634Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20420), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 13:56:04,414 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574859364.cuda\n",
      "2019-11-27 13:56:04,425 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:56:04,427 : INFO : wrote 1 event to disk\n",
      "2019-11-27 13:57:04,455 : INFO : wrote 1410 events to disk\n",
      "2019-11-27 13:58:04,484 : INFO : wrote 1390 events to disk\n",
      "2019-11-27 13:59:04,562 : INFO : wrote 1422 events to disk\n",
      "2019-11-27 14:00:04,619 : INFO : wrote 1426 events to disk\n",
      "2019-11-27 14:01:04,728 : INFO : wrote 1378 events to disk\n",
      "2019-11-27 14:02:04,818 : INFO : wrote 1404 events to disk\n",
      "2019-11-27 14:03:04,903 : INFO : wrote 1384 events to disk\n",
      "2019-11-27 14:04:04,919 : INFO : wrote 1404 events to disk\n",
      "2019-11-27 14:05:04,995 : INFO : wrote 1378 events to disk\n",
      "2019-11-27 14:06:05,062 : INFO : wrote 1424 events to disk\n",
      "2019-11-27 14:07:05,063 : INFO : wrote 1410 events to disk\n",
      "2019-11-27 14:08:05,113 : INFO : wrote 1420 events to disk\n",
      "2019-11-27 14:09:05,153 : INFO : wrote 1388 events to disk\n",
      "2019-11-27 14:10:05,227 : INFO : wrote 1426 events to disk\n",
      "2019-11-27 14:11:05,225 : INFO : wrote 1474 events to disk\n",
      "2019-11-27 14:12:05,277 : INFO : wrote 1390 events to disk\n",
      "2019-11-27 14:13:05,317 : INFO : wrote 1414 events to disk\n",
      "2019-11-27 14:14:05,358 : INFO : wrote 1376 events to disk\n",
      "2019-11-27 14:15:05,410 : INFO : wrote 1414 events to disk\n",
      "2019-11-27 14:16:05,456 : INFO : wrote 1410 events to disk\n",
      "2019-11-27 14:17:05,494 : INFO : wrote 1418 events to disk\n",
      "2019-11-27 14:18:05,504 : INFO : wrote 1398 events to disk\n",
      "2019-11-27 14:19:05,570 : INFO : wrote 1386 events to disk\n",
      "2019-11-27 14:20:05,598 : INFO : wrote 1388 events to disk\n",
      "2019-11-27 14:21:05,619 : INFO : wrote 1408 events to disk\n",
      "2019-11-27 14:22:05,714 : INFO : wrote 1436 events to disk\n",
      "2019-11-27 14:23:05,738 : INFO : wrote 1396 events to disk\n",
      "2019-11-27 14:24:05,798 : INFO : wrote 1400 events to disk\n",
      "2019-11-27 14:25:05,856 : INFO : wrote 1384 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:29:04.873559\n",
      "Accuracy: 0.9829578844270324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 14:25:13,464 : INFO : wrote 83 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19698   308]\n",
      " [  388 20446]]\n",
      "\n",
      "Accuracy:  0.98 \n",
      "\n",
      "Report for [BERTClassifier - within foreign topic BCE epilog 0.1 split]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     20006\n",
      "           1       0.99      0.98      0.98     20834\n",
      "\n",
      "    accuracy                           0.98     40840\n",
      "   macro avg       0.98      0.98      0.98     40840\n",
      "weighted avg       0.98      0.98      0.98     40840\n",
      "\n",
      "Time for [8 - evaluate - within same topic]: 0:29:09.166592\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"8 - evaluate - within same topic\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within same topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:50:59.995039Z",
     "start_time": "2019-11-27T13:50:59.613197Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split (within)]: 0:00:00.026504\n",
      "abortion opens the door to the sexual exploitation of women the existence of abortion gives men a little more of a safeguard against unintentionally impregnating a woman. as a result, men will be more aggressive in their sexual exploitation of women.\n",
      "the fact that a child is likely to have a short life does not justify further shortening it:\n",
      "0\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2 11324  7480  1996  2341  2000  1996  4424 14427  1997  2308  1996\n",
      "  4598  1997 11324  3957  2273  1037  2210  2062  1997  1037 28805  2114\n",
      "  4895 18447  4765 19301  2135 17727  2890 16989  3436  1037  2450  1012\n",
      "  2004  1037  2765  1010  2273  2097  2022  2062  9376  1999  2037  4424\n",
      " 14427  1997  2308  1012     3  1996  2755  2008  1037  2775  2003  3497\n",
      "  2000  2031  1037  2460  2166  2515  2025 16114  2582  2460  7406  2009\n",
      "  1024     3     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "74\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "Time for [7 - prepare eval data - for within both topics (0.1 split)]: 0:00:00.348692\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"1 - test/train split (within)\"):\n",
    "    _, X_dev_within, _, y_dev_within = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"7 - prepare eval data - for within both topics (0.1 split)\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev_within, y_dev_within, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:56:37.562631Z",
     "start_time": "2019-11-27T13:52:04.066463Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3196), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 14:52:04,186 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574862724.cuda\n",
      "2019-11-27 14:52:04,195 : INFO : wrote 1 event to disk\n",
      "2019-11-27 14:52:04,196 : INFO : wrote 1 event to disk\n",
      "2019-11-27 14:53:04,257 : INFO : wrote 1414 events to disk\n",
      "2019-11-27 14:54:04,329 : INFO : wrote 1414 events to disk\n",
      "2019-11-27 14:55:04,356 : INFO : wrote 1412 events to disk\n",
      "2019-11-27 14:56:04,407 : INFO : wrote 1416 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:04:32.704990\n",
      "Accuracy: 0.8687216398059772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 14:56:37,559 : INFO : wrote 735 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2588  371]\n",
      " [ 468 2964]]\n",
      "\n",
      "Accuracy:  0.87 \n",
      "\n",
      "Report for [BERTClassifier - within both topics topic BCE epilog 0.1 split]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      2959\n",
      "           1       0.89      0.86      0.88      3432\n",
      "\n",
      "    accuracy                           0.87      6391\n",
      "   macro avg       0.87      0.87      0.87      6391\n",
      "weighted avg       0.87      0.87      0.87      6391\n",
      "\n",
      "Time for [8 - evaluate - within both topics]: 0:04:33.487855\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"8 - evaluate - within both topics\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within both topics topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:56:39.296844Z",
     "start_time": "2019-11-27T13:56:38.268870Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split (within)]: 0:00:00.013570\n",
      "abortion opens the door to the sexual exploitation of women the existence of abortion gives men a little more of a safeguard against unintentionally impregnating a woman. as a result, men will be more aggressive in their sexual exploitation of women.\n",
      "the fact that a child is likely to have a short life does not justify further shortening it:\n",
      "0\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2 11324  7480  1996  2341  2000  1996  4424 14427  1997  2308  1996\n",
      "  4598  1997 11324  3957  2273  1037  2210  2062  1997  1037 28805  2114\n",
      "  4895 18447  4765 19301  2135 17727  2890 16989  3436  1037  2450  1012\n",
      "  2004  1037  2765  1010  2273  2097  2022  2062  9376  1999  2037  4424\n",
      " 14427  1997  2308  1012     3  1996  2755  2008  1037  2775  2003  3497\n",
      "  2000  2031  1037  2460  2166  2515  2025 16114  2582  2460  7406  2009\n",
      "  1024     3     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "74\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "Time for [7 - prepare eval data - for within both topics (0.3 split)]: 0:00:01.010255\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"1 - test/train split (within)\"):\n",
    "    _, X_dev_within, _, y_dev_within = get_train_test_sets(within_traindev_df, ratio=0.3)\n",
    "\n",
    "with Timer(\"7 - prepare eval data - for within both topics (0.3 split)\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev_within, y_dev_within, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:10:18.660711Z",
     "start_time": "2019-11-27T13:56:40.117561Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4687f6f84542858d35a0842a97d3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9586), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 14:56:40,224 : INFO : successfully opened events file: data/cross_traindev_epi512_BCE_0.1/events.out.tfevents.1574863000.cuda\n",
      "2019-11-27 14:56:40,232 : INFO : wrote 1 event to disk\n",
      "2019-11-27 14:56:40,234 : INFO : wrote 1 event to disk\n",
      "2019-11-27 14:57:40,266 : INFO : wrote 1478 events to disk\n",
      "2019-11-27 14:58:40,299 : INFO : wrote 1436 events to disk\n",
      "2019-11-27 14:59:40,329 : INFO : wrote 1424 events to disk\n",
      "2019-11-27 15:00:40,368 : INFO : wrote 1384 events to disk\n",
      "2019-11-27 15:01:40,418 : INFO : wrote 1390 events to disk\n",
      "2019-11-27 15:02:40,490 : INFO : wrote 1394 events to disk\n",
      "2019-11-27 15:03:40,486 : INFO : wrote 1422 events to disk\n",
      "2019-11-27 15:04:40,538 : INFO : wrote 1394 events to disk\n",
      "2019-11-27 15:05:40,545 : INFO : wrote 1392 events to disk\n",
      "2019-11-27 15:06:40,607 : INFO : wrote 1440 events to disk\n",
      "2019-11-27 15:07:40,613 : INFO : wrote 1386 events to disk\n",
      "2019-11-27 15:08:40,629 : INFO : wrote 1388 events to disk\n",
      "2019-11-27 15:09:40,713 : INFO : wrote 1418 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:13:36.526051\n",
      "Accuracy: 0.8649522716603203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-27 15:10:18,657 : INFO : wrote 825 events to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[7724 1109]\n",
      " [1480 8858]]\n",
      "\n",
      "Accuracy:  0.86 \n",
      "\n",
      "Report for [BERTClassifier - within both topics topic (0.3 within) BCE epilog 0.1 split]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      8833\n",
      "           1       0.89      0.86      0.87     10338\n",
      "\n",
      "    accuracy                           0.86     19171\n",
      "   macro avg       0.86      0.87      0.86     19171\n",
      "weighted avg       0.87      0.86      0.87     19171\n",
      "\n",
      "Time for [8 - evaluate - within both topics (0.3 split)]: 0:13:38.539167\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"8 - evaluate - within both topics (0.3 split)\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within both topics topic (0.3 within) BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T14:22:18.545155Z",
     "start_time": "2019-11-27T14:22:18.536757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(30522 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.1, axes=())\n",
      "    (1): Dense(768 -> 1, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14,
     22
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model,\n",
    "                      data_train,\n",
    "                      ctx,\n",
    "                      metric,\n",
    "                      loss_function,\n",
    "                      batch_size=2,\n",
    "                      lr=5e-6,\n",
    "                      num_epochs=epoch_id + 1,\n",
    "                      checkpoint_dir='data/cross_traindev_epi512_BCE')\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model,\n",
    "                                            data_dev,\n",
    "                                            ctx,\n",
    "                                            metric,\n",
    "                                            loss_function,\n",
    "                                            batch_size=2)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true,\n",
    "                                y_pred,\n",
    "                                name=\"BERTClassifier\",\n",
    "                                heatmap=False)\n",
    "\n",
    "    model.save_parameters(\n",
    "        \"data/cross_traindev_epi512_BCE/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"11 - test/train split\"):\n",
    "    # evaluate on \"within\" test-data\n",
    "    _, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "with Timer(\"12 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "with Timer(\"13 - evaluate\"):\n",
    "    # model from \"cross\"\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cross-Model with Within-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:24:48.940295\n",
    "Accuracy: 0.8536330916488446\n",
    "Confusion Matrix:\n",
    "[[7659 1174]\n",
    " [1632 8706]]\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier cross with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.87      0.85      8833\n",
    "           1       0.88      0.84      0.86     10338\n",
    "\n",
    "    accuracy                           0.85     19171\n",
    "   macro avg       0.85      0.85      0.85     19171\n",
    "weighted avg       0.85      0.85      0.85     19171\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Cross-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with cross\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:22:17.542674\n",
    "Accuracy: 0.9379197379197379\n",
    "Confusion Matrix:\n",
    "[[8397  539]\n",
    " [ 598 8781]]\n",
    "\n",
    "Accuracy:  0.94 \n",
    "\n",
    "Report for [BERTClassifier]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.94      0.94      8936\n",
    "           1       0.94      0.94      0.94      9379\n",
    "\n",
    "    accuracy                           0.94     18315\n",
    "   macro avg       0.94      0.94      0.94     18315\n",
    "weighted avg       0.94      0.94      0.94     18315\n",
    "\n",
    "Time for [6 - evaluate]: 0:22:19.841677\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Within-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with within\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:19:51.733113\n",
    "Accuracy: 0.9069427781545042\n",
    "Confusion Matrix:\n",
    "[[7972  861]\n",
    " [ 923 9415]]\n",
    "\n",
    "Accuracy:  0.91 \n",
    "\n",
    "Report for [BERTClassifier within with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.90      0.90      8833\n",
    "           1       0.92      0.91      0.91     10338\n",
    "\n",
    "    accuracy                           0.91     19171\n",
    "   macro avg       0.91      0.91      0.91     19171\n",
    "weighted avg       0.91      0.91      0.91     19171\n",
    "\n",
    "Time for [evaluate within with cross]: 0:19:52.352049\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Cross-Model with Cross-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:23:28.845010\n",
    "Accuracy: 0.9197925197925197\n",
    "Confusion Matrix:\n",
    "[[8329  607]\n",
    " [ 862 8517]]\n",
    "\n",
    "Accuracy:  0.92 \n",
    "\n",
    "Report for [BERTClassifier cross]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.93      0.92      8936\n",
    "           1       0.93      0.91      0.92      9379\n",
    "\n",
    "    accuracy                           0.92     18315\n",
    "   macro avg       0.92      0.92      0.92     18315\n",
    "weighted avg       0.92      0.92      0.92     18315\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details to wrong classified arguments\n",
    "\n",
    "within_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()\n",
    "\n",
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "# print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier within-within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to dataframe\n",
    "dev_pred_df = pd.DataFrame(data=y_pred, columns=[\"prediction\"], dtype=\"bool\")\n",
    "\n",
    "# merge all dataframes\n",
    "dev_df = X_dev.join(y_dev)\n",
    "dev_df = dev_df.reset_index()\n",
    "dev_df = pd.merge(dev_df, dev_pred_df, left_index=True, right_index=True, how='inner')\n",
    "dev_df.set_index('id', inplace=True)\n",
    "\n",
    "# re-apply tag value\n",
    "dev_df = dev_df.progress_apply(add_tag, axis=1)\n",
    "# info\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "dev_df_ser_file = \"data/within_traindev_epi512_BCE/eval_dev_df.pickle\"\n",
    "\n",
    "\n",
    "with open(dev_df_ser_file, \"wb\") as f:\n",
    "    pickle.dump(dev_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(dev_df_ser_file, \"rb\") as f:\n",
    "    dev_df = pickle.load(f)\n",
    "\n",
    "\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPFN_df = dev_df[(dev_df['is_same_side'] != dev_df['prediction'])]  #  and (dev_df['tag'] != 'abortion')\n",
    "FPFN_df.info()\n",
    "FPFN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import re\n",
    "#import tabulate\n",
    "#display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "\n",
    "\n",
    "def print_args(df, idx, add_linebreaks=True):\n",
    "    row = df.iloc[idx]\n",
    "    print('IDX: {}, tag: {}, topics: {}'.format(idx, row['tag'], row['topic']))\n",
    "    print('Is-Same-Side: {}'.format(row['is_same_side']))\n",
    "\n",
    "    arg1 = row['argument1']\n",
    "    arg2 = row['argument2']\n",
    "    if add_linebreaks:\n",
    "        pat = re.compile(r'(?P<c>(\\.|\\?|\\!|\\:)+\\\"?)')\n",
    "        arg1 = pat.sub(r'\\1<br/>', arg1)\n",
    "        arg2 = pat.sub(r'\\1<br/>', arg2)\n",
    "\n",
    "    display(HTML('''<table>\n",
    "        <tr>\n",
    "            <td style=\"border-right:1px dashed black;\">{arg1}</td>\n",
    "            <td>{arg2}</td>\n",
    "        </tr>\n",
    "    </table>'''.format(arg1=arg1, arg2=arg2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = {print_args(FPFN_df, i) for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff'])\n",
    "    return row\n",
    "\n",
    "\n",
    "FPFN_df = FPFN_df.progress_apply(tokenize_arguments, axis=1)\n",
    "FPFN_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPFN_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final results/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "# model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "model.load_parameters('data/within_traindev_epi512_BCE_0.1/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pred = within_test_df[['argument1', 'argument2', 'topic']]\n",
    "#X_pred = cross_test_df[['argument1', 'argument2', 'topic']]\n",
    "X_pred = new_within_test_df[['argument1', 'argument2', 'topic']]\n",
    "y_pred = None\n",
    "\n",
    "data_pred_raw, data_pred = transform_dataset(X_pred, y_pred, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# data_pred_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# label_map=all_labels\n",
    "predictions = predict_unknown(model, data_pred, ctx, label_map=None, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data_pred) == len(predictions) == len(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to dataframe\n",
    "# bool works because we mapped 0 to False, 1 to True, is default conversion\n",
    "test_pred_df = pd.DataFrame(data=predictions, columns=[\"prediction\"], dtype=\"bool\")\n",
    "\n",
    "# merge all dataframes\n",
    "# test_df = X_pred.join(y_pred)\n",
    "test_df = X_pred.reset_index()\n",
    "test_df = pd.merge(test_df, test_pred_df, left_index=True, right_index=True, how='inner')\n",
    "test_df.set_index('id', inplace=True)\n",
    "\n",
    "# re-apply tag value\n",
    "test_df = test_df.progress_apply(add_tag, axis=1)\n",
    "# info\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE/within_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/cross_traindev_epi512_BCE/cross_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/cross_traindev_epi512_BCE/within_with_cross_model_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE/cross_with_within_model_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE_0.1/within_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_test_pred_df.pickle\"\n",
    "ser_fn = \"data/within_traindev_epi512_BCE_0.1/new_within_test_pred_df.pickle\"\n",
    "\n",
    "with open(ser_fn, \"wb\") as f:\n",
    "    pickle.dump(test_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test_df.itertuples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_fn = \"data/within_traindev_epi512_BCE/within_results.csv\"\n",
    "# res_fn = \"data/cross_traindev_epi512_BCE/cross_results.csv\"\n",
    "# res_fn = \"data/cross_traindev_epi512_BCE/within_with_cross_model_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE/cross_with_within_model_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE_0.1/within_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_results.csv\"\n",
    "res_fn = \"data/within_traindev_epi512_BCE_0.1/new_within_results.csv\"\n",
    "\n",
    "with open(res_fn, \"w\") as of:\n",
    "    of.write('\"id\",\"label\"\\n')\n",
    "    for row_id, row in test_df.iterrows():\n",
    "        of.write('{},\"{}\"\\n'.format(row_id, str(row['prediction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "cp cross_with_within_model_results.csv cross.csv\n",
    "cp within_results.csv within.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "gzip cross.csv\n",
    "gzip within.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "gzip new_within_results.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: do this for within and cross !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test read\n",
    "# temp_test_df = pd.read_csv(\"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_results.csv\", index_col='id')\n",
    "temp_test_df = pd.read_csv(\"data/within_traindev_epi512_BCE_0.1/new_within_results.csv\", index_col='id')\n",
    "temp_test_df.info()\n",
    "temp_test_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
